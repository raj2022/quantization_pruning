{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12678dcf",
   "metadata": {},
   "source": [
    "Working on the Post-training quantization of the model and the subset of the dataset. \n",
    "* Working on the model already trained with the CMS dataset.\n",
    "* The model has been quantized using the `tf.lite.converter`\n",
    "* Further, we are working with sample of the dataset(100 for our case). \n",
    "* Quantizing the sample of dataset using INT8 quantization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c78f63",
   "metadata": {},
   "source": [
    "As written on here, we were working on the stuff with the debugging of the model and working out the task. \n",
    "* Perform the quantization of the model\n",
    "* Convert all of the data \n",
    "* Put all stuff in a notebook along with the model interface."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf482f43",
   "metadata": {},
   "source": [
    "## `Task`\n",
    "Standardize the P_T value before quantizing.\n",
    "\n",
    "Three P_T plots:\n",
    "\n",
    "Raw P_T (Number of particles vs P_T (GeV))\n",
    "P_T after standardization (X-axis should be arbitrary units)\n",
    "After int8 quantization. Centers at 0 and range should be between -127, 127)\n",
    "Upon standardization, there could be a few values which could be out of the range of (-127, 127). How to deal with the outliers? One of the methods is to put all of them in the last bin. Are there any other methods available?\n",
    "\n",
    "Fix bin size does not give resolution. We can lose information if we discard those outliers.\n",
    "\n",
    "Print the true and predicted P_T values. Should be in the INT8 range.\n",
    "\n",
    "Put on the distribution if it makes sense."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99fd99c9",
   "metadata": {},
   "source": [
    "We need to standradization to whole datasample which is 100 in our case.\n",
    "* Plot the datasample before and after standradization ??\n",
    "* Or do we only need to standradize the True P_T?\n",
    "* What type of output you have right now?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08fd0d38",
   "metadata": {},
   "source": [
    "`The dataset contains input features and target features consist of different things like pT, eta, phi etc. so all of those need to be standardized and quantized separately. but you can start with just pT` Task:\n",
    "\n",
    "1. Since working only on the pT, quntize it after standradization. Further Check the plots before and after quantization.\n",
    "\n",
    "Quantize the dataset after stnadradization and then do the inference. Check the output plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52af97f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-26 15:44:29.290847: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-12-26 15:44:36.408911: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.30/03\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import ROOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "935f2edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path += [\"../../../MLPF/mlpf/particleflow/mlpf/\"]\n",
    "from tfmodel.model_setup import make_model\n",
    "from tfmodel.utils import parse_config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e76e3561",
   "metadata": {},
   "outputs": [],
   "source": [
    "config, _ = parse_config(\"../../../MLPF/mlpf/particleflow/parameters/clic.yaml\") #positions on the lxplus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "825cf2bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-26 15:49:08.261369: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-26 15:49:09.215487: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-26 15:49:09.220625: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-26 15:49:09.231120: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-26 15:49:09.234293: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-26 15:49:09.237436: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-26 15:49:09.467478: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-26 15:49:09.469348: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-26 15:49:09.471086: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-26 15:49:09.472866: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13775 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:07:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = make_model(config, tf.float32)\n",
    "model.build((1, None, config[\"dataset\"][\"num_input_features\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25663786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"pf_net_dense\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " node_encoding (Sequential)  (1, None, 256)            70912     \n",
      "                                                                 \n",
      " input_encoding_clic (Input  multiple                  0         \n",
      " EncodingCLIC)                                                   \n",
      "                                                                 \n",
      " cg_id_0 (CombinedGraphLaye  multiple                  440128    \n",
      " r)                                                              \n",
      "                                                                 \n",
      " cg_id_1 (CombinedGraphLaye  multiple                  440128    \n",
      " r)                                                              \n",
      "                                                                 \n",
      " cg_id_2 (CombinedGraphLaye  multiple                  440128    \n",
      " r)                                                              \n",
      "                                                                 \n",
      " cg_id_3 (CombinedGraphLaye  multiple                  440128    \n",
      " r)                                                              \n",
      "                                                                 \n",
      " cg_id_4 (CombinedGraphLaye  multiple                  440128    \n",
      " r)                                                              \n",
      "                                                                 \n",
      " cg_id_5 (CombinedGraphLaye  multiple                  440128    \n",
      " r)                                                              \n",
      "                                                                 \n",
      " cg_reg_0 (CombinedGraphLay  multiple                  440128    \n",
      " er)                                                             \n",
      "                                                                 \n",
      " cg_reg_1 (CombinedGraphLay  multiple                  440128    \n",
      " er)                                                             \n",
      "                                                                 \n",
      " cg_reg_2 (CombinedGraphLay  multiple                  440128    \n",
      " er)                                                             \n",
      "                                                                 \n",
      " cg_reg_3 (CombinedGraphLay  multiple                  440128    \n",
      " er)                                                             \n",
      "                                                                 \n",
      " cg_reg_4 (CombinedGraphLay  multiple                  440128    \n",
      " er)                                                             \n",
      "                                                                 \n",
      " cg_reg_5 (CombinedGraphLay  multiple                  440128    \n",
      " er)                                                             \n",
      "                                                                 \n",
      " output_decoding (OutputDec  multiple                  269967    \n",
      " oding)                                                          \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5622415 (21.45 MB)\n",
      "Trainable params: 5468815 (20.86 MB)\n",
      "Non-trainable params: 153600 (600.00 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8b789ea",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Unable to open file (file signature not found)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m/tmp/sraj/ipykernel_3815594/1940220216.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../../../MLPF/mlpf/weights-96-5.346523.hdf5\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_mismatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mby_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m## These files hosted at https://huggingface.co/jpata/particleflow/tree/clic_clusters_v1.6\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cvmfs/sft-nightlies.cern.ch/lcg/views/dev4cuda/Tue/x86_64-el9-gcc11-opt/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cvmfs/sft-nightlies.cern.ch/lcg/views/dev4cuda/Tue/x86_64-el9-gcc11-opt/lib/python3.9/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[0m\n\u001b[1;32m    565\u001b[0m                                  \u001b[0mfs_persist\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfs_persist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfs_threshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfs_threshold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m                                  fs_page_size=fs_page_size)\n\u001b[0;32m--> 567\u001b[0;31m                 \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    568\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cvmfs/sft-nightlies.cern.ch/lcg/views/dev4cuda/Tue/x86_64-el9-gcc11-opt/lib/python3.9/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Unable to open file (file signature not found)"
     ]
    }
   ],
   "source": [
    "model.load_weights(\"../../../MLPF/mlpf/weights-96-5.346523.hdf5\", skip_mismatch=False, by_name=True)\n",
    "## These files hosted at https://huggingface.co/jpata/particleflow/tree/clic_clusters_v1.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365ad42d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68b0a5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
