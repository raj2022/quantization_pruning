{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12678dcf",
   "metadata": {},
   "source": [
    "Working on the Post-training quantization of the model and the subset of the dataset. \n",
    "* Working on the model already trained with the CMS dataset.\n",
    "* The model has been quantized using the `tf.lite.converter`\n",
    "* Further, we are working with sample of the dataset(100 for our case). \n",
    "* Quantizing the sample of dataset using INT8 quantization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c78f63",
   "metadata": {},
   "source": [
    "As written on here, we were working on the stuff with the debugging of the model and working out the task. \n",
    "* Perform the quantization of the model\n",
    "* Convert all of the data \n",
    "* Put all stuff in a notebook along with the model interface."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf482f43",
   "metadata": {},
   "source": [
    "## `Task`\n",
    "Standardize the P_T value before quantizing.\n",
    "\n",
    "Three P_T plots:\n",
    "\n",
    "Raw P_T (Number of particles vs P_T (GeV))\n",
    "P_T after standardization (X-axis should be arbitrary units)\n",
    "After int8 quantization. Centers at 0 and range should be between -127, 127)\n",
    "Upon standardization, there could be a few values which could be out of the range of (-127, 127). How to deal with the outliers? One of the methods is to put all of them in the last bin. Are there any other methods available?\n",
    "\n",
    "Fix bin size does not give resolution. We can lose information if we discard those outliers.\n",
    "\n",
    "Print the true and predicted P_T values. Should be in the INT8 range.\n",
    "\n",
    "Put on the distribution if it makes sense."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99fd99c9",
   "metadata": {},
   "source": [
    "We need to standradization to whole datasample which is 100 in our case.\n",
    "* Plot the datasample before and after standradization ??\n",
    "* Or do we only need to standradize the True P_T?\n",
    "* What type of output you have right now?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08fd0d38",
   "metadata": {},
   "source": [
    "`The dataset contains input features and target features consist of different things like pT, eta, phi etc. so all of those need to be standardized and quantized separately. but you can start with just pT` Task:\n",
    "\n",
    "1. Since working only on the pT, quntize it after standradization. Further Check the plots before and after quantization.\n",
    "\n",
    "Quantize the dataset after stnadradization and then do the inference. Check the output plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52af97f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import ROOT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "935f2edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path += [\"../../../MLPF/mlpf/particleflow/mlpf/\"]\n",
    "from tfmodel.model_setup import make_model\n",
    "from tfmodel.utils import parse_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e76e3561",
   "metadata": {},
   "outputs": [],
   "source": [
    "config, _ = parse_config(\"../../../MLPF/mlpf/particleflow/parameters/clic.yaml\") #positions on the lxplus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "825cf2bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-04 22:49:03.103688: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-04 22:49:03.130399: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-04 22:49:03.132358: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-04 22:49:03.141680: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-04 22:49:03.143638: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-04 22:49:03.145587: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-04 22:49:03.389484: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-04 22:49:03.391583: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-04 22:49:03.393534: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-04 22:49:03.395441: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 724 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:07:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = make_model(config, tf.float32)\n",
    "model.build((1, None, config[\"dataset\"][\"num_input_features\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25663786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"pf_net_dense\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " node_encoding (Sequential)  (1, None, 256)            70912     \n",
      "                                                                 \n",
      " input_encoding_clic (Input  multiple                  0         \n",
      " EncodingCLIC)                                                   \n",
      "                                                                 \n",
      " cg_id_0 (CombinedGraphLaye  multiple                  440128    \n",
      " r)                                                              \n",
      "                                                                 \n",
      " cg_id_1 (CombinedGraphLaye  multiple                  440128    \n",
      " r)                                                              \n",
      "                                                                 \n",
      " cg_id_2 (CombinedGraphLaye  multiple                  440128    \n",
      " r)                                                              \n",
      "                                                                 \n",
      " cg_id_3 (CombinedGraphLaye  multiple                  440128    \n",
      " r)                                                              \n",
      "                                                                 \n",
      " cg_id_4 (CombinedGraphLaye  multiple                  440128    \n",
      " r)                                                              \n",
      "                                                                 \n",
      " cg_id_5 (CombinedGraphLaye  multiple                  440128    \n",
      " r)                                                              \n",
      "                                                                 \n",
      " cg_reg_0 (CombinedGraphLay  multiple                  440128    \n",
      " er)                                                             \n",
      "                                                                 \n",
      " cg_reg_1 (CombinedGraphLay  multiple                  440128    \n",
      " er)                                                             \n",
      "                                                                 \n",
      " cg_reg_2 (CombinedGraphLay  multiple                  440128    \n",
      " er)                                                             \n",
      "                                                                 \n",
      " cg_reg_3 (CombinedGraphLay  multiple                  440128    \n",
      " er)                                                             \n",
      "                                                                 \n",
      " cg_reg_4 (CombinedGraphLay  multiple                  440128    \n",
      " er)                                                             \n",
      "                                                                 \n",
      " cg_reg_5 (CombinedGraphLay  multiple                  440128    \n",
      " er)                                                             \n",
      "                                                                 \n",
      " output_decoding (OutputDec  multiple                  269967    \n",
      " oding)                                                          \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5622415 (21.45 MB)\n",
      "Trainable params: 5468815 (20.86 MB)\n",
      "Non-trainable params: 153600 (600.00 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a8b789ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"weights-96-5.346523.hdf5\", skip_mismatch=False, by_name=True)\n",
    "## These files hosted at https://huggingface.co/jpata/particleflow/tree/clic_clusters_v1.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "365ad42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reading the dataset\n",
    "ds_builder = tfds.builder(\"clic_edm_qq_pf\", data_dir = '../../../MLPF/mlpf/tensorflow_datasets/') # Tensorflow datsets positions in the lxplus\n",
    "dss = ds_builder.as_data_source(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a68b0a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def yield_from_ds():\n",
    "    for elem in dss:\n",
    "        yield {\"X\": elem[\"X\"], \"ygen\": elem[\"ygen\"], \"ycand\": elem[\"ycand\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4897c8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_signature = {k: tf.TensorSpec(shape=(None, v.shape[1])) for (k, v) in dss.dataset_info.features.items()}\n",
    "tf_dataset = tf.data.Dataset.from_generator(yield_from_ds, output_signature=output_signature).take(100).padded_batch(batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5b3fe913",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = list(tfds.as_numpy(tf_dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5d77fc9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs = [d[\"X\"] for d in data]\n",
    "ys = [d[\"ygen\"] for d in data]\n",
    "ycs= [d[\"ycand\"] for d in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "47cfabda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-04 23:25:46.979690: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n"
     ]
    }
   ],
   "source": [
    "true_pts = []\n",
    "pred_pts = []\n",
    "\n",
    "for ibatch in range(len(Xs)):\n",
    "    ret = model(Xs[ibatch])\n",
    "\n",
    "    mask_true_particles = ys[ibatch][..., 0]!=0\n",
    "    \n",
    "    true_pt = ys[ibatch][mask_true_particles, 2]\n",
    "    pred_pt = ret[\"pt\"][mask_true_particles][..., 0].numpy()\n",
    "\n",
    "    true_pts.append(true_pt)\n",
    "    pred_pts.append(pred_pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "72e71625",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_pt = np.concatenate(true_pts)\n",
    "pred_pt = np.concatenate(pred_pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "40e45ff4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(pred_pt/true_pt, bins=np.linspace(0,3,100));\n",
    "plt.yscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce942149",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e899cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88230c9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fdcfdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9046d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
