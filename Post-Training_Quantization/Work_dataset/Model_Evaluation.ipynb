{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "259b8401",
   "metadata": {},
   "source": [
    "\n",
    "Given the notebook, https://github.com/jpata/particleflow/blob/nb_clic_evaluate/notebooks/mlpf-clic-evaluate.ipynb as it loads the model, sets the weights, run the inference on a  set of events and compare the true vs. Predicted value for pT on a smaller subset.\n",
    "\n",
    "*Task:*\n",
    "Do the quantization of the model, and the conversion of the data, all in one notebook along with the model inference. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a1bf01",
   "metadata": {},
   "source": [
    "Load the quantized model, load the quantized weights, and convert all of the data using quantization and then mesaure the inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81940f5a",
   "metadata": {},
   "source": [
    "some point you need to use something like tf.lite.TFLiteConverter?\n",
    "https://www.tensorflow.org/lite/performance/post_training_integer_quant\n",
    "or is there another way?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59fe0600",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 13:37:09.509373: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-22 13:37:09.662701: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-22 13:37:09.662728: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-22 13:37:09.663976: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-22 13:37:09.772084: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-22 13:37:09.773922: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-22 13:37:10.743742: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47659ab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:horovod not found, ignoring\n",
      "WARNING:root:horovod not found, ignoring\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path += [\"../../../../particleflow/mlpf/\"]\n",
    "from tfmodel.model_setup import make_model\n",
    "from tfmodel.utils import parse_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e4b05d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "config, _ = parse_config(\"../../../../particleflow/parameters/clic.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b19e9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_model(config, tf.float32)\n",
    "model.build((1, None, config[\"dataset\"][\"num_input_features\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a179b4f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"pf_net_dense\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " normalization (Normalizati  multiple                  33        \n",
      " on)                                                             \n",
      "                                                                 \n",
      " node_encoding (Sequential)  (1, None, 256)            70912     \n",
      "                                                                 \n",
      " input_encoding_clic (Input  multiple                  0         \n",
      " EncodingCLIC)                                                   \n",
      "                                                                 \n",
      " cg_id_0 (CombinedGraphLaye  multiple                  440128    \n",
      " r)                                                              \n",
      "                                                                 \n",
      " cg_id_1 (CombinedGraphLaye  multiple                  440128    \n",
      " r)                                                              \n",
      "                                                                 \n",
      " cg_id_2 (CombinedGraphLaye  multiple                  440128    \n",
      " r)                                                              \n",
      "                                                                 \n",
      " cg_id_3 (CombinedGraphLaye  multiple                  440128    \n",
      " r)                                                              \n",
      "                                                                 \n",
      " cg_id_4 (CombinedGraphLaye  multiple                  440128    \n",
      " r)                                                              \n",
      "                                                                 \n",
      " cg_id_5 (CombinedGraphLaye  multiple                  440128    \n",
      " r)                                                              \n",
      "                                                                 \n",
      " cg_reg_0 (CombinedGraphLay  multiple                  440128    \n",
      " er)                                                             \n",
      "                                                                 \n",
      " cg_reg_1 (CombinedGraphLay  multiple                  440128    \n",
      " er)                                                             \n",
      "                                                                 \n",
      " cg_reg_2 (CombinedGraphLay  multiple                  440128    \n",
      " er)                                                             \n",
      "                                                                 \n",
      " cg_reg_3 (CombinedGraphLay  multiple                  440128    \n",
      " er)                                                             \n",
      "                                                                 \n",
      " cg_reg_4 (CombinedGraphLay  multiple                  440128    \n",
      " er)                                                             \n",
      "                                                                 \n",
      " cg_reg_5 (CombinedGraphLay  multiple                  440128    \n",
      " er)                                                             \n",
      "                                                                 \n",
      " output_decoding (OutputDec  multiple                  269967    \n",
      " oding)                                                          \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5622448 (21.45 MB)\n",
      "Trainable params: 5468815 (20.86 MB)\n",
      "Non-trainable params: 153633 (600.13 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "331f3cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"weights-96-5.346523.hdf5\", skip_mismatch=False, by_name=True)\n",
    "## These files hosted at https://huggingface.co/jpata/particleflow/tree/clic_clusters_v1.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c896d51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reading the dataset\n",
    "ds_builder = tfds.builder(\"clic_edm_qq_pf\", data_dir = '../../../tensorflow_datasets/')\n",
    "dss = ds_builder.as_data_source(\"test\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d5e4dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def yield_from_ds():\n",
    "    for elem in dss:\n",
    "        yield {\"X\": elem[\"X\"], \"ygen\": elem[\"ygen\"], \"ycand\": elem[\"ycand\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1479b843",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_signature = {k: tf.TensorSpec(shape=(None, v.shape[1])) for (k, v) in dss.dataset_info.features.items()}\n",
    "tf_dataset = tf.data.Dataset.from_generator(yield_from_ds, output_signature=output_signature).take(100).padded_batch(batch_size=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5fd80d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = list(tfds.as_numpy(tf_dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b4acdb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs = [d[\"X\"] for d in data]\n",
    "ys = [d[\"ygen\"] for d in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "689eef34",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_pts = []\n",
    "pred_pts = []\n",
    "\n",
    "for ibatch in range(len(Xs)):\n",
    "    ret = model(Xs[ibatch])\n",
    "\n",
    "    mask_true_particles = ys[ibatch][..., 0]!=0\n",
    "    \n",
    "    true_pt = ys[ibatch][mask_true_particles, 2]\n",
    "    pred_pt = ret[\"pt\"][mask_true_particles][..., 0].numpy()\n",
    "\n",
    "    true_pts.append(true_pt)\n",
    "    pred_pts.append(pred_pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1bcd5ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_pt = np.concatenate(true_pts)\n",
    "pred_pt = np.concatenate(pred_pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "716b68b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(pred_pt/true_pt, bins=np.linspace(0,3,100));\n",
    "plt.yscale(\"log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c32a2ee",
   "metadata": {},
   "source": [
    "## Quantized data into the unquantized model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4817027",
   "metadata": {},
   "source": [
    "Quantizing the data into INT8 before feeding it into the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63219f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantize input data\n",
    "Xs_quantized = [np.round(X * 127).astype(np.int8) for X in Xs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a63aed50",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs_quantized = [np.round(X * 127).astype(np.int8) for X in Xs]\n",
    "Xs_tf = [tf.convert_to_tensor(X_q, dtype=tf.float32) for X_q in Xs_quantized]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0ab11cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ys_quantized = [np.round(y * 127).astype(np.int8) for y in ys]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "744809e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_pts = []\n",
    "pred_pts = []\n",
    "\n",
    "for ibatch in range(len(Xs_tf)):\n",
    "    ret = model(Xs_tf[ibatch])\n",
    "\n",
    "    mask_true_particles = ys_quantized[ibatch][..., 0]!=0\n",
    "    \n",
    "    true_pt = ys[ibatch][mask_true_particles, 2]\n",
    "    pred_pt = ret[\"pt\"][mask_true_particles][..., 0].numpy()\n",
    "\n",
    "    true_pts.append(true_pt)\n",
    "    pred_pts.append(pred_pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8840038c",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_pt = np.concatenate(true_pts)\n",
    "pred_pt = np.concatenate(pred_pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a1730822",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(pred_pt/true_pt, bins=np.linspace(0,3,100));\n",
    "plt.title(\"After INT8 Quantization\")\n",
    "plt.yscale(\"log\")\n",
    "plt.savefig('Output_after_INT8_quantization.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63be5752",
   "metadata": {},
   "source": [
    "Above one is the output with the quantized dataset but not quantized model. We were wokring with the Dynamic Range Quantization. \n",
    "Dynamic range quantization is a recommended starting point because it provides reduced memory usage and faster computation without you having to provide a representative dataset for calibration. This type of quantization, statically quantizes only the weights from floating point to integer at conversion time, which provides 8-bits of precision.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5391ebdd",
   "metadata": {},
   "source": [
    "## Quantized Model with the Quantized Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77582ebf",
   "metadata": {},
   "source": [
    "Let's try with **[quantized model](https://www.tensorflow.org/lite/performance/post_training_quantization#full_integer_quantization_of_weights_and_activations)**, Post-training qunatization method, Dynamic range quantization. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f439ec",
   "metadata": {},
   "source": [
    "## Dynamic Range Quantization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b108b047",
   "metadata": {},
   "source": [
    "Converting the model using dynamic range quantization(https://www.tensorflow.org/lite/performance/post_training_integer_quant):\n",
    "Let's enable the default optimizations flag to quantize all fixed parameters (such as weights):\n",
    "The model is now a bit smaller with quantized weights, but other variable data is still in float format.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3790f748",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "quantized_tflite_model = converter.convert()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc83ead0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measuring the size of the quantized tflite model\n",
    "# Saving the model\n",
    "import os\n",
    "\n",
    "with open('quantized_tflite_model.tflite', 'wb') as f:\n",
    "    f.write(quantized_tflite_model)\n",
    "    \n",
    "model_size = os.path.getsize('quantized_tflite_model.tflite')\n",
    "\n",
    "print(f\"Size of the quantized model: {model_size} bytes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3a2f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the quantized TFlite model\n",
    "interpreter = tf.lite.Interpreter(model_content=quantized_tflite_model)\n",
    "interpreter.allocate_tensors()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e936d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get input and output details\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa32d90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3e1ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Xs_quantized is a list of quantized input data\n",
    "input_data = Xs_quantized[ibatch]\n",
    "\n",
    "# Print shapes for debugging\n",
    "print(\"Input Data Shape:\", input_data.shape)\n",
    "print(\"Expected Input Shape:\", input_details[0]['shape'][1:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a241a73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you want to use the first 111 samples as a single batch\n",
    "input_data_reshaped = input_data[:111, :, :]\n",
    "\n",
    "# Remove the singleton batch dimension\n",
    "input_data_reshaped = np.squeeze(input_data_reshaped)\n",
    "\n",
    "\n",
    "# Check the shape after reshaping\n",
    "print(\"Reshaped Input Data Shape:\", input_data_reshaped.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59e4b6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885fc6c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d535893",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b64592",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3acc333",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "71712e16",
   "metadata": {},
   "source": [
    "Run the inference on the quantized TFLite model: \\\n",
    "**Something is not right here**\n",
    "Check this one https://www.tensorflow.org/lite/performance/post_training_integer_quant\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346e9b9d",
   "metadata": {},
   "source": [
    "## 11/22/23\n",
    "## Quantization for the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65eaa27a",
   "metadata": {},
   "source": [
    "Trying with dynamic range quantization for both the model and the dataset.the model is not constructed using standard Keras layers, leading to difficulties with quantization.\n",
    "\n",
    "If the model contains custom layers or non-Keras components, it might not be straightforward to apply dynamic range quantization directly. In such cases, you may consider using a different quantization approach like post-training quantization.\n",
    "\n",
    "We will go with Post-Training Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fba57bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_model_optimization as tfmot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3c6905cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 13:38:42.933393: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2023-11-22 13:38:42.933415: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2023-11-22 13:38:42.933980: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmp1l7nko0h\n",
      "2023-11-22 13:38:42.988756: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2023-11-22 13:38:42.988782: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmp1l7nko0h\n",
      "2023-11-22 13:38:43.096654: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:382] MLIR V1 optimization pass is not enabled\n",
      "2023-11-22 13:38:43.144178: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2023-11-22 13:38:43.750925: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /tmp/tmp1l7nko0h\n",
      "2023-11-22 13:38:44.108345: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 1174365 microseconds.\n",
      "2023-11-22 13:38:44.681779: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n"
     ]
    }
   ],
   "source": [
    "# Convert the new model to a TensorFlow Lite model\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "quantized_tflite_model = converter.convert()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f207ecd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the TensorFlow Lite model to a file\n",
    "with open(\"quantized_model.tflite\", \"wb\") as f:\n",
    "    f.write(quantized_tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2325b7c",
   "metadata": {},
   "source": [
    "### Quantize the dataset\n",
    "To quantize the dataset, you can apply quantization to the features and labels before feeding them to the model. You can achieve this by normalizing the values to a quantized range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "305e0d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs_quantized = [np.round(X * 127).astype(np.int8) for X in Xs]\n",
    "Xs_tf = [tf.convert_to_tensor(X_q, dtype=tf.float32) for X_q in Xs_quantized]\n",
    "\n",
    "ys_quantized = [np.round(y * 127).astype(np.int8) for y in ys]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee1dbe1",
   "metadata": {},
   "source": [
    "convert the quantized data to TensorFlow tensors and proceed with inference on the quantized model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6e5c398e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert quantized features to TensorFlow tensors\n",
    "Xs_tf = [tf.convert_to_tensor(X_q, dtype=tf.float32) for X_q in Xs_quantized]\n",
    "\n",
    "# Convert quantized labels to TensorFlow tensors\n",
    "ys_tf = [tf.convert_to_tensor(y_q, dtype=tf.float32) for y_q in ys_quantized]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70eda1ab",
   "metadata": {},
   "source": [
    "After converting the data to TensorFlow tensors, you can perform inference using your quantized model:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "418ad842",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have a TensorFlow Lite quantized model (quantized_tflite_model)\n",
    "interpreter = tf.lite.Interpreter(model_content=quantized_tflite_model)\n",
    "interpreter.allocate_tensors()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ef5c3898",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get input and output details\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1ffebbaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected input shape: [  1 111  17]\n"
     ]
    }
   ],
   "source": [
    "# Checking the expected shape of the input tensor\n",
    "expected_input_shape = input_details[0]['shape']\n",
    "print(\"Expected input shape:\", expected_input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "517cd59b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_q: (10, 111, 17)\n"
     ]
    }
   ],
   "source": [
    "# Verify the shape of your input tensor (X_q)\n",
    "print(\"Shape of X_q:\", X_q.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c54a1e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape X_q to match the expected input shape\n",
    "X_q_reshaped = np.reshape(X_q, (1, 111, 17))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6a66af8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_q_reshaped: (1, 111, 17)\n"
     ]
    }
   ],
   "source": [
    "X_q_reshaped.shape\n",
    "print(\"Shape of X_q_reshaped:\", X_q_reshaped.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "08404715",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set input tensor\n",
    "interpreter.set_tensor(input_details[0]['index'], X_q_reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b496fdff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run inference\n",
    "interpreter.invoke()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d2bc85fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the output tensor\n",
    "output_tensor = interpreter.get_tensor(output_details[0]['index'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "30fddab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Create an interpreter for the quantized model\n",
    "interpreter_quantized = tf.lite.Interpreter(model_content=quantized_tflite_model)\n",
    "interpreter_quantized.allocate_tensors()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "e6ddc4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists to store true and predicted pt values\n",
    "true_pts_quantized = []\n",
    "pred_pts_quantized = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "3503449a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measure inference time and process output for the quantized dataset\n",
    "inference_times_quantized = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "93b87143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_q before reshaping: (10, 111, 17)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of X_q before reshaping:\", X_q.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "ee236756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_q before reshaping: (10, 111, 17)\n",
      "Shape of X_q before reshaping: (10, 186, 17)\n",
      "Shape of X_q before reshaping: (10, 142, 17)\n",
      "Shape of X_q before reshaping: (10, 90, 17)\n",
      "Shape of X_q before reshaping: (10, 111, 17)\n",
      "Shape of X_q before reshaping: (10, 195, 17)\n",
      "Shape of X_q before reshaping: (10, 100, 17)\n",
      "Shape of X_q before reshaping: (10, 81, 17)\n",
      "Shape of X_q before reshaping: (10, 130, 17)\n",
      "Shape of X_q before reshaping: (10, 147, 17)\n"
     ]
    }
   ],
   "source": [
    "for X_q in Xs_tf:\n",
    "    # Print the shape of X_q before reshaping\n",
    "    print(\"Shape of X_q before reshaping:\", X_q.shape)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "4c2c805b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming X_q is a list of NumPy arrays\n",
    "max_length = max(X_q.shape[1] for X_q in Xs_tf)  # Update this based on your actual data\n",
    "\n",
    "\n",
    "# Pad sequences to the maximum length\n",
    "X_q_padded = [np.pad(X_q, ((0, 0), (0, max_length - X_q.shape[1]), (0, 0)), 'constant') for X_q in Xs_tf]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "f760c062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_q_padded: (10, 111, 17)\n",
      "Shape of X_q_resized: (1, 111, 17)\n",
      "Shape of X_q_padded: (10, 111, 17)\n",
      "Shape of X_q_resized: (1, 111, 17)\n",
      "Shape of X_q_padded: (10, 111, 17)\n",
      "Shape of X_q_resized: (1, 111, 17)\n",
      "Shape of X_q_padded: (10, 111, 17)\n",
      "Shape of X_q_resized: (1, 111, 17)\n",
      "Shape of X_q_padded: (10, 111, 17)\n",
      "Shape of X_q_resized: (1, 111, 17)\n",
      "Shape of X_q_padded: (10, 111, 17)\n",
      "Shape of X_q_resized: (1, 111, 17)\n",
      "Shape of X_q_padded: (10, 111, 17)\n",
      "Shape of X_q_resized: (1, 111, 17)\n",
      "Shape of X_q_padded: (10, 111, 17)\n",
      "Shape of X_q_resized: (1, 111, 17)\n",
      "Shape of X_q_padded: (10, 111, 17)\n",
      "Shape of X_q_resized: (1, 111, 17)\n",
      "Shape of X_q_padded: (10, 111, 17)\n",
      "Shape of X_q_resized: (1, 111, 17)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Perform inference on the quantized dataset\n",
    "for X_q in Xs_tf:\n",
    "    # Assuming X_q is a NumPy array\n",
    "    target_shape = (1, 111, 17)\n",
    "    \n",
    "    # Determine the length of the second dimension in X_q\n",
    "    current_length = X_q.shape[1]\n",
    "    \n",
    "    \n",
    "    # Pad or truncate X_q to match the target length\n",
    "    if current_length < target_shape[1]:\n",
    "        # Pad with zeros\n",
    "        X_q_padded = np.pad(X_q, ((0, 0), (0, target_shape[1] - current_length), (0, 0)), mode='constant')\n",
    "    elif current_length > target_shape[1]:\n",
    "        # Truncate\n",
    "        X_q_padded = X_q[:, :target_shape[1], :]\n",
    "    else:\n",
    "        # No need to change the shape\n",
    "        X_q_padded = X_q\n",
    "        \n",
    "    # Print the shapes for debugging\n",
    "    print(f\"Shape of X_q_padded: {X_q_padded.shape}\")\n",
    "    \n",
    "    \n",
    "     # Reshape to match the expected shape\n",
    "    X_q_resized = np.resize(X_q_padded, target_shape)\n",
    "    \n",
    "     # Print the shape for debugging\n",
    "    print(f\"Shape of X_q_resized: {X_q_resized.shape}\")\n",
    "    \n",
    "    \n",
    "    # Set input tensor\n",
    "    interpreter_quantized.set_tensor(input_details[0]['index'], X_q_resized)\n",
    "    # Run inference\n",
    "    interpreter_quantized.invoke()\n",
    "    end_time= time.time()\n",
    "    inference_times_quantized.append(end_time - start_time)\n",
    "    \n",
    "    \n",
    "    # Get output tensor\n",
    "    output_tensor_quantized = interpreter_quantized.get_tensor(output_details[0]['index'])\n",
    "\n",
    "     # Process the output as needed\n",
    "    # Assuming a classification task, adjust this based on your output structure\n",
    "    predicted_class_quantized = np.argmax(output_tensor_quantized)\n",
    "    confidence_score_quantized = output_tensor_quantized[0, predicted_class_quantized]\n",
    "    \n",
    "    \n",
    "    # Append true and predicted pt values\n",
    "    true_pt_quantized = ys[ibatch][mask_true_particles, 2]\n",
    "    pred_pt_quantized = confidence_score_quantized  # Adjust based on your output structure\n",
    "    true_pts_quantized.append(true_pt_quantized)\n",
    "    pred_pts_quantized.append(pred_pt_quantized)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "f79a2cb8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (20,) (9260,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[119], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m pred_pt_quantized \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate(pred_pts_quantized)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Plot the histogram\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m plt\u001b[38;5;241m.\u001b[39mhist(\u001b[43mpred_pt_quantized\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43mtrue_pt_quantized\u001b[49m, bins\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m100\u001b[39m))\n\u001b[1;32m      7\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAfter INT8 Quantization\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m plt\u001b[38;5;241m.\u001b[39myscale(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlog\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (20,) (9260,) "
     ]
    }
   ],
   "source": [
    "# Concatenate true and predicted pt values\n",
    "true_pt_quantized = np.concatenate(true_pts_quantized)\n",
    "pred_pt_quantized = np.concatenate(pred_pts_quantized)\n",
    "\n",
    "# Plot the histogram\n",
    "plt.hist(pred_pt_quantized/true_pt_quantized, bins=np.linspace(0, 3, 100))\n",
    "plt.title(\"After INT8 Quantization\")\n",
    "plt.yscale(\"log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5adf197f",
   "metadata": {},
   "source": [
    "**Trying to work out on the above error**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "cc9c0d9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_q_padded: (10, 111, 17)\n",
      "Shape of X_q_reshaped: (1, 111, 17)\n",
      "Shape of true_pt_quantized: (463,)\n",
      "Shape of confidence_score_quantized: (1,)\n",
      "Shape of predicted_class_quantized: ()\n",
      "Shape of pred_pt_quantized: (1,)\n",
      "Shape of X_q_padded: (10, 111, 17)\n",
      "Shape of X_q_reshaped: (1, 111, 17)\n",
      "Shape of true_pt_quantized: (463,)\n",
      "Shape of confidence_score_quantized: (1,)\n",
      "Shape of predicted_class_quantized: ()\n",
      "Shape of pred_pt_quantized: (1,)\n",
      "Shape of X_q_padded: (10, 111, 17)\n",
      "Shape of X_q_reshaped: (1, 111, 17)\n",
      "Shape of true_pt_quantized: (463,)\n",
      "Shape of confidence_score_quantized: (1,)\n",
      "Shape of predicted_class_quantized: ()\n",
      "Shape of pred_pt_quantized: (1,)\n",
      "Shape of X_q_padded: (10, 111, 17)\n",
      "Shape of X_q_reshaped: (1, 111, 17)\n",
      "Shape of true_pt_quantized: (463,)\n",
      "Shape of confidence_score_quantized: (1,)\n",
      "Shape of predicted_class_quantized: ()\n",
      "Shape of pred_pt_quantized: (1,)\n",
      "Shape of X_q_padded: (10, 111, 17)\n",
      "Shape of X_q_reshaped: (1, 111, 17)\n",
      "Shape of true_pt_quantized: (463,)\n",
      "Shape of confidence_score_quantized: (1,)\n",
      "Shape of predicted_class_quantized: ()\n",
      "Shape of pred_pt_quantized: (1,)\n",
      "Shape of X_q_padded: (10, 111, 17)\n",
      "Shape of X_q_reshaped: (1, 111, 17)\n",
      "Shape of true_pt_quantized: (463,)\n",
      "Shape of confidence_score_quantized: (1,)\n",
      "Shape of predicted_class_quantized: ()\n",
      "Shape of pred_pt_quantized: (1,)\n",
      "Shape of X_q_padded: (10, 111, 17)\n",
      "Shape of X_q_reshaped: (1, 111, 17)\n",
      "Shape of true_pt_quantized: (463,)\n",
      "Shape of confidence_score_quantized: (1,)\n",
      "Shape of predicted_class_quantized: ()\n",
      "Shape of pred_pt_quantized: (1,)\n",
      "Shape of X_q_padded: (10, 111, 17)\n",
      "Shape of X_q_reshaped: (1, 111, 17)\n",
      "Shape of true_pt_quantized: (463,)\n",
      "Shape of confidence_score_quantized: (1,)\n",
      "Shape of predicted_class_quantized: ()\n",
      "Shape of pred_pt_quantized: (1,)\n",
      "Shape of X_q_padded: (10, 111, 17)\n",
      "Shape of X_q_reshaped: (1, 111, 17)\n",
      "Shape of true_pt_quantized: (463,)\n",
      "Shape of confidence_score_quantized: (1,)\n",
      "Shape of predicted_class_quantized: ()\n",
      "Shape of pred_pt_quantized: (1,)\n",
      "Shape of X_q_padded: (10, 111, 17)\n",
      "Shape of X_q_reshaped: (1, 111, 17)\n",
      "Shape of true_pt_quantized: (463,)\n",
      "Shape of confidence_score_quantized: (1,)\n",
      "Shape of predicted_class_quantized: ()\n",
      "Shape of pred_pt_quantized: (1,)\n",
      "Final shape of true_pt_quantized: (4630,)\n",
      "Final shape of pred_pt_quantized: (10,)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (10,) (4630,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[127], line 80\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinal shape of pred_pt_quantized: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpred_pt_quantized\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     79\u001b[0m \u001b[38;5;66;03m# Plot the histogram\u001b[39;00m\n\u001b[0;32m---> 80\u001b[0m plt\u001b[38;5;241m.\u001b[39mhist(\u001b[43mpred_pt_quantized\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrue_pt_quantized\u001b[49m, bins\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m100\u001b[39m))\n\u001b[1;32m     81\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAfter INT8 Quantization\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     82\u001b[0m plt\u001b[38;5;241m.\u001b[39myscale(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlog\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (10,) (4630,) "
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize lists to store true and predicted values\n",
    "true_pts_quantized = []\n",
    "pred_pts_quantized = []\n",
    "\n",
    "# Perform inference on the quantized dataset\n",
    "for X_q in Xs_tf:\n",
    "    # Assuming X_q is a NumPy array\n",
    "    target_shape = (1, 111, 17)\n",
    "\n",
    "    # Determine the length of the second dimension in X_q\n",
    "    current_length = X_q.shape[1]\n",
    "\n",
    "    # Pad or truncate X_q to match the target length\n",
    "    if current_length < target_shape[1]:\n",
    "        # Pad with zeros\n",
    "        X_q_padded = np.pad(X_q, ((0, 0), (0, target_shape[1] - current_length), (0, 0)), mode='constant')\n",
    "    elif current_length > target_shape[1]:\n",
    "        # Truncate\n",
    "        X_q_padded = X_q[:, :target_shape[1], :]\n",
    "    else:\n",
    "        # No need to change the shape\n",
    "        X_q_padded = X_q\n",
    "\n",
    "    # Print the shapes for debugging\n",
    "    print(f\"Shape of X_q_padded: {X_q_padded.shape}\")\n",
    "\n",
    "    # Reshape to match the expected shape\n",
    "    X_q_reshaped = np.resize(X_q_padded, target_shape)\n",
    "\n",
    "    # Print the shape for debugging\n",
    "    print(f\"Shape of X_q_reshaped: {X_q_reshaped.shape}\")\n",
    "\n",
    "    # Set input tensor\n",
    "    interpreter_quantized.set_tensor(input_details[0]['index'], X_q_reshaped)\n",
    "\n",
    "    # Run inference\n",
    "    start_time = time.time()\n",
    "    interpreter_quantized.invoke()\n",
    "    end_time = time.time()\n",
    "    inference_times_quantized.append(end_time - start_time)\n",
    "\n",
    "    # Get output tensor\n",
    "    output_tensor_quantized = interpreter_quantized.get_tensor(output_details[0]['index'])\n",
    "\n",
    "    # Process the output as needed\n",
    "    # Assuming a classification task with softmax output\n",
    "    predicted_probabilities_quantized = output_tensor_quantized[0]\n",
    "\n",
    "    # Get the class with the highest probability\n",
    "    predicted_class_quantized = np.argmax(predicted_probabilities_quantized)\n",
    "    confidence_score_quantized = predicted_probabilities_quantized[predicted_class_quantized]\n",
    "\n",
    "\n",
    "    # Append true and predicted pt values\n",
    "    true_pt_quantized = ys[ibatch][mask_true_particles, 2]\n",
    "    pred_pt_quantized = confidence_score_quantized  # Adjust based on your output structure\n",
    "    true_pts_quantized.append(true_pt_quantized)\n",
    "    pred_pts_quantized.append(pred_pt_quantized)\n",
    "    \n",
    "     # Print the shapes for debugging\n",
    "    print(f\"Shape of true_pt_quantized: {true_pt_quantized.shape}\")\n",
    "    print(f\"Shape of confidence_score_quantized: {confidence_score_quantized.shape}\")\n",
    "    print(f\"Shape of predicted_class_quantized: {predicted_class_quantized.shape}\")\n",
    "    print(f\"Shape of pred_pt_quantized: {pred_pt_quantized.shape}\")\n",
    "\n",
    "# After the loop, concatenate true and predicted pt values\n",
    "true_pt_quantized = np.concatenate(true_pts_quantized)\n",
    "pred_pt_quantized = np.concatenate(pred_pts_quantized)\n",
    "\n",
    "# Print the final shapes for debugging\n",
    "print(f\"Final shape of true_pt_quantized: {true_pt_quantized.shape}\")\n",
    "print(f\"Final shape of pred_pt_quantized: {pred_pt_quantized.shape}\")\n",
    "\n",
    "\n",
    "# Plot the histogram\n",
    "plt.hist(pred_pt_quantized / true_pt_quantized, bins=np.linspace(0, 3, 100))\n",
    "plt.title(\"After INT8 Quantization\")\n",
    "plt.yscale(\"log\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "21e2b1d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_q_padded: (10, 111, 17)\n",
      "Shape of X_q_reshaped: (1, 111, 17)\n",
      "Shape of X_q_padded: (10, 111, 17)\n",
      "Shape of X_q_reshaped: (1, 111, 17)\n",
      "Shape of X_q_padded: (10, 111, 17)\n",
      "Shape of X_q_reshaped: (1, 111, 17)\n",
      "Shape of X_q_padded: (10, 111, 17)\n",
      "Shape of X_q_reshaped: (1, 111, 17)\n",
      "Shape of X_q_padded: (10, 111, 17)\n",
      "Shape of X_q_reshaped: (1, 111, 17)\n",
      "Shape of X_q_padded: (10, 111, 17)\n",
      "Shape of X_q_reshaped: (1, 111, 17)\n",
      "Shape of X_q_padded: (10, 111, 17)\n",
      "Shape of X_q_reshaped: (1, 111, 17)\n",
      "Shape of X_q_padded: (10, 111, 17)\n",
      "Shape of X_q_reshaped: (1, 111, 17)\n",
      "Shape of X_q_padded: (10, 111, 17)\n",
      "Shape of X_q_reshaped: (1, 111, 17)\n",
      "Shape of X_q_padded: (10, 111, 17)\n",
      "Shape of X_q_reshaped: (1, 111, 17)\n",
      "Final shape of true_pt_quantized: (80, 8)\n",
      "Final shape of pred_pt_quantized: (270, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34370/3925792354.py:73: RuntimeWarning: divide by zero encountered in divide\n",
      "  plt.hist(pred_pt_quantized[:80] / true_pt_quantized[:, 0], bins=np.linspace(0, 3, 100))\n",
      "/tmp/ipykernel_34370/3925792354.py:73: RuntimeWarning: invalid value encountered in divide\n",
      "  plt.hist(pred_pt_quantized[:80] / true_pt_quantized[:, 0], bins=np.linspace(0, 3, 100))\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize lists to store true and predicted values\n",
    "true_pts_quantized = []\n",
    "pred_pts_quantized = []\n",
    "\n",
    "# Perform inference on the quantized dataset\n",
    "for X_q in Xs_tf:\n",
    "    # Assuming X_q is a NumPy array\n",
    "    target_shape = (1, 111, 17)\n",
    "\n",
    "    # Determine the length of the second dimension in X_q\n",
    "    current_length = X_q.shape[1]\n",
    "\n",
    "    # Pad or truncate X_q to match the target length\n",
    "    if current_length < target_shape[1]:\n",
    "        # Pad with zeros\n",
    "        X_q_padded = np.pad(X_q, ((0, 0), (0, target_shape[1] - current_length), (0, 0)), mode='constant')\n",
    "    elif current_length > target_shape[1]:\n",
    "        # Truncate\n",
    "        X_q_padded = X_q[:, :target_shape[1], :]\n",
    "    else:\n",
    "        # No need to change the shape\n",
    "        X_q_padded = X_q\n",
    "\n",
    "    # Print the shapes for debugging\n",
    "    print(f\"Shape of X_q_padded: {X_q_padded.shape}\")\n",
    "\n",
    "    # Reshape to match the expected shape\n",
    "    X_q_reshaped = np.resize(X_q_padded, target_shape)\n",
    "\n",
    "    # Print the shape for debugging\n",
    "    print(f\"Shape of X_q_reshaped: {X_q_reshaped.shape}\")\n",
    "\n",
    "    # Set input tensor\n",
    "    interpreter_quantized.set_tensor(input_details[0]['index'], X_q_reshaped)\n",
    "\n",
    "    # Run inference\n",
    "    start_time = time.time()\n",
    "    interpreter_quantized.invoke()\n",
    "    end_time = time.time()\n",
    "    inference_times_quantized.append(end_time - start_time)\n",
    "\n",
    "    # Get output tensor\n",
    "    output_tensor_quantized = interpreter_quantized.get_tensor(output_details[0]['index'])\n",
    "\n",
    "    # Process the output as needed\n",
    "    # Assuming a classification task with softmax output\n",
    "    predicted_probabilities_quantized = output_tensor_quantized[0]\n",
    "\n",
    "    # Get the confidence score for the true class\n",
    "    confidence_score_quantized = predicted_probabilities_quantized[ mask_true_particles[0, :111]]\n",
    "\n",
    "    # Get the predicted class (index with the highest probability)\n",
    "    predicted_class_quantized = np.argmax(predicted_probabilities_quantized, axis=1)\n",
    "    \n",
    "    # Extract the first row for boolean indexing\n",
    "    mask_true_particles_row = mask_true_particles[0, :10]\n",
    "    \n",
    "    # Append true and predicted pt values\n",
    "    true_pt_quantized = ys[ibatch][mask_true_particles_row, 2]\n",
    "    pred_pt_quantized = confidence_score_quantized  # Adjust based on your output structure\n",
    "    true_pts_quantized.append(true_pt_quantized)\n",
    "    pred_pts_quantized.append(pred_pt_quantized)\n",
    "    \n",
    "# After the loop, concatenate true and predicted pt values\n",
    "true_pt_quantized = np.concatenate(true_pts_quantized)\n",
    "pred_pt_quantized = np.concatenate(pred_pts_quantized)\n",
    "\n",
    "# Print the final shapes for debugging\n",
    "print(f\"Final shape of true_pt_quantized: {true_pt_quantized.shape}\")\n",
    "print(f\"Final shape of pred_pt_quantized: {pred_pt_quantized.shape}\")\n",
    "\n",
    "# Plot the histogram\n",
    "plt.hist(pred_pt_quantized[:80] / true_pt_quantized[:, 0], bins=np.linspace(0, 3, 100))\n",
    "plt.title(\"After INT8 Quantization\")\n",
    "plt.yscale(\"log\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "d9fecfc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34370/2572463005.py:6: RuntimeWarning: divide by zero encountered in divide\n",
      "  plt.hist(pred_pt_quantized / true_pt_quantized_repeated, bins=np.linspace(0, 3, 100))\n",
      "/tmp/ipykernel_34370/2572463005.py:6: RuntimeWarning: invalid value encountered in divide\n",
      "  plt.hist(pred_pt_quantized / true_pt_quantized_repeated, bins=np.linspace(0, 3, 100))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[ 19.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         113.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
       "        [ 19.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         106.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
       "        [ 19.,   0.,  20.,  29.,  20.,  17.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,  10.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  17.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
       "        [ 19.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,  15.,   0.,   0.,   0.,   0.,  10.,   0.,   0.,   0.,   0.,\n",
       "          15.,   0.,   0.,   0.,   0.,   0.,  20.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,  20.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,  18.,   0.,   0.,   0.,   0.,  15.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
       "        [ 19.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          35.,   0.,   0.,   0.,   0.,   0.,   0.,  15.,   0.,   0.,  17.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  18.,   0.,   0.,\n",
       "           0.,   0.,   0.,  20.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
       "        [ 19.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,  10.,   0.,   0.,  20.,  14.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,  15.,   0.,   0.,   0.,   0.,\n",
       "           0.,  15.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
       "        [ 19.,  35.,   0.,  34.,  27.,   0.,  17.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
       "        [ 19.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          20.,   0.,   0.,   0.,   0.,  42.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          51.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.]]),\n",
       " array([0.        , 0.03030303, 0.06060606, 0.09090909, 0.12121212,\n",
       "        0.15151515, 0.18181818, 0.21212121, 0.24242424, 0.27272727,\n",
       "        0.3030303 , 0.33333333, 0.36363636, 0.39393939, 0.42424242,\n",
       "        0.45454545, 0.48484848, 0.51515152, 0.54545455, 0.57575758,\n",
       "        0.60606061, 0.63636364, 0.66666667, 0.6969697 , 0.72727273,\n",
       "        0.75757576, 0.78787879, 0.81818182, 0.84848485, 0.87878788,\n",
       "        0.90909091, 0.93939394, 0.96969697, 1.        , 1.03030303,\n",
       "        1.06060606, 1.09090909, 1.12121212, 1.15151515, 1.18181818,\n",
       "        1.21212121, 1.24242424, 1.27272727, 1.3030303 , 1.33333333,\n",
       "        1.36363636, 1.39393939, 1.42424242, 1.45454545, 1.48484848,\n",
       "        1.51515152, 1.54545455, 1.57575758, 1.60606061, 1.63636364,\n",
       "        1.66666667, 1.6969697 , 1.72727273, 1.75757576, 1.78787879,\n",
       "        1.81818182, 1.84848485, 1.87878788, 1.90909091, 1.93939394,\n",
       "        1.96969697, 2.        , 2.03030303, 2.06060606, 2.09090909,\n",
       "        2.12121212, 2.15151515, 2.18181818, 2.21212121, 2.24242424,\n",
       "        2.27272727, 2.3030303 , 2.33333333, 2.36363636, 2.39393939,\n",
       "        2.42424242, 2.45454545, 2.48484848, 2.51515152, 2.54545455,\n",
       "        2.57575758, 2.60606061, 2.63636364, 2.66666667, 2.6969697 ,\n",
       "        2.72727273, 2.75757576, 2.78787879, 2.81818182, 2.84848485,\n",
       "        2.87878788, 2.90909091, 2.93939394, 2.96969697, 3.        ]),\n",
       " <a list of 8 BarContainer objects>)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAigAAAGdCAYAAAA44ojeAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAdTklEQVR4nO3df3TV9X348Vf4kYQqCUJHQo5Bs9aJPygqCg16VqtZM8vXA6ecVXZYD7NO2i50Rc7RwTkC7Wob9ViluFTargXddLauB7rqinOh4loDasANrYfalmlam7AdS65GCYx8vn/0eLsoKKE3ue+Qx+Oczznkc9/3w+u+zz2X57m5ISVZlmUBAJCQUcUeAADgzQQKAJAcgQIAJEegAADJESgAQHIECgCQHIECACRHoAAAyRlT7AGOR19fX7z00ksxfvz4KCkpKfY4AMAxyLIsXnnllaipqYlRo97+PZJhGSgvvfRS1NbWFnsMAOA4dHR0xKmnnvq2a4ZloIwfPz4ifvMAKyoqijwNAHAscrlc1NbW5v8dfzvDMlDe+LZORUWFQAGAYeZYPp7hQ7IAQHIECgCQHIECACRHoAAAyREoAEByBAoAkByBAgAkR6AAAMkRKABAcgQKAJAcgQIAJEegAADJESgAQHIECgCQHIECQ+T0FQ8VewSAYUOgAADJESgAQHIECgCQHIECACRHoAAAyREoAEByBAoAkByBAgAkR6AAAMkRKABAcgQKAJAcgQIAJEegAADJESgAQHIECgCQHIECACRHoAAAyREoAEByBAoAkByBAgAkR6AAAMkRKABAcgQKAJAcgQIAJEegAADJESgAQHIECgCQHIECACRHoAAAyREoAEByBAoAkByBAgAkR6AAAMkRKABAcgQKAJAcgQIAJGfAgfLYY4/FlVdeGTU1NVFSUhKbN2/ud3uWZbF69eqYMmVKjBs3LhoaGuL555/vt+bll1+ORYsWRUVFRUyYMCGuueaaePXVV3+nBwIAnDgGHCg9PT0xY8aMaGlpOeLtt956a6xbty7Wr18fO3bsiJNOOikaGxvjwIED+TWLFi2KZ599Nh555JF48MEH47HHHoslS5Yc/6MAAE4oYwZ6hyuuuCKuuOKKI96WZVmsXbs2brzxxpg3b15ERNxzzz1RVVUVmzdvjoULF8Zzzz0XW7ZsiSeffDIuvPDCiIi4884748Mf/nDcdtttUVNT8zs8HADgRFDQz6Ds3bs3Ojs7o6GhIX+usrIyZs+eHW1tbRER0dbWFhMmTMjHSUREQ0NDjBo1Knbs2HHE6/b29kYul+t3AAAnroIGSmdnZ0REVFVV9TtfVVWVv62zszMmT57c7/YxY8bExIkT82verLm5OSorK/NHbW1tIccGABIzLH6KZ+XKldHd3Z0/Ojo6ij0SADCIChoo1dXVERHR1dXV73xXV1f+turq6ti3b1+/2//3f/83Xn755fyaNysrK4uKiop+BwBw4ipooNTV1UV1dXW0trbmz+VyudixY0fU19dHRER9fX3s378/2tvb82u2bt0afX19MXv27EKOAwAMUwP+KZ5XX301fvrTn+a/3rt3bzz99NMxceLEmDp1aixbtixuuummOOOMM6Kuri5WrVoVNTU1MX/+/IiIOOuss+KP//iP49prr43169fHoUOHYunSpbFw4UI/wQMARMRxBMpTTz0VH/zgB/NfL1++PCIiFi9eHBs3bowbbrghenp6YsmSJbF///645JJLYsuWLVFeXp6/z7333htLly6Nyy+/PEaNGhULFiyIdevWFeDhAAAngpIsy7JiDzFQuVwuKisro7u72+dRGDZOX/FQ/NfNc4s9BkDRDOTf72HxUzwAwMgiUACA5AgUACA5AgUASI5AAQCSI1AAgOQIFAAgOQIFAEiOQAEAkiNQAIDkCBQAIDkCBQBIjkABAJIjUACA5AgUACA5AgUASI5AAQCSI1AAgOQIFAAgOQIFAEiOQAEAkiNQAIDkCBQAIDkCBQBIjkABAJIjUACA5AgUACA5AgUASI5AAQCSI1AAgOQIFAAgOQIFAEiOQAEAkiNQAIDkCBQAIDkCBQBIjkABAJIjUACA5AgUACA5AgUASI5AAQCSI1AAgOQIFAAgOQIFAEiOQAEAkiNQAIDkCBQAIDkCBQBIjkABAJIjUACA5AgUACA5BQ+Uw4cPx6pVq6Kuri7GjRsX73nPe+Lzn/98ZFmWX5NlWaxevTqmTJkS48aNi4aGhnj++ecLPQoAMEwVPFBuueWWuOuuu+Jv//Zv47nnnotbbrklbr311rjzzjvza2699dZYt25drF+/Pnbs2BEnnXRSNDY2xoEDBwo9DgAwDI0p9AUff/zxmDdvXsydOzciIk4//fT4x3/8x3jiiSci4jfvnqxduzZuvPHGmDdvXkRE3HPPPVFVVRWbN2+OhQsXFnokAGCYKfg7KHPmzInW1tb4yU9+EhER//Ef/xE//OEP44orroiIiL1790ZnZ2c0NDTk71NZWRmzZ8+Otra2I16zt7c3crlcvwMAOHEV/B2UFStWRC6Xi2nTpsXo0aPj8OHD8YUvfCEWLVoUERGdnZ0REVFVVdXvflVVVfnb3qy5uTk+97nPFXpUACBRBX8H5dvf/nbce++9cd9998XOnTvj7rvvjttuuy3uvvvu477mypUro7u7O390dHQUcGIAIDUFfwfl+uuvjxUrVuQ/SzJ9+vR44YUXorm5ORYvXhzV1dUREdHV1RVTpkzJ36+rqyvOO++8I16zrKwsysrKCj0qAJCogr+D8tprr8WoUf0vO3r06Ojr64uIiLq6uqiuro7W1tb87blcLnbs2BH19fWFHgcAGIYK/g7KlVdeGV/4whdi6tSpcc4558SuXbvi9ttvj49//OMREVFSUhLLli2Lm266Kc4444yoq6uLVatWRU1NTcyfP7/Q4wAAw1DBA+XOO++MVatWxV/+5V/Gvn37oqamJj7xiU/E6tWr82tuuOGG6OnpiSVLlsT+/fvjkksuiS1btkR5eXmhxwEAhqGS7P/+F6/DRC6Xi8rKyuju7o6KiopijwPH5PQVD8V/3Ty32GMAFM1A/v32u3gAgOQIFAAgOQIFAEiOQAEAkiNQAIDkCBQAIDkCBQBIjkABAJIjUACA5AgUACA5AgUASI5AAQCSI1AAgOQIFAAgOQIFAEiOQAEAkiNQAIDkCBQAIDkCBQBIjkABAJIjUACA5AgUACA5AgUASI5AAQCSI1AAgOQIFAAgOQIFAEiOQAEAkiNQAIDkCBQAIDkCBQBIjkABAJIjUACA5AgUACA5AgUASI5AAQCSI1AAgOQIFAAgOQIFAEiOQAEAkiNQAIDkCBQAIDkCBQBIjkABAJIjUACA5AgUACA5AgUASI5AAQCSI1AAgOQIFAAgOQIFAEjOoATKL3/5y/izP/uzmDRpUowbNy6mT58eTz31VP72LMti9erVMWXKlBg3blw0NDTE888/PxijAADDUMED5de//nVcfPHFMXbs2Pj+978fP/7xj+NLX/pSnHLKKfk1t956a6xbty7Wr18fO3bsiJNOOikaGxvjwIEDhR4HABiGxhT6grfcckvU1tbGhg0b8ufq6uryf86yLNauXRs33nhjzJs3LyIi7rnnnqiqqorNmzfHwoULCz0SADDMFPwdlH/+53+OCy+8MP7kT/4kJk+eHOeff358/etfz9++d+/e6OzsjIaGhvy5ysrKmD17drS1tR3xmr29vZHL5fodAMCJq+CB8vOf/zzuuuuuOOOMM+Lhhx+OT33qU/FXf/VXcffdd0dERGdnZ0REVFVV9btfVVVV/rY3a25ujsrKyvxRW1tb6LEBgIQUPFD6+vriggsuiC9+8Ytx/vnnx5IlS+Laa6+N9evXH/c1V65cGd3d3fmjo6OjgBMDAKkpeKBMmTIlzj777H7nzjrrrHjxxRcjIqK6ujoiIrq6uvqt6erqyt/2ZmVlZVFRUdHvAABOXAUPlIsvvjj27NnT79xPfvKTOO200yLiNx+Yra6ujtbW1vztuVwuduzYEfX19YUeBwAYhgr+UzzXXXddzJkzJ774xS/GRz/60XjiiSfia1/7Wnzta1+LiIiSkpJYtmxZ3HTTTXHGGWdEXV1drFq1KmpqamL+/PmFHgcAGIYKHigXXXRRbNq0KVauXBl/8zd/E3V1dbF27dpYtGhRfs0NN9wQPT09sWTJkti/f39ccsklsWXLligvLy/0OADAMFSSZVlW7CEGKpfLRWVlZXR3d/s8CsPG6Sseiv+6eW6xxwAomoH8++138QAAyREoAEByBAoAkByBAgAkR6AAAMkRKABAcgQKAJAcgQIAJEegAADJESgAQHIECgCQHIECACRHoAAAyREoAEByBAoAkByBAgAkR6AAAMkRKABAcgQKAJAcgQIAJEegAADJEShQBJ/97GeLPQJA0gQKAJAcgQIAJEegAADJESgAQHIECgCQHIECACRHoAAAyREoAEByBAoAkByBAgAkR6AAAMkRKABAcgQKAJAcgQIAJEegAADJESgAQHIECgCQHIECACRHoAAAyREoAEByBAoAkByBAgAkR6AAAMkRKABAcgQKAJAcgQIAJEegAADJESgAQHIECgCQnEEPlJtvvjlKSkpi2bJl+XMHDhyIpqammDRpUpx88smxYMGC6OrqGuxRAIBhYlAD5cknn4yvfvWr8b73va/f+euuuy6+973vxQMPPBDbtm2Ll156KT7ykY8M5igAwDAyaIHy6quvxqJFi+LrX/96nHLKKfnz3d3d8Y1vfCNuv/32uOyyy2LmzJmxYcOGePzxx2P79u2DNQ4AMIwMWqA0NTXF3Llzo6Ghod/59vb2OHToUL/z06ZNi6lTp0ZbW9tgjQMADCNjBuOi999/f+zcuTOefPLJt9zW2dkZpaWlMWHChH7nq6qqorOz84jX6+3tjd7e3vzXuVyuoPMCAGkp+DsoHR0d8ZnPfCbuvffeKC8vL8g1m5ubo7KyMn/U1tYW5LoAQJoKHijt7e2xb9++uOCCC2LMmDExZsyY2LZtW6xbty7GjBkTVVVVcfDgwdi/f3+/+3V1dUV1dfURr7ly5cro7u7OHx0dHYUeGwBISMG/xXP55ZfH7t27+527+uqrY9q0afHXf/3XUVtbG2PHjo3W1tZYsGBBRETs2bMnXnzxxaivrz/iNcvKyqKsrKzQowIAiSp4oIwfPz7OPffcfudOOumkmDRpUv78NddcE8uXL4+JEydGRUVFfPrTn476+vp4//vfX+hxAIBhaFA+JPtO7rjjjhg1alQsWLAgent7o7GxMb7yla8UYxQAIEFDEiiPPvpov6/Ly8ujpaUlWlpahuKvBwCGGb+LBwBIjkABAJIjUACA5AgUACA5AgUASI5AAQCSI1AAgOQIFAAgOQIFAEiOQIEh1vLJrcUeASB5AgUASI5AAQCSI1AGwS9W/HuxRwCAYU2gAADJESgAQHIECgCQHIECACRHoAAAyREoAEByBAoAkByBAgAkR6AAAMkRKABAcgQKAJAcgQIAJEegAADJESgAQHIECgCQHIFSQNPvnl7sEQDghCBQAIDkCBQAIDkCBQBIjkABAJIjUACA5AgUACA5AgUASI5AAQCSI1AAgOQIFAAgOQIFAEiOQAEAkiNQAIDkCBQAIDkCBQBIjkABAJIjUACA5AgUACA5AgUASI5AAQCSI1AAgOQIFAAgOQIFAEhOwQOlubk5Lrroohg/fnxMnjw55s+fH3v27Om35sCBA9HU1BSTJk2Kk08+ORYsWBBdXV2FHgUAGKYKHijbtm2Lpqam2L59ezzyyCNx6NCh+NCHPhQ9PT35Ndddd11873vfiwceeCC2bdsWL730UnzkIx8p9CgAwDA1ptAX3LJlS7+vN27cGJMnT4729vb4wz/8w+ju7o5vfOMbcd9998Vll10WEREbNmyIs846K7Zv3x7vf//7Cz0SADDMDPpnULq7uyMiYuLEiRER0d7eHocOHYqGhob8mmnTpsXUqVOjra3tiNfo7e2NXC7X7wAATlyDGih9fX2xbNmyuPjii+Pcc8+NiIjOzs4oLS2NCRMm9FtbVVUVnZ2dR7xOc3NzVFZW5o/a2trBHBtgxGj55NZijwBHNKiB0tTUFM8880zcf//9v9N1Vq5cGd3d3fmjo6OjQBMCACkq+GdQ3rB06dJ48MEH47HHHotTTz01f766ujoOHjwY+/fv7/cuSldXV1RXVx/xWmVlZVFWVjZYowIAiSn4OyhZlsXSpUtj06ZNsXXr1qirq+t3+8yZM2Ps2LHR2tqaP7dnz5548cUXo76+vtDjHJ/PVkbLJ7fGL1b8e7EnAYARqeDvoDQ1NcV9990X3/3ud2P8+PH5z5VUVlbGuHHjorKyMq655ppYvnx5TJw4MSoqKuLTn/501NfX+wkeACAiBiFQ7rrrroiIuPTSS/ud37BhQ/z5n/95RETccccdMWrUqFiwYEH09vZGY2NjfOUrXyn0KADAMFXwQMmy7B3XlJeXR0tLS7S0tBT6rwcATgB+Fw8AkByBAgAkR6AMsel3Ty/2CACQPIECACRHoAAAyREoAEByBAoAkByBAgAkR6AAAMkRKAwLz007q9gjUGRfuur/FXsEYAgJFAAgOQIFAEiOQIETiG+DACcKgQIAJEegAADJESgAQHIECgCQHIECACRHoAAAyREoAEByBAoAkByBAgAkR6AAAMkRKABAcgQKbzH97unFHmHE8Tt0APoTKABAcgQKAJAcgQIAJEegAADJESgAQHIECgCQHIECACRHoAAAyREoAEByBAoAkByBAgAkR6AAAMkRKABAcgQKAJAcgQIAJEegAADJESgAQHIECgCQHIECACRHoAAAyREoAEByBAoAkByBAgAkR6AAAMkRKABAcgQKAJCcogZKS0tLnH766VFeXh6zZ8+OJ554opjjAACJKFqgfOtb34rly5fHmjVrYufOnTFjxoxobGyMffv2FWskACARRQuU22+/Pa699tq4+uqr4+yzz47169fHu971rvjmN79ZrJEAgESMKcZfevDgwWhvb4+VK1fmz40aNSoaGhqira3tLet7e3ujt7c3/3V3d3dERORyucEZsDeL1w/2xCu9Ywf0dxx+/XDkcrl4pbfnqPd7Y03KUpzx1cPpzTRQfb2vRS6Xi9cP9kRvb2+/x3Pg0KGCPL5CXSdFJ/JjK6bXDx799QoK7Y3nWpZl77w4K4Jf/vKXWURkjz/+eL/z119/fTZr1qy3rF+zZk0WEQ6Hw+FwOE6Ao6Oj4x1boSjvoAzUypUrY/ny5fmv+/r64uWXX45JkyZFSUlJwf6eXC4XtbW10dHRERUVFQW77onIXg2M/Tp29urY2auBsV/HbrD2KsuyeOWVV6KmpuYd1xYlUN797nfH6NGjo6urq9/5rq6uqK6ufsv6srKyKCsr63duwoQJgzZfRUWFJ+8xslcDY7+Onb06dvZqYOzXsRuMvaqsrDymdUX5kGxpaWnMnDkzWltb8+f6+vqitbU16uvrizESAJCQon2LZ/ny5bF48eK48MILY9asWbF27dro6emJq6++ulgjAQCJKFqgXHXVVfHf//3fsXr16ujs7IzzzjsvtmzZElVVVcUaKcrKymLNmjVv+XYSb2WvBsZ+HTt7dezs1cDYr2OXwl6VZNmx/KwPAMDQ8bt4AIDkCBQAIDkCBQBIjkABAJIz4gKlpaUlTj/99CgvL4/Zs2fHE0888bbrH3jggZg2bVqUl5fH9OnT41/+5V+GaNLiG8hebdy4MUpKSvod5eXlQzht8Tz22GNx5ZVXRk1NTZSUlMTmzZvf8T6PPvpoXHDBBVFWVhbvfe97Y+PGjYM+ZyoGul+PPvroW55bJSUl0dnZOTQDF0lzc3NcdNFFMX78+Jg8eXLMnz8/9uzZ8473G6mvWcezXyP1deuuu+6K973vffn/hK2+vj6+//3vv+19ivG8GlGB8q1vfSuWL18ea9asiZ07d8aMGTOisbEx9u3bd8T1jz/+ePzpn/5pXHPNNbFr166YP39+zJ8/P5555pkhnnzoDXSvIn7zPw7+6le/yh8vvPDCEE5cPD09PTFjxoxoaWk5pvV79+6NuXPnxgc/+MF4+umnY9myZfEXf/EX8fDDDw/ypGkY6H69Yc+ePf2eX5MnTx6kCdOwbdu2aGpqiu3bt8cjjzwShw4dig996EPR09Nz1PuM5Nes49mviJH5unXqqafGzTffHO3t7fHUU0/FZZddFvPmzYtnn332iOuL9rwqzK//Gx5mzZqVNTU15b8+fPhwVlNTkzU3Nx9x/Uc/+tFs7ty5/c7Nnj07+8QnPjGoc6ZgoHu1YcOGrLKycoimS1dEZJs2bXrbNTfccEN2zjnn9Dt31VVXZY2NjYM4WZqOZb9+8IMfZBGR/frXvx6SmVK1b9++LCKybdu2HXXNSH7NerNj2S+vW791yimnZH/3d393xNuK9bwaMe+gHDx4MNrb26OhoSF/btSoUdHQ0BBtbW1HvE9bW1u/9RERjY2NR11/ojievYqIePXVV+O0006L2trat63xkW6kPq9+V+edd15MmTIl/uiP/ih+9KMfFXucIdfd3R0RERMnTjzqGs+t3zqW/YrwunX48OG4//77o6en56i/aqZYz6sREyj/8z//E4cPH37L/1RbVVV11O9ld3Z2Dmj9ieJ49urMM8+Mb37zm/Hd7343/uEf/iH6+vpizpw58Ytf/GIoRh5Wjva8yuVy8frrrxdpqnRNmTIl1q9fH9/5znfiO9/5TtTW1sall14aO3fuLPZoQ6avry+WLVsWF198cZx77rlHXTdSX7Pe7Fj3ayS/bu3evTtOPvnkKCsri09+8pOxadOmOPvss4+4tljPq6L9V/ecWOrr6/vV95w5c+Kss86Kr371q/H5z3++iJMx3J155plx5pln5r+eM2dO/OxnP4s77rgj/v7v/76Ikw2dpqameOaZZ+KHP/xhsUcZFo51v0by69aZZ54ZTz/9dHR3d8c//dM/xeLFi2Pbtm1HjZRiGDHvoLz73e+O0aNHR1dXV7/zXV1dUV1dfcT7VFdXD2j9ieJ49urNxo4dG+eff3789Kc/HYwRh7WjPa8qKipi3LhxRZpqeJk1a9aIeW4tXbo0HnzwwfjBD34Qp5566tuuHamvWf/XQPbrzUbS61ZpaWm8973vjZkzZ0Zzc3PMmDEjvvzlLx9xbbGeVyMmUEpLS2PmzJnR2tqaP9fX1xetra1H/b5bfX19v/UREY888shR158ojmev3uzw4cOxe/fumDJlymCNOWyN1OdVIT399NMn/HMry7JYunRpbNq0KbZu3Rp1dXXveJ+R/Nw6nv16s5H8utXX1xe9vb1HvK1oz6tB/QhuYu6///6srKws27hxY/bjH/84W7JkSTZhwoSss7Mzy7Is+9jHPpatWLEiv/5HP/pRNmbMmOy2227LnnvuuWzNmjXZ2LFjs927dxfrIQyZge7V5z73uezhhx/Ofvazn2Xt7e3ZwoULs/Ly8uzZZ58t1kMYMq+88kq2a9eubNeuXVlEZLfffnu2a9eu7IUXXsiyLMtWrFiRfexjH8uv//nPf569613vyq6//vrsueeey1paWrLRo0dnW7ZsKdZDGFID3a877rgj27x5c/b8889nu3fvzj7zmc9ko0aNyv7t3/6tWA9hSHzqU5/KKisrs0cffTT71a9+lT9ee+21/BqvWb91PPs1Ul+3VqxYkW3bti3bu3dv9p//+Z/ZihUrspKSkuxf//VfsyxL53k1ogIly7LszjvvzKZOnZqVlpZms2bNyrZv356/7QMf+EC2ePHifuu//e1vZ3/wB3+QlZaWZuecc0720EMPDfHExTOQvVq2bFl+bVVVVfbhD38427lzZxGmHnpv/Bjsm4839mfx4sXZBz7wgbfc57zzzstKS0uz3//93882bNgw5HMXy0D365Zbbsne8573ZOXl5dnEiROzSy+9NNu6dWtxhh9CR9qjiOj3XPGa9VvHs18j9XXr4x//eHbaaadlpaWl2e/93u9ll19+eT5Osiyd51VJlmXZ4L5HAwAwMCPmMygAwPAhUACA5AgUACA5AgUASI5AAQCSI1AAgOQIFAAgOQIFAEiOQAEAkiNQAIDkCBQAIDkCBQBIzv8H/EAriGeOk9QAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Repeat the true_pt_quantized to match or exceed the length of pred_pt_quantized\n",
    "repetition_factor = (pred_pt_quantized.shape[0] + true_pt_quantized.shape[0] - 1) // true_pt_quantized.shape[0]\n",
    "true_pt_quantized_repeated = np.repeat(true_pt_quantized, repetition_factor, axis=0)[:pred_pt_quantized.shape[0]]\n",
    "\n",
    "# Perform element-wise division\n",
    "plt.hist(pred_pt_quantized / true_pt_quantized_repeated, bins=np.linspace(0, 3, 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "6239e21a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34370/3367825139.py:1: RuntimeWarning: divide by zero encountered in divide\n",
      "  plt.hist(pred_pt_quantized[:80] / true_pt_quantized[:, 0], bins=np.linspace(0, 3, 50), label='Method 1')\n",
      "/tmp/ipykernel_34370/3367825139.py:1: RuntimeWarning: invalid value encountered in divide\n",
      "  plt.hist(pred_pt_quantized[:80] / true_pt_quantized[:, 0], bins=np.linspace(0, 3, 50), label='Method 1')\n",
      "/tmp/ipykernel_34370/3367825139.py:2: RuntimeWarning: divide by zero encountered in divide\n",
      "  plt.hist(pred_pt_quantized / true_pt_quantized_repeated, bins=np.linspace(0, 3, 50), label='Method 2', alpha=0.5)\n",
      "/tmp/ipykernel_34370/3367825139.py:2: RuntimeWarning: invalid value encountered in divide\n",
      "  plt.hist(pred_pt_quantized / true_pt_quantized_repeated, bins=np.linspace(0, 3, 50), label='Method 2', alpha=0.5)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(pred_pt_quantized[:80] / true_pt_quantized[:, 0], bins=np.linspace(0, 3, 50), label='Method 1')\n",
    "plt.hist(pred_pt_quantized / true_pt_quantized_repeated, bins=np.linspace(0, 3, 50), label='Method 2', alpha=0.5)\n",
    "plt.title(\"Comparison of Methods\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09e200c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e5befd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15d1cb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7097369c",
   "metadata": {},
   "source": [
    "## Dynamic Range Quantization for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "ba2df2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.lite.python import lite_constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "f333ae1a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "For full integer quantization, a `representative_dataset` must be specified.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[165], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m converter\u001b[38;5;241m.\u001b[39minference_input_type \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mint8\n\u001b[1;32m     10\u001b[0m converter\u001b[38;5;241m.\u001b[39minference_output_type \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mint8\n\u001b[0;32m---> 12\u001b[0m tflite_model_dynamic_range \u001b[38;5;241m=\u001b[39m \u001b[43mconverter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Save the quantized model\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquantized_model_dynamic_range.tflite\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/lite/python/lite.py:1125\u001b[0m, in \u001b[0;36m_export_metrics.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1122\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(convert_func)\n\u001b[1;32m   1123\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1124\u001b[0m   \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m-> 1125\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_and_export_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/lite/python/lite.py:1077\u001b[0m, in \u001b[0;36mTFLiteConverterBase._convert_and_export_metrics\u001b[0;34m(self, convert_func, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1066\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Wraps around convert function to export metrics.\u001b[39;00m\n\u001b[1;32m   1067\u001b[0m \n\u001b[1;32m   1068\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1074\u001b[0m \u001b[38;5;124;03m  The decorator to wrap the convert function.\u001b[39;00m\n\u001b[1;32m   1075\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1076\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_increase_conversion_attempt_metric()\n\u001b[0;32m-> 1077\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_conversion_params_metric\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1078\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mprocess_time()\n\u001b[1;32m   1079\u001b[0m result \u001b[38;5;241m=\u001b[39m convert_func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/lite/python/lite.py:907\u001b[0m, in \u001b[0;36mTFLiteConverterBase._save_conversion_params_metric\u001b[0;34m(self, graph_def, inference_type, inference_input_type)\u001b[0m\n\u001b[1;32m    904\u001b[0m converter_kwargs\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_base_converter_args())\n\u001b[1;32m    906\u001b[0m \u001b[38;5;66;03m# Optimization parameters.\u001b[39;00m\n\u001b[0;32m--> 907\u001b[0m quant_mode \u001b[38;5;241m=\u001b[39m \u001b[43mQuantizationMode\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    908\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    909\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_spec\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    910\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepresentative_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    911\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgraph_def\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    912\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_experimental_disable_per_channel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    913\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexperimental_new_dynamic_range_quantizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    914\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_experimental_low_bit_qat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    915\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_experimental_full_integer_quantization_bias_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    916\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_experimental_variable_quantization\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    918\u001b[0m converter_kwargs\u001b[38;5;241m.\u001b[39mupdate({\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf_version\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata\u001b[38;5;241m.\u001b[39menvironment\u001b[38;5;241m.\u001b[39mtensorflowVersion,\n\u001b[1;32m    920\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapi_version\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata\u001b[38;5;241m.\u001b[39menvironment\u001b[38;5;241m.\u001b[39mapiVersion,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    937\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactivations_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: quant_mode\u001b[38;5;241m.\u001b[39mactivations_type(),\n\u001b[1;32m    938\u001b[0m })\n\u001b[1;32m    939\u001b[0m converter_kwargs\u001b[38;5;241m.\u001b[39mupdate(\n\u001b[1;32m    940\u001b[0m     quant_mode\u001b[38;5;241m.\u001b[39mconverter_flags(inference_type, inference_input_type)\n\u001b[1;32m    941\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/lite/python/lite.py:267\u001b[0m, in \u001b[0;36mQuantizationMode.__init__\u001b[0;34m(self, optimizations, target_spec, representative_dataset, graph_def, disable_per_channel, experimental_new_dynamic_range_quantizer, experimental_low_bit_qat, full_integer_quantization_bias_type, experimental_mlir_variable_quantization)\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_representative_dataset \u001b[38;5;241m=\u001b[39m representative_dataset\n\u001b[1;32m    265\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph_def \u001b[38;5;241m=\u001b[39m graph_def\n\u001b[0;32m--> 267\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_int8_required\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_disable_per_channel \u001b[38;5;241m=\u001b[39m disable_per_channel\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_new_dynamic_range_quantizer \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    271\u001b[0m     experimental_new_dynamic_range_quantizer\n\u001b[1;32m    272\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/lite/python/lite.py:498\u001b[0m, in \u001b[0;36mQuantizationMode._validate_int8_required\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    493\u001b[0m \u001b[38;5;66;03m# Check if representative_dataset is specified.\u001b[39;00m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    495\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_representative_dataset\n\u001b[1;32m    496\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_quantization_aware_training()\n\u001b[1;32m    497\u001b[0m ):\n\u001b[0;32m--> 498\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    499\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFor full integer quantization, a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    500\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`representative_dataset` must be specified.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    501\u001b[0m   )\n\u001b[1;32m    503\u001b[0m \u001b[38;5;66;03m# Update represenative dataset to the expected format.\u001b[39;00m\n\u001b[1;32m    504\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_representative_dataset:\n",
      "\u001b[0;31mValueError\u001b[0m: For full integer quantization, a `representative_dataset` must be specified."
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Convert the model to TensorFlow Lite format with dynamic range quantization\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]  # Use DEFAULT for dynamic range quantization\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.inference_input_type = tf.int8\n",
    "converter.inference_output_type = tf.int8\n",
    "\n",
    "tflite_model_dynamic_range = converter.convert()\n",
    "\n",
    "# Save the quantized model\n",
    "with open('quantized_model_dynamic_range.tflite', 'wb') as f:\n",
    "    f.write(tflite_model_dynamic_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "d14cd2ea",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "For full integer quantization, a `representative_dataset` must be specified.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[164], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tflite_model_dynamic_range \u001b[38;5;241m=\u001b[39m \u001b[43mconverter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Save the quantized model\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquantized_model_dynamic_range.tflite\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/lite/python/lite.py:1125\u001b[0m, in \u001b[0;36m_export_metrics.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1122\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(convert_func)\n\u001b[1;32m   1123\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1124\u001b[0m   \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m-> 1125\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_and_export_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/lite/python/lite.py:1077\u001b[0m, in \u001b[0;36mTFLiteConverterBase._convert_and_export_metrics\u001b[0;34m(self, convert_func, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1066\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Wraps around convert function to export metrics.\u001b[39;00m\n\u001b[1;32m   1067\u001b[0m \n\u001b[1;32m   1068\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1074\u001b[0m \u001b[38;5;124;03m  The decorator to wrap the convert function.\u001b[39;00m\n\u001b[1;32m   1075\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1076\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_increase_conversion_attempt_metric()\n\u001b[0;32m-> 1077\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_conversion_params_metric\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1078\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mprocess_time()\n\u001b[1;32m   1079\u001b[0m result \u001b[38;5;241m=\u001b[39m convert_func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/lite/python/lite.py:907\u001b[0m, in \u001b[0;36mTFLiteConverterBase._save_conversion_params_metric\u001b[0;34m(self, graph_def, inference_type, inference_input_type)\u001b[0m\n\u001b[1;32m    904\u001b[0m converter_kwargs\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_base_converter_args())\n\u001b[1;32m    906\u001b[0m \u001b[38;5;66;03m# Optimization parameters.\u001b[39;00m\n\u001b[0;32m--> 907\u001b[0m quant_mode \u001b[38;5;241m=\u001b[39m \u001b[43mQuantizationMode\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    908\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    909\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_spec\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    910\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepresentative_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    911\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgraph_def\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    912\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_experimental_disable_per_channel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    913\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexperimental_new_dynamic_range_quantizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    914\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_experimental_low_bit_qat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    915\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_experimental_full_integer_quantization_bias_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    916\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_experimental_variable_quantization\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    918\u001b[0m converter_kwargs\u001b[38;5;241m.\u001b[39mupdate({\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf_version\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata\u001b[38;5;241m.\u001b[39menvironment\u001b[38;5;241m.\u001b[39mtensorflowVersion,\n\u001b[1;32m    920\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapi_version\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata\u001b[38;5;241m.\u001b[39menvironment\u001b[38;5;241m.\u001b[39mapiVersion,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    937\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactivations_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: quant_mode\u001b[38;5;241m.\u001b[39mactivations_type(),\n\u001b[1;32m    938\u001b[0m })\n\u001b[1;32m    939\u001b[0m converter_kwargs\u001b[38;5;241m.\u001b[39mupdate(\n\u001b[1;32m    940\u001b[0m     quant_mode\u001b[38;5;241m.\u001b[39mconverter_flags(inference_type, inference_input_type)\n\u001b[1;32m    941\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/lite/python/lite.py:267\u001b[0m, in \u001b[0;36mQuantizationMode.__init__\u001b[0;34m(self, optimizations, target_spec, representative_dataset, graph_def, disable_per_channel, experimental_new_dynamic_range_quantizer, experimental_low_bit_qat, full_integer_quantization_bias_type, experimental_mlir_variable_quantization)\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_representative_dataset \u001b[38;5;241m=\u001b[39m representative_dataset\n\u001b[1;32m    265\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph_def \u001b[38;5;241m=\u001b[39m graph_def\n\u001b[0;32m--> 267\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_int8_required\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_disable_per_channel \u001b[38;5;241m=\u001b[39m disable_per_channel\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_new_dynamic_range_quantizer \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    271\u001b[0m     experimental_new_dynamic_range_quantizer\n\u001b[1;32m    272\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/lite/python/lite.py:498\u001b[0m, in \u001b[0;36mQuantizationMode._validate_int8_required\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    493\u001b[0m \u001b[38;5;66;03m# Check if representative_dataset is specified.\u001b[39;00m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    495\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_representative_dataset\n\u001b[1;32m    496\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_quantization_aware_training()\n\u001b[1;32m    497\u001b[0m ):\n\u001b[0;32m--> 498\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    499\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFor full integer quantization, a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    500\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`representative_dataset` must be specified.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    501\u001b[0m   )\n\u001b[1;32m    503\u001b[0m \u001b[38;5;66;03m# Update represenative dataset to the expected format.\u001b[39;00m\n\u001b[1;32m    504\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_representative_dataset:\n",
      "\u001b[0;31mValueError\u001b[0m: For full integer quantization, a `representative_dataset` must be specified."
     ]
    }
   ],
   "source": [
    "tflite_model_dynamic_range = converter.convert()\n",
    "\n",
    "# Save the quantized model\n",
    "with open('quantized_model_dynamic_range.tflite', 'wb') as f:\n",
    "    f.write(tflite_model_dynamic_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "adbea18e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.14.0'"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89cb166",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4e5e9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d065ffdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2aa95ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4f7dd95a",
   "metadata": {},
   "source": [
    "Let's try with the Full integer quantization \n",
    "## Full integer Quantization\n",
    "Reductions in peak memory usage, and compatibility with integer only hardware devices or accelerators by making sure all model math is integer quantized.\n",
    "\n",
    "For full integer quantization, you need to calibrate or estimate the range, i.e, (min, max) of all floating-point tensors in the model. Unlike constant tensors such as weights and biases, variable tensors such as model input, activations (outputs of intermediate layers) and model output cannot be calibrated unless we run a few inference cycles. As a result, the converter requires a representative dataset to calibrate them. This dataset can be a small subset (around ~100-500 samples) of the training or validation data. Refer to the `representative_dataset()`function below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc71158b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to apply Full Integer quantization\n",
    "def full_integer_quantization(model):\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "    tflite_model = converter.convert()\n",
    "    return tflite_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69c34e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reading the dataset\n",
    "ds_builder = tfds.builder(\"clic_edm_qq_pf\", data_dir = '../../../tensorflow_datasets/')\n",
    "dss = ds_builder.as_data_source(\"test\")\n",
    "\n",
    "\n",
    "# Define a function to preprocess the data\n",
    "def preprocess_data(data):\n",
    "    # Implement your preprocessing steps here\n",
    "    return preprocessed_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b2ab32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the dataset and run inference with quantized model\n",
    "true_pts = []\n",
    "pred_pts = []\n",
    "\n",
    "for data_batch in tfds.as_numpy(dss):\n",
    "    X = preprocess_data(data_batch[\"X\"])\n",
    "    ys = data_batch[\"ygen\"]\n",
    "    \n",
    "    # Run inference with the quantized model\n",
    "    try:\n",
    "        interpreter = tf.lite.Interpreter(model_content=quantized_model)\n",
    "        interpreter.allocate_tensors()\n",
    "        \n",
    "        input_details = interpreter.get_input_details()\n",
    "        output_details = interpreter.get_output_details()\n",
    "        \n",
    "        interpreter.set_tensor(input_details[0]['index'], [X])\n",
    "        interpreter.invoke()\n",
    "        quantized_output = interpreter.get_tensor(output_details[0]['index'])\n",
    "        \n",
    "        mask_true_particles = ys[..., 0] != 0\n",
    "        true_pt = ys[mask_true_particles, 2]\n",
    "        pred_pt = quantized_output[0][mask_true_particles][..., 0]\n",
    "        \n",
    "        true_pts.extend(true_pt)\n",
    "        pred_pts.extend(pred_pt)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing batch: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373d1b7b",
   "metadata": {},
   "source": [
    "## Float 16 Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8416b91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79033bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path += [\"../../../../particleflow/mlpf/\"]\n",
    "from tfmodel.model_setup import make_model\n",
    "from tfmodel.utils import parse_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996cd4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "config, _ = parse_config(\"../../../../particleflow/parameters/clic.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae941d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_model(config, tf.float32)\n",
    "model.build((1, None, config[\"dataset\"][\"num_input_features\"]))\n",
    "model.load_weights(\"weights-96-5.346523.hdf5\", skip_mismatch=False, by_name=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ce012f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reading the dataset\n",
    "ds_builder = tfds.builder(\"clic_edm_qq_pf\", data_dir = '../../../tensorflow_datasets/')\n",
    "dss = ds_builder.as_data_source(\"test\")\n",
    "def yield_from_ds():\n",
    "    for elem in dss:\n",
    "        yield {\"X\": elem[\"X\"], \"ygen\": elem[\"ygen\"], \"ycand\": elem[\"ycand\"]}\n",
    "output_signature = {k: tf.TensorSpec(shape=(None, v.shape[1])) for (k, v) in dss.dataset_info.features.items()}\n",
    "tf_dataset = tf.data.Dataset.from_generator(yield_from_ds, output_signature=output_signature).take(100).padded_batch(batch_size=10)\n",
    "data = list(tfds.as_numpy(tf_dataset))\n",
    "Xs = [d[\"X\"] for d in data]\n",
    "ys = [d[\"ygen\"] for d in data]\n",
    "\n",
    "true_pts = []\n",
    "pred_pts = []\n",
    "\n",
    "for ibatch in range(len(Xs)):\n",
    "    ret = model(Xs[ibatch])\n",
    "\n",
    "    mask_true_particles = ys[ibatch][..., 0]!=0\n",
    "    \n",
    "    true_pt = ys[ibatch][mask_true_particles, 2]\n",
    "    pred_pt = ret[\"pt\"][mask_true_particles][..., 0].numpy()\n",
    "\n",
    "    true_pts.append(true_pt)\n",
    "    pred_pts.append(pred_pt)\n",
    "    \n",
    "    \n",
    "true_pt = np.concatenate(true_pts)\n",
    "pred_pt = np.concatenate(pred_pts)\n",
    "\n",
    "\n",
    "plt.hist(pred_pt/true_pt, bins=np.linspace(0,3,100));\n",
    "plt.yscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa9ee56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to float16 quantized model\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.target_spec.supported_types = [tf.float16]\n",
    "quantized_float16_tflite_model = converter.convert()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a641ab08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantize the dataset after Assuming Xs is a list of input data\n",
    "quantized_Xs = [tf.constant(x, dtype=tf.float16) for x in Xs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf500f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantize the model prediction\n",
    "Xs_tf = [tf.convert_to_tensor(X_q, dtype=tf.float32) for X_q in quantized_Xs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ebc2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantized_Xs = [tf.constant(x, dtype=tf.float16) for x in Xs]\n",
    "\n",
    "ys_quantized = [np.round(y * 127).astype(np.int8) for y in ys]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8293bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_pts = []\n",
    "pred_pts = []\n",
    "\n",
    "for ibatch in range(len(Xs)):\n",
    "    ret = model(Xs_tf[ibatch])\n",
    "\n",
    "    mask_true_particles = ys_quantized[ibatch][..., 0]!=0\n",
    "    \n",
    "    true_pt = ys[ibatch][mask_true_particles, 2]\n",
    "    pred_pt = ret[\"pt\"][mask_true_particles][..., 0].numpy()\n",
    "\n",
    "    true_pts.append(true_pt)\n",
    "    pred_pts.append(pred_pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d597801a",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_pt = np.concatenate(true_pts)\n",
    "pred_pt = np.concatenate(pred_pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb18ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(pred_pt/true_pt, bins=np.linspace(0,3,100));\n",
    "plt.title(\"After FP16 Quantization\")\n",
    "plt.yscale(\"log\")\n",
    "# plt.savefig('Output_after_INT8_quantization.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b1391b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d486ed8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c33ac97e",
   "metadata": {},
   "source": [
    "**Goal**: \\\n",
    "Target and goal is to convert the model  into the tensorflow quantized model and further after quantizing the dataset measure the inference time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae44e11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ce4e0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
