{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25bbb433",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-14 21:32:46.934475: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-14 21:33:09.572319: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 188160000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "938/938 [==============================] - 11s 11ms/step - loss: 0.1786 - accuracy: 0.9473 - val_loss: 0.0543 - val_accuracy: 0.9833\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 8s 9ms/step - loss: 0.0533 - accuracy: 0.9835 - val_loss: 0.0467 - val_accuracy: 0.9849\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 8s 8ms/step - loss: 0.0374 - accuracy: 0.9880 - val_loss: 0.0389 - val_accuracy: 0.9877\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 8s 8ms/step - loss: 0.0289 - accuracy: 0.9910 - val_loss: 0.0362 - val_accuracy: 0.9892\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 8s 8ms/step - loss: 0.0222 - accuracy: 0.9928 - val_loss: 0.0393 - val_accuracy: 0.9881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cvmfs/sft.cern.ch/lcg/views/LCG_105/x86_64-el9-gcc13-opt/lib/python3.9/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "# Load and preprocess the MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "# Reshape the input data to match CNN input shape (add a channel dimension)\n",
    "x_train = x_train.reshape((-1, 28, 28, 1))\n",
    "x_test = x_test.reshape((-1, 28, 28, 1))\n",
    "\n",
    "# Define the model architecture\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train, y_train, epochs=5, batch_size=64, validation_data=(x_test, y_test))\n",
    "\n",
    "# Save the trained model\n",
    "model.save('mnist_cnn_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8ec61ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "\n",
    "model = load_model('mnist_cnn_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c53ab21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 13, 13, 32)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 5, 5, 64)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1600)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                102464    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 121930 (476.29 KB)\n",
      "Trainable params: 121930 (476.29 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c3252923",
   "metadata": {},
   "outputs": [],
   "source": [
    "def representative_dataset_gen():\n",
    "    for _ in range(num_calibration_steps):\n",
    "        # Generate or load representative data samples\n",
    "        data_sample = np.random.rand(1, 28, 28, 1)  # Sample input data\n",
    "        yield [data_sample.astype(np.float32)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "837f1ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/sraj/tmpn5zd6wyc/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/sraj/tmpn5zd6wyc/assets\n",
      "/cvmfs/sft.cern.ch/lcg/views/LCG_105/x86_64-el9-gcc13-opt/lib/python3.9/site-packages/tensorflow/lite/python/convert.py:887: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\n",
      "2024-02-14 21:40:14.174976: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
      "2024-02-14 21:40:14.175013: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
      "2024-02-14 21:40:14.175218: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /tmp/sraj/tmpn5zd6wyc\n",
      "2024-02-14 21:40:14.176212: I tensorflow/cc/saved_model/reader.cc:91] Reading meta graph with tags { serve }\n",
      "2024-02-14 21:40:14.176228: I tensorflow/cc/saved_model/reader.cc:132] Reading SavedModel debug info (if present) from: /tmp/sraj/tmpn5zd6wyc\n",
      "2024-02-14 21:40:14.179006: I tensorflow/cc/saved_model/loader.cc:231] Restoring SavedModel bundle.\n",
      "2024-02-14 21:40:14.231126: I tensorflow/cc/saved_model/loader.cc:215] Running initialization op on SavedModel bundle at path: /tmp/sraj/tmpn5zd6wyc\n",
      "2024-02-14 21:40:14.243263: I tensorflow/cc/saved_model/loader.cc:314] SavedModel load for tags { serve }; Status: success: OK. Took 68044 microseconds.\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: UINT8, output_inference_type: UINT8\n"
     ]
    }
   ],
   "source": [
    "# Define the number of calibration steps\n",
    "num_calibration_steps = 100\n",
    "\n",
    "# Convert the model to a TensorFlow Lite compatible format with int8 quantization\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_dataset_gen\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.inference_input_type = tf.uint8\n",
    "converter.inference_output_type = tf.uint8\n",
    "tflite_model = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0b961cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the quantized model\n",
    "with open('quantized_mnist_model.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8a5a7dfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "# load the quantized model\n",
    "interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
    "interpreter.allocate_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "db89be6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get input and output tensors\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5c216c3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'serving_default_conv2d_input:0',\n",
       "  'index': 0,\n",
       "  'shape': array([ 1, 28, 28,  1], dtype=int32),\n",
       "  'shape_signature': array([-1, 28, 28,  1], dtype=int32),\n",
       "  'dtype': numpy.uint8,\n",
       "  'quantization': (0.003921540919691324, 0),\n",
       "  'quantization_parameters': {'scales': array([0.00392154], dtype=float32),\n",
       "   'zero_points': array([0], dtype=int32),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e04ef095",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'StatefulPartitionedCall:0',\n",
       "  'index': 19,\n",
       "  'shape': array([ 1, 10], dtype=int32),\n",
       "  'shape_signature': array([-1, 10], dtype=int32),\n",
       "  'dtype': numpy.uint8,\n",
       "  'quantization': (0.00390625, 0),\n",
       "  'quantization_parameters': {'scales': array([0.00390625], dtype=float32),\n",
       "   'zero_points': array([0], dtype=int32),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "13259915",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_data = np.random.rand(1, 28, 28, 1)\n",
    "\n",
    "# Inference\n",
    "interpreter.set_tensor(input_details[0]['index'], input_data.astype(np.uint8))\n",
    "interpreter.invoke()\n",
    "output_data = interpreter.get_tensor(output_details[0]['index'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "163bb927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference result: [[27 35 24 20 26 26 25 26 24 23]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Inference result:\", output_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c64d054a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dynamic Range Quantiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0385b395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/sraj/tmp8x7drts5/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/sraj/tmp8x7drts5/assets\n",
      "2024-02-14 21:50:59.007776: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
      "2024-02-14 21:50:59.007909: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
      "2024-02-14 21:50:59.008110: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /tmp/sraj/tmp8x7drts5\n",
      "2024-02-14 21:50:59.009167: I tensorflow/cc/saved_model/reader.cc:91] Reading meta graph with tags { serve }\n",
      "2024-02-14 21:50:59.009186: I tensorflow/cc/saved_model/reader.cc:132] Reading SavedModel debug info (if present) from: /tmp/sraj/tmp8x7drts5\n",
      "2024-02-14 21:50:59.012785: I tensorflow/cc/saved_model/loader.cc:231] Restoring SavedModel bundle.\n",
      "2024-02-14 21:50:59.050442: I tensorflow/cc/saved_model/loader.cc:215] Running initialization op on SavedModel bundle at path: /tmp/sraj/tmp8x7drts5\n",
      "2024-02-14 21:50:59.066991: I tensorflow/cc/saved_model/loader.cc:314] SavedModel load for tags { serve }; Status: success: OK. Took 58881 microseconds.\n"
     ]
    }
   ],
   "source": [
    "# Load the trained model\n",
    "model = tf.keras.models.load_model('mnist_cnn_model.h5')\n",
    "\n",
    "# Convert the model to a TensorFlow Lite compatible format with dynamic range quantization\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "# converter.target_spec.supported_types = [tf.float16]\n",
    "tflite_model = converter.convert()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c5e7c8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the quantized model\n",
    "with open('quantized_mnist_model_dynamic.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd770ef",
   "metadata": {},
   "source": [
    "# Float16 quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1383e3a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/sraj/tmpsxjeuhu6/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/sraj/tmpsxjeuhu6/assets\n",
      "2024-02-14 21:54:13.443474: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
      "2024-02-14 21:54:13.443588: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
      "2024-02-14 21:54:13.443785: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /tmp/sraj/tmpsxjeuhu6\n",
      "2024-02-14 21:54:13.444851: I tensorflow/cc/saved_model/reader.cc:91] Reading meta graph with tags { serve }\n",
      "2024-02-14 21:54:13.444872: I tensorflow/cc/saved_model/reader.cc:132] Reading SavedModel debug info (if present) from: /tmp/sraj/tmpsxjeuhu6\n",
      "2024-02-14 21:54:13.447841: I tensorflow/cc/saved_model/loader.cc:231] Restoring SavedModel bundle.\n",
      "2024-02-14 21:54:13.488121: I tensorflow/cc/saved_model/loader.cc:215] Running initialization op on SavedModel bundle at path: /tmp/sraj/tmpsxjeuhu6\n",
      "2024-02-14 21:54:13.499961: I tensorflow/cc/saved_model/loader.cc:314] SavedModel load for tags { serve }; Status: success: OK. Took 56174 microseconds.\n"
     ]
    }
   ],
   "source": [
    "# Load the trained model\n",
    "model = tf.keras.models.load_model('mnist_cnn_model.h5')\n",
    "\n",
    "# Convert the model to a TensorFlow Lite compatible format with dynamic range quantization\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.target_spec.supported_types = [tf.float16]\n",
    "tflite_model = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a6683e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the quantized model\n",
    "with open('quantized_mnist_model_fp16.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "64fba754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 2.5M\r\n",
      "-rw-r--r--. 1 sraj zh  745 Feb 14 19:04 INT8_quantization_Pytorch.ipynb\r\n",
      "-rw-r--r--. 1 sraj zh  21K Feb 14 22:00 INT8_quantization_Tf.ipynb\r\n",
      "-rw-r--r--. 1 sraj zh  68K Feb 14 21:37 load-pytorch.ipynb\r\n",
      "-rw-r--r--. 1 sraj zh 1.5M Feb 14 21:33 mnist_cnn_model.h5\r\n",
      "-rw-r--r--. 1 sraj zh 8.1K Feb 14 18:52 Quantization_understanding.ipynb\r\n",
      "-rw-r--r--. 1 sraj zh 127K Feb 14 21:51 quantized_mnist_model_dynamic.tflite\r\n",
      "-rw-r--r--. 1 sraj zh 243K Feb 14 21:54 quantized_mnist_model_fp16.tflite\r\n",
      "-rw-r--r--. 1 sraj zh 127K Feb 14 21:41 quantized_mnist_model.tflite\r\n",
      "-rw-r--r--. 1 sraj zh 480K Feb 14 21:59 unquantized_mnist_model.tflite\r\n"
     ]
    }
   ],
   "source": [
    "ls -lh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c79609",
   "metadata": {},
   "source": [
    "Convert the unquantized model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0a48988c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/sraj/tmpum3qpyqe/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/sraj/tmpum3qpyqe/assets\n",
      "2024-02-14 21:58:57.368302: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
      "2024-02-14 21:58:57.368417: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
      "2024-02-14 21:58:57.368626: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /tmp/sraj/tmpum3qpyqe\n",
      "2024-02-14 21:58:57.369673: I tensorflow/cc/saved_model/reader.cc:91] Reading meta graph with tags { serve }\n",
      "2024-02-14 21:58:57.369694: I tensorflow/cc/saved_model/reader.cc:132] Reading SavedModel debug info (if present) from: /tmp/sraj/tmpum3qpyqe\n",
      "2024-02-14 21:58:57.373588: I tensorflow/cc/saved_model/loader.cc:231] Restoring SavedModel bundle.\n",
      "2024-02-14 21:58:57.416144: I tensorflow/cc/saved_model/loader.cc:215] Running initialization op on SavedModel bundle at path: /tmp/sraj/tmpum3qpyqe\n",
      "2024-02-14 21:58:57.427755: I tensorflow/cc/saved_model/loader.cc:314] SavedModel load for tags { serve }; Status: success: OK. Took 59129 microseconds.\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e6f14007",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('unquantized_mnist_model.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9ddf3d42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Data for unquantized model\n",
    "unquantized_data = {\n",
    "    \"cpu w/ 4 threads (xnnpack)\": 25.8211,\n",
    "    \"cpu w/ 2 threads (xnnpack)\": 36.2405,\n",
    "    \"cpu w/ 1 threads (xnnpack)\": 64.7086,\n",
    "    \"cpu w/ 4 threads\": 84.4446,\n",
    "    \"cpu w/ 2 threads\": 94.5954,\n",
    "    \"cpu w/ 1 threads\": 108.926,\n",
    "    \"gpu-default\": 120.178\n",
    "}\n",
    "\n",
    "# Data for Fp16 quantization\n",
    "fp16_data = {\n",
    "    \"cpu w/ 4 threads (xnnpack)\": 28.3489,\n",
    "    \"cpu w/ 2 threads (xnnpack)\": 37.655,\n",
    "    \"cpu w/ 1 threads (xnnpack)\": 64.8064,\n",
    "    \"cpu w/ 4 threads\": 84.8022,\n",
    "    \"cpu w/ 2 threads\": 97.2019,\n",
    "    \"cpu w/ 1 threads\": 108.768,\n",
    "    \"gpu-default\": 109.432\n",
    "}\n",
    "\n",
    "# Data for Dynamic Range quantization\n",
    "dynamic_range_data = {\n",
    "    \"cpu w/ 4 threads (xnnpack)\": 75.4052,\n",
    "    \"cpu w/ 2 threads (xnnpack)\": 82.9918,\n",
    "    \"cpu w/ 1 threads (xnnpack)\": 130.894,\n",
    "    \"cpu w/ 4 threads\": 92.6607,\n",
    "    \"cpu w/ 2 threads\": 105.124,\n",
    "    \"cpu w/ 1 threads\": 150.422,\n",
    "    \"gpu-default\": 150.063\n",
    "}\n",
    "\n",
    "# Data for Int8 quantization\n",
    "int8_data = {\n",
    "    \"cpu w/ 4 threads (xnnpack)\": 37.4216,\n",
    "    \"cpu w/ 2 threads (xnnpack)\": 67.3639,\n",
    "    \"cpu w/ 1 threads (xnnpack)\": 107.24,\n",
    "    \"cpu w/ 4 threads\": 83.1904,\n",
    "    \"cpu w/ 2 threads\": 103.453,\n",
    "    \"cpu w/ 1 threads\": 161.806,\n",
    "    \"gpu-default\": 161.96\n",
    "}\n",
    "\n",
    "# Extract labels and values\n",
    "labels = list(unquantized_data.keys())\n",
    "unquantized_values = list(unquantized_data.values())\n",
    "fp16_values = list(fp16_data.values())\n",
    "dynamic_range_values = list(dynamic_range_data.values())\n",
    "int8_values = list(int8_data.values())\n",
    "\n",
    "# Set width of bars\n",
    "bar_width = 0.2\n",
    "\n",
    "# Set position of bar on X axis\n",
    "r1 = range(len(labels))\n",
    "r2 = [x + bar_width for x in r1]\n",
    "r3 = [x + bar_width for x in r2]\n",
    "r4 = [x + bar_width for x in r3]\n",
    "\n",
    "# Make the plot\n",
    "plt.bar(r1, unquantized_values, color='b', width=bar_width, edgecolor='grey', label='Unquantized')\n",
    "plt.bar(r2, fp16_values, color='r', width=bar_width, edgecolor='grey', label='Fp16')\n",
    "plt.bar(r3, dynamic_range_values, color='g', width=bar_width, edgecolor='grey', label='Dynamic Range')\n",
    "plt.bar(r4, int8_values, color='y', width=bar_width, edgecolor='grey', label='Int8')\n",
    "\n",
    "# Add xticks on the middle of the group bars\n",
    "plt.xlabel('Performance Options', fontweight='bold')\n",
    "plt.xticks([r + bar_width for r in range(len(labels))], labels, rotation=90)\n",
    "\n",
    "# Create legend & Show graphic\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b3d539",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5662ab86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c79a8db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee083d6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
