{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9eef64e5",
   "metadata": {},
   "source": [
    "Task:\n",
    "1.  quantization to INT8:\n",
    "    1. Perform training \n",
    "    2. recompute the loss using the quantized model\n",
    "    3. ultimately reproduce Fig 9 from the paper, adding additional an int8-quantized MLPF model (e.g. dashed orange line)\n",
    "    \n",
    "2. Again perform Quantizatio on Fp16:\n",
    "\n",
    "    1. Perform training\n",
    "    2. Recompute the loss\n",
    "\n",
    "3. Check the physics loss in all of these three plots.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1d3a1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.set_num_threads(1)\n",
    "from torch import nn, Tensor\n",
    "import tensorflow_datasets as tfds\n",
    "import torch_geometric\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4104391c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../../mlpf/tensorflow_datasets/\"\n",
    "dataset = \"clic_edm_ttbar_pf\"\n",
    "\n",
    "#Load dataset\n",
    "builder = tfds.builder(dataset, data_dir=data_dir)\n",
    "ds_train = builder.as_data_source(split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc706b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_FEATURES_TRK = [\n",
    "    \"elemtype\",\n",
    "    \"pt\",\n",
    "    \"eta\",\n",
    "    \"sin_phi\",\n",
    "    \"cos_phi\",\n",
    "    \"p\",\n",
    "    \"chi2\",\n",
    "    \"ndf\",\n",
    "    \"dEdx\",\n",
    "    \"dEdxError\",\n",
    "    \"radiusOfInnermostHit\",\n",
    "    \"tanLambda\",\n",
    "    \"D0\",\n",
    "    \"omega\",\n",
    "    \"Z0\",\n",
    "    \"time\",\n",
    "]\n",
    "X_FEATURES_CL = [\n",
    "    \"elemtype\",\n",
    "    \"et\",\n",
    "    \"eta\",\n",
    "    \"sin_phi\",\n",
    "    \"cos_phi\",\n",
    "    \"energy\",\n",
    "    \"position.x\",\n",
    "    \"position.y\",\n",
    "    \"position.z\",\n",
    "    \"iTheta\",\n",
    "    \"energy_ecal\",\n",
    "    \"energy_hcal\",\n",
    "    \"energy_other\",\n",
    "    \"num_hits\",\n",
    "    \"sigma_x\",\n",
    "    \"sigma_y\",\n",
    "    \"sigma_z\",\n",
    "]\n",
    "Y_FEATURES = [\"cls_id\", \"charge\", \"pt\", \"eta\", \"sin_phi\", \"cos_phi\", \"energy\"]\n",
    "Y_CLASSES = [0, 211, 130, 22, 11, 13]\n",
    "\n",
    "INPUT_DIM = max(len(X_FEATURES_TRK), len(X_FEATURES_CL))\n",
    "NUM_CLASSES = len(Y_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b8d66ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    \"\"\"Focal Loss, as described in https://arxiv.org/abs/1708.02002.\n",
    "    It is essentially an enhancement to cross entropy loss and is\n",
    "    useful for classification tasks when there is a large class imbalance.\n",
    "    x is expected to contain raw, unnormalized scores for each class.\n",
    "    y is expected to contain class labels.\n",
    "    Shape:\n",
    "        - x: (batch_size, C) or (batch_size, C, d1, d2, ..., dK), K > 0.\n",
    "        - y: (batch_size,) or (batch_size, d1, d2, ..., dK), K > 0.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, alpha = None, gamma = 0.0, reduction = \"mean\", ignore_index = -100\n",
    "    ):\n",
    "        \"\"\"Constructor.\n",
    "        Args:\n",
    "            alpha (Tensor, optional): Weights for each class. Defaults to None.\n",
    "            gamma (float, optional): A constant, as described in the paper.\n",
    "                Defaults to 0.\n",
    "            reduction (str, optional): 'mean', 'sum' or 'none'.\n",
    "                Defaults to 'mean'.\n",
    "            ignore_index (int, optional): class label to ignore.\n",
    "                Defaults to -100.\n",
    "        \"\"\"\n",
    "        if reduction not in (\"mean\", \"sum\", \"none\"):\n",
    "            raise ValueError('Reduction must be one of: \"mean\", \"sum\", \"none\".')\n",
    "\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "        self.nll_loss = nn.NLLLoss(weight=alpha, reduction=\"none\")\n",
    "\n",
    "    def __repr__(self):\n",
    "        arg_keys = [\"alpha\", \"gamma\", \"reduction\"]\n",
    "        arg_vals = [self.__dict__[k] for k in arg_keys]\n",
    "        arg_strs = [f\"{k}={v!r}\" for k, v in zip(arg_keys, arg_vals)]\n",
    "        arg_str = \", \".join(arg_strs)\n",
    "        return f\"{type(self).__name__}({arg_str})\"\n",
    "\n",
    "    def forward(self, x: Tensor, y: Tensor) -> Tensor:\n",
    "        if x.ndim > 2:\n",
    "            # (N, C, d1, d2, ..., dK) --> (N * d1 * ... * dK, C)\n",
    "            c = x.shape[1]\n",
    "            x = x.permute(0, *range(2, x.ndim), 1).reshape(-1, c)\n",
    "            # (N, d1, d2, ..., dK) --> (N * d1 * ... * dK,)\n",
    "            y = y.view(-1)\n",
    "\n",
    "        # compute weighted cross entropy term: -alpha * log(pt)\n",
    "        # (alpha is already part of self.nll_loss)\n",
    "        log_p = F.log_softmax(x, dim=-1)\n",
    "        ce = self.nll_loss(log_p, y)\n",
    "\n",
    "        # get true class column from each row\n",
    "        # this is slow due to indexing\n",
    "        # all_rows = torch.arange(len(x))\n",
    "        # log_pt = log_p[all_rows, y]\n",
    "        log_pt = torch.gather(log_p, 1, y.unsqueeze(axis=-1)).squeeze(axis=-1)\n",
    "\n",
    "        # compute focal term: (1 - pt)^gamma\n",
    "        pt = log_pt.exp()\n",
    "        focal_term = (1 - pt) ** self.gamma\n",
    "\n",
    "        # the full loss: -alpha * ((1 - pt)^gamma) * log(pt)\n",
    "        loss = focal_term * ce\n",
    "\n",
    "        if self.reduction == \"mean\":\n",
    "            loss = loss.mean()\n",
    "        elif self.reduction == \"sum\":\n",
    "            loss = loss.sum()\n",
    "\n",
    "        return loss\n",
    "\n",
    "class QuantizeFeaturesStub(torch.nn.Module):\n",
    "    def __init__(self, num_feats):\n",
    "        super().__init__()\n",
    "        self.num_feats = num_feats\n",
    "        self.quants = torch.nn.ModuleList()\n",
    "        for ifeat in range(self.num_feats):\n",
    "            self.quants.append(torch.ao.quantization.QuantStub())\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.cat([self.quants[ifeat](x[..., ifeat:ifeat+1]) for ifeat in range(self.num_feats)], axis=-1)\n",
    "        \n",
    "def mlpf_loss(y, ypred):\n",
    "    loss = {}\n",
    "    loss_obj_id = FocalLoss(gamma=2.0, reduction=\"none\")\n",
    "\n",
    "    msk_true_particle = torch.unsqueeze((y[\"cls_id\"] != 0).to(dtype=torch.float32), axis=-1)\n",
    "    npart = y[\"pt\"].numel()\n",
    "\n",
    "    ypred[\"momentum\"] = ypred[\"momentum\"] * msk_true_particle\n",
    "    y[\"momentum\"] = y[\"momentum\"] * msk_true_particle\n",
    "\n",
    "    ypred[\"cls_id_onehot\"] = ypred[\"cls_id_onehot\"].permute((0, 2, 1))\n",
    "\n",
    "    loss_classification = 100 * loss_obj_id(ypred[\"cls_id_onehot\"], y[\"cls_id\"]).reshape(y[\"cls_id\"].shape)\n",
    "    loss_regression = 10 * torch.nn.functional.huber_loss(ypred[\"momentum\"], y[\"momentum\"], reduction=\"none\")\n",
    "    \n",
    "    # average over all particles\n",
    "    loss[\"Classification\"] = loss_classification.sum() / npart\n",
    "    loss[\"Regression\"] = loss_regression.sum() / npart\n",
    "\n",
    "    loss[\"Total\"] = loss[\"Classification\"] + loss[\"Regression\"]\n",
    "    return loss\n",
    "    \n",
    "class SelfAttentionLayer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        embedding_dim=128,\n",
    "        num_heads=2,\n",
    "        width=128,\n",
    "        dropout_mha=0.1,\n",
    "        dropout_ff=0.1,\n",
    "        attention_type=\"efficient\",\n",
    "    ):\n",
    "        super(SelfAttentionLayer, self).__init__()\n",
    "\n",
    "        self.attention_type = attention_type\n",
    "        self.act = nn.ReLU()\n",
    "        self.mha = torch.nn.MultiheadAttention(embedding_dim, num_heads, dropout=dropout_mha, batch_first=True)\n",
    "        self.norm0 = torch.nn.LayerNorm(embedding_dim)\n",
    "        self.norm1 = torch.nn.LayerNorm(embedding_dim)\n",
    "        self.seq = torch.nn.Sequential(\n",
    "            nn.Linear(embedding_dim, width), self.act, nn.Linear(width, embedding_dim), self.act\n",
    "        )\n",
    "\n",
    "        self.dropout = torch.nn.Dropout(dropout_ff)\n",
    "\n",
    "        self.add0 = torch.ao.nn.quantized.FloatFunctional()\n",
    "        self.add1 = torch.ao.nn.quantized.FloatFunctional()\n",
    "        self.mul = torch.ao.nn.quantized.FloatFunctional()\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        mha_out = self.mha(x, x, x, need_weights=False)[0]\n",
    "        x = self.add0.add(x, mha_out)\n",
    "        x = self.norm0(x)\n",
    "        x = self.add1.add(x, self.seq(x))\n",
    "        x = self.norm1(x)\n",
    "        x = self.dropout(x)\n",
    "#         mask = mask.to(x.dtype)        \n",
    "#         x = x * mask.unsqueeze(-1).expand(-1, -1, x.size(2))\n",
    "\n",
    "        \n",
    "        return x\n",
    "\n",
    "class RegressionOutput(nn.Module):\n",
    "    def __init__(self, embed_dim, width, act, dropout):\n",
    "        super(RegressionOutput, self).__init__()\n",
    "        self.dequant = torch.ao.quantization.DeQuantStub()\n",
    "        self.nn = ffn(embed_dim, 1, width, act, dropout)\n",
    "\n",
    "    def forward(self, elems, x, orig_value):\n",
    "        nn_out = self.nn(x)\n",
    "        nn_out = self.dequant(nn_out)\n",
    "        return orig_value + nn_out\n",
    "\n",
    "def ffn(input_dim, output_dim, width, act, dropout):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(input_dim, width),\n",
    "        act(),\n",
    "        torch.nn.LayerNorm(width),\n",
    "        nn.Dropout(dropout),\n",
    "        nn.Linear(width, output_dim),\n",
    "    )\n",
    "\n",
    "def transform_batch(Xbatch):\n",
    "    Xbatch = Xbatch.clone()\n",
    "    Xbatch[..., 1] = torch.log(Xbatch[..., 1])\n",
    "    Xbatch[..., 5] = torch.log(Xbatch[..., 5])\n",
    "    Xbatch[torch.isnan(Xbatch)] = 0.0\n",
    "    Xbatch[torch.isinf(Xbatch)] = 0.0\n",
    "    return Xbatch\n",
    "    \n",
    "def unpack_target(y):\n",
    "    ret = {}\n",
    "    ret[\"cls_id\"] = y[..., 0].long()\n",
    "\n",
    "    for i, feat in enumerate(Y_FEATURES):\n",
    "        if i >= 2:  # skip the cls and charge as they are defined above\n",
    "            ret[feat] = y[..., i].to(dtype=torch.float32)\n",
    "    ret[\"phi\"] = torch.atan2(ret[\"sin_phi\"], ret[\"cos_phi\"])\n",
    "    \n",
    "    # note ~ momentum = [\"pt\", \"eta\", \"sin_phi\", \"cos_phi\", \"energy\"]\n",
    "    ret[\"momentum\"] = y[..., 2:7].to(dtype=torch.float32)\n",
    "    ret[\"p4\"] = torch.cat(\n",
    "        [ret[\"pt\"].unsqueeze(1), ret[\"eta\"].unsqueeze(1), ret[\"phi\"].unsqueeze(1), ret[\"energy\"].unsqueeze(1)], axis=1\n",
    "    )\n",
    "\n",
    "    return ret\n",
    "\n",
    "\n",
    "def unpack_predictions(preds):\n",
    "    ret = {}\n",
    "    ret[\"cls_id_onehot\"], ret[\"momentum\"] = preds\n",
    "\n",
    "    ret[\"pt\"] = ret[\"momentum\"][..., 0]\n",
    "    ret[\"eta\"] = ret[\"momentum\"][..., 1]\n",
    "    ret[\"sin_phi\"] = ret[\"momentum\"][..., 2]\n",
    "    ret[\"cos_phi\"] = ret[\"momentum\"][..., 3]\n",
    "    ret[\"energy\"] = ret[\"momentum\"][..., 4]\n",
    "\n",
    "    ret[\"cls_id\"] = torch.argmax(ret[\"cls_id_onehot\"], axis=-1)\n",
    "    ret[\"phi\"] = torch.atan2(ret[\"sin_phi\"], ret[\"cos_phi\"])\n",
    "    ret[\"p4\"] = torch.cat(\n",
    "        [\n",
    "            ret[\"pt\"].unsqueeze(axis=-1),\n",
    "            ret[\"eta\"].unsqueeze(axis=-1),\n",
    "            ret[\"phi\"].unsqueeze(axis=-1),\n",
    "            ret[\"energy\"].unsqueeze(axis=-1),\n",
    "        ],\n",
    "        axis=-1,\n",
    "    )\n",
    "\n",
    "    return ret\n",
    "\n",
    "class MLPF(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim=16,\n",
    "        num_classes=6,\n",
    "        num_convs=2,\n",
    "        dropout_ff=0.0,\n",
    "        dropout_conv_reg_mha=0.0,\n",
    "        dropout_conv_reg_ff=0.0,\n",
    "        dropout_conv_id_mha=0.0,\n",
    "        dropout_conv_id_ff=0.0,\n",
    "        num_heads=16,\n",
    "        head_dim=16,\n",
    "        elemtypes=[0,1,2],\n",
    "    ):\n",
    "        super(MLPF, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.act = nn.ReLU  # Change activation function here\n",
    "        self.elemtypes = elemtypes\n",
    "        self.num_elemtypes = len(self.elemtypes)\n",
    "\n",
    "        embedding_dim = num_heads * head_dim\n",
    "        width = num_heads * head_dim\n",
    "        \n",
    "        self.nn0_id = ffn(self.input_dim, embedding_dim, width, self.act, dropout_ff)\n",
    "        self.nn0_reg = ffn(self.input_dim, embedding_dim, width, self.act, dropout_ff)\n",
    "        \n",
    "        self.conv_id = nn.ModuleList()\n",
    "        self.conv_reg = nn.ModuleList()\n",
    "\n",
    "        for i in range(num_convs):\n",
    "            self.conv_id.append(\n",
    "                SelfAttentionLayer(\n",
    "                    embedding_dim=embedding_dim,\n",
    "                    num_heads=num_heads,\n",
    "                    width=width,\n",
    "                    dropout_mha=dropout_conv_id_mha,\n",
    "                    dropout_ff=dropout_conv_id_ff,\n",
    "                )\n",
    "            )\n",
    "            self.conv_reg.append(\n",
    "                SelfAttentionLayer(\n",
    "                    embedding_dim=embedding_dim,\n",
    "                    num_heads=num_heads,\n",
    "                    width=width,\n",
    "                    dropout_mha=dropout_conv_reg_mha,\n",
    "                    dropout_ff=dropout_conv_reg_ff,\n",
    "                )\n",
    "            )\n",
    "\n",
    "        decoding_dim = self.input_dim + embedding_dim\n",
    "\n",
    "        # DNN that acts on the node level to predict the PID\n",
    "        self.nn_id = ffn(decoding_dim, num_classes, width, self.act, dropout_ff)\n",
    "\n",
    "        # elementwise DNN for node momentum regression\n",
    "        embed_dim = decoding_dim + num_classes\n",
    "        self.nn_pt = RegressionOutput(embed_dim, width, self.act, dropout_ff)\n",
    "        self.nn_eta = RegressionOutput(embed_dim, width, self.act, dropout_ff)\n",
    "        self.nn_sin_phi = RegressionOutput(embed_dim, width, self.act, dropout_ff)\n",
    "        self.nn_cos_phi = RegressionOutput(embed_dim, width, self.act, dropout_ff)\n",
    "        self.nn_energy = RegressionOutput(embed_dim, width, self.act, dropout_ff)\n",
    "        \n",
    "        self.quant = QuantizeFeaturesStub(self.input_dim + len(self.elemtypes))\n",
    "        self.dequant_id = torch.ao.quantization.DeQuantStub()\n",
    "\n",
    "    def forward(self, X_features, mask):\n",
    "        Xfeat_transformed = transform_batch(X_features)\n",
    "        Xfeat_normed = self.quant(Xfeat_transformed)\n",
    "\n",
    "        embeddings_id, embeddings_reg = [], []\n",
    "        embedding_id = self.nn0_id(Xfeat_normed)\n",
    "        embedding_reg = self.nn0_reg(Xfeat_normed)\n",
    "        for num, conv in enumerate(self.conv_id):\n",
    "            conv_input = embedding_id if num == 0 else embeddings_id[-1]\n",
    "            out_padded = conv(conv_input, mask)\n",
    "            embeddings_id.append(out_padded)\n",
    "        for num, conv in enumerate(self.conv_reg):\n",
    "            conv_input = embedding_reg if num == 0 else embeddings_reg[-1]\n",
    "            out_padded = conv(conv_input, mask)\n",
    "            embeptptptptddings_reg.append(out_padded)\n",
    "\n",
    "        final_embedding_id = torch.cat([Xfeat_normed] + [embeddings_id[-1]], axis=-1)\n",
    "        preds_id = self.nn_id(final_embedding_id)\n",
    "\n",
    "        final_embedding_reg = torch.cat([Xfeat_normed] + [embeddings_reg[-1]] + [preds_id], axis=-1)\n",
    "        preds_pt = self.nn_pt(X_features, final_embedding_reg, X_features[..., 1:2])\n",
    "        preds_eta = self.nn_eta(X_features, final_embedding_reg, X_features[..., 2:3])\n",
    "        preds_sin_phi = self.nn_sin_phi(X_features, final_embedding_reg, X_features[..., 3:4])\n",
    "        preds_cos_phi = self.nn_cos_phi(X_features, final_embedding_reg, X_features[..., 4:5])\n",
    "        preds_energy = self.nn_energy(X_features, final_embedding_reg, X_features[..., 5:6])\n",
    "        preds_momentum = torch.cat([preds_pt, preds_eta, preds_sin_phi, preds_cos_phi, preds_energy], axis=-1)\n",
    "        \n",
    "        preds_id = self.dequant_id(preds_id)\n",
    "        return preds_id, preds_momentum\n",
    "\n",
    "\n",
    "model = MLPF(input_dim=INPUT_DIM, num_classes=NUM_CLASSES)\n",
    "optimizer = torch.optim.Adam(lr=1e-4, params=model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "474a4c00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x7febcc392ac0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.set_grad_enabled(True)  # Context-manager \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9647cc4f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=33.94\n",
      "Loss=34.19\n",
      "Loss=25.22\n",
      "Loss=34.30\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/sraj/ipykernel_649402/2108663449.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmlpf_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets_unpacked_unq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds_unpacked_unq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Total\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mcurrent_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Total\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cvmfs/sft.cern.ch/lcg/views/LCG_105/x86_64-el9-gcc13-opt/lib/python3.9/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    490\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             )\n\u001b[0;32m--> 492\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    493\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         )\n",
      "\u001b[0;32m/cvmfs/sft.cern.ch/lcg/views/LCG_105/x86_64-el9-gcc13-opt/lib/python3.9/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    252\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "max_events_train = 1000\n",
    "events_per_batch = 10\n",
    "\n",
    "losses = []\n",
    "\n",
    "#Training loop\n",
    "inds_train = range(0,max_events_train,events_per_batch)\n",
    "for ind in inds_train:\n",
    "    optimizer.zero_grad()\n",
    "    ds_elems = [ds_train[i] for i in range(ind,ind+events_per_batch)]\n",
    "    X_features = [torch.tensor(elem[\"X\"]).to(torch.float32) for elem in ds_elems]\n",
    "    X_features_padded = pad_sequence(X_features, batch_first=True)\n",
    "    y_targets = [torch.tensor(elem[\"ygen\"]).to(torch.float32) for elem in ds_elems]\n",
    "    y_targets_padded = pad_sequence(y_targets, batch_first=True)\n",
    "    \n",
    "    mask = X_features_padded[:, :, 0]!=0\n",
    "\n",
    "    preds = model(X_features_padded, mask)\n",
    "    preds_unpacked_unq = unpack_predictions(preds)\n",
    "    targets_unpacked_unq = unpack_target(y_targets_padded)\n",
    "    \n",
    "    loss = mlpf_loss(targets_unpacked_unq, preds_unpacked_unq)\n",
    "    loss[\"Total\"].backward()\n",
    "    optimizer.step()\n",
    "    current_loss = loss[\"Total\"].detach().item()\n",
    "    losses.append(current_loss)\n",
    "    print(\"Loss={:.2f}\".format(loss[\"Total\"].detach().item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b06f673c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "484683d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e691bd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# losses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab79643",
   "metadata": {},
   "source": [
    "## Quantized model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a8b60eb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cvmfs/sft.cern.ch/lcg/views/LCG_105/x86_64-el9-gcc13-opt/lib/python3.9/site-packages/torch/ao/quantization/observer.py:214: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
      "  warnings.warn(\n",
      "/cvmfs/sft.cern.ch/lcg/views/LCG_105/x86_64-el9-gcc13-opt/lib/python3.9/site-packages/torch/ao/quantization/observer.py:1207: UserWarning: must run observer before calling calculate_qparams.                                    Returning default scale and zero point \n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# torch.backends.quantized.engine = 'onednn'\n",
    "\n",
    "model.eval()\n",
    "model.qconfig = torch.ao.quantization.get_default_qconfig('x86')\n",
    "model_prepared = torch.ao.quantization.prepare(model)\n",
    "\n",
    "\n",
    "#calibrate on data\n",
    "num_events_to_calibrate = 1\n",
    "for ind in range(1000,1000+num_events_to_calibrate):\n",
    "    X = torch.unsqueeze(torch.tensor(ds_train[ind][\"X\"]).to(torch.float32), 0)\n",
    "    mask = X[:, :, 0]!=0\n",
    "    model_prepared(X, mask)\n",
    "\n",
    "model_int8 = torch.ao.quantization.convert(model_prepared)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ad3335",
   "metadata": {},
   "source": [
    "## Training on the quantized model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1631487b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPF(\n",
       "  (nn0_id): Sequential(\n",
       "    (0): QuantizedLinear(in_features=17, out_features=256, scale=19.90985107421875, zero_point=74, qscheme=torch.per_channel_affine)\n",
       "    (1): ReLU()\n",
       "    (2): QuantizedLayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    (3): QuantizedDropout(p=0.0, inplace=False)\n",
       "    (4): QuantizedLinear(in_features=256, out_features=256, scale=0.034293293952941895, zero_point=70, qscheme=torch.per_channel_affine)\n",
       "  )\n",
       "  (nn0_reg): Sequential(\n",
       "    (0): QuantizedLinear(in_features=17, out_features=256, scale=18.684614181518555, zero_point=63, qscheme=torch.per_channel_affine)\n",
       "    (1): ReLU()\n",
       "    (2): QuantizedLayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    (3): QuantizedDropout(p=0.0, inplace=False)\n",
       "    (4): QuantizedLinear(in_features=256, out_features=256, scale=0.036145973950624466, zero_point=69, qscheme=torch.per_channel_affine)\n",
       "  )\n",
       "  (conv_id): ModuleList(\n",
       "    (0): SelfAttentionLayer(\n",
       "      (act): ReLU()\n",
       "      (mha): QuantizedMultiheadAttention(\n",
       "        (out_proj): QuantizedLinear(in_features=256, out_features=256, scale=0.00781739130616188, zero_point=67, qscheme=torch.per_channel_affine)\n",
       "        (linear_Q): QuantizedLinear(in_features=256, out_features=256, scale=0.03000890277326107, zero_point=65, qscheme=torch.per_channel_affine)\n",
       "        (linear_K): QuantizedLinear(in_features=256, out_features=256, scale=0.022782057523727417, zero_point=65, qscheme=torch.per_channel_affine)\n",
       "        (linear_V): QuantizedLinear(in_features=256, out_features=256, scale=0.02227146551012993, zero_point=62, qscheme=torch.per_channel_affine)\n",
       "        (q_scaling_product): QFunctional(\n",
       "          scale=1.0, zero_point=0\n",
       "          (activation_post_process): Identity()\n",
       "        )\n",
       "        (quant_attn_output): Quantize(scale=tensor([0.0103]), zero_point=tensor([61]), dtype=torch.quint8)\n",
       "        (quant_attn_output_weights): Quantize(scale=tensor([0.0001]), zero_point=tensor([0]), dtype=torch.quint8)\n",
       "        (dequant_q): DeQuantize()\n",
       "        (dequant_k): DeQuantize()\n",
       "        (dequant_v): DeQuantize()\n",
       "      )\n",
       "      (norm0): QuantizedLayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm1): QuantizedLayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (seq): Sequential(\n",
       "        (0): QuantizedLinear(in_features=256, out_features=256, scale=0.03407742828130722, zero_point=64, qscheme=torch.per_channel_affine)\n",
       "        (1): ReLU()\n",
       "        (2): QuantizedLinear(in_features=256, out_features=256, scale=0.015803074464201927, zero_point=59, qscheme=torch.per_channel_affine)\n",
       "        (3): ReLU()\n",
       "      )\n",
       "      (dropout): QuantizedDropout(p=0.0, inplace=False)\n",
       "      (add0): QFunctional(\n",
       "        scale=0.0357317179441452, zero_point=70\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "      (add1): QFunctional(\n",
       "        scale=0.054118961095809937, zero_point=63\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "      (mul): QFunctional(\n",
       "        scale=1.0, zero_point=0\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "    (1): SelfAttentionLayer(\n",
       "      (act): ReLU()\n",
       "      (mha): QuantizedMultiheadAttention(\n",
       "        (out_proj): QuantizedLinear(in_features=256, out_features=256, scale=0.017897145822644234, zero_point=67, qscheme=torch.per_channel_affine)\n",
       "        (linear_Q): QuantizedLinear(in_features=256, out_features=256, scale=0.040513280779123306, zero_point=64, qscheme=torch.per_channel_affine)\n",
       "        (linear_K): QuantizedLinear(in_features=256, out_features=256, scale=0.04187820479273796, zero_point=65, qscheme=torch.per_channel_affine)\n",
       "        (linear_V): QuantizedLinear(in_features=256, out_features=256, scale=0.03843288868665695, zero_point=65, qscheme=torch.per_channel_affine)\n",
       "        (q_scaling_product): QFunctional(\n",
       "          scale=1.0, zero_point=0\n",
       "          (activation_post_process): Identity()\n",
       "        )\n",
       "        (quant_attn_output): Quantize(scale=tensor([0.0212]), zero_point=tensor([61]), dtype=torch.quint8)\n",
       "        (quant_attn_output_weights): Quantize(scale=tensor([0.0004]), zero_point=tensor([0]), dtype=torch.quint8)\n",
       "        (dequant_q): DeQuantize()\n",
       "        (dequant_k): DeQuantize()\n",
       "        (dequant_v): DeQuantize()\n",
       "      )\n",
       "      (norm0): QuantizedLayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm1): QuantizedLayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (seq): Sequential(\n",
       "        (0): QuantizedLinear(in_features=256, out_features=256, scale=0.04201672598719597, zero_point=63, qscheme=torch.per_channel_affine)\n",
       "        (1): ReLU()\n",
       "        (2): QuantizedLinear(in_features=256, out_features=256, scale=0.02021423727273941, zero_point=55, qscheme=torch.per_channel_affine)\n",
       "        (3): ReLU()\n",
       "      )\n",
       "      (dropout): QuantizedDropout(p=0.0, inplace=False)\n",
       "      (add0): QFunctional(\n",
       "        scale=0.05663720518350601, zero_point=65\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "      (add1): QFunctional(\n",
       "        scale=0.05707407742738724, zero_point=63\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "      (mul): QFunctional(\n",
       "        scale=1.0, zero_point=0\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (conv_reg): ModuleList(\n",
       "    (0): SelfAttentionLayer(\n",
       "      (act): ReLU()\n",
       "      (mha): QuantizedMultiheadAttention(\n",
       "        (out_proj): QuantizedLinear(in_features=256, out_features=256, scale=0.006987292319536209, zero_point=66, qscheme=torch.per_channel_affine)\n",
       "        (linear_Q): QuantizedLinear(in_features=256, out_features=256, scale=0.022741422057151794, zero_point=65, qscheme=torch.per_channel_affine)\n",
       "        (linear_K): QuantizedLinear(in_features=256, out_features=256, scale=0.0231480710208416, zero_point=64, qscheme=torch.per_channel_affine)\n",
       "        (linear_V): QuantizedLinear(in_features=256, out_features=256, scale=0.024837197735905647, zero_point=72, qscheme=torch.per_channel_affine)\n",
       "        (q_scaling_product): QFunctional(\n",
       "          scale=1.0, zero_point=0\n",
       "          (activation_post_process): Identity()\n",
       "        )\n",
       "        (quant_attn_output): Quantize(scale=tensor([0.0094]), zero_point=tensor([60]), dtype=torch.quint8)\n",
       "        (quant_attn_output_weights): Quantize(scale=tensor([0.0001]), zero_point=tensor([0]), dtype=torch.quint8)\n",
       "        (dequant_q): DeQuantize()\n",
       "        (dequant_k): DeQuantize()\n",
       "        (dequant_v): DeQuantize()\n",
       "      )\n",
       "      (norm0): QuantizedLayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm1): QuantizedLayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (seq): Sequential(\n",
       "        (0): QuantizedLinear(in_features=256, out_features=256, scale=0.03622797504067421, zero_point=66, qscheme=torch.per_channel_affine)\n",
       "        (1): ReLU()\n",
       "        (2): QuantizedLinear(in_features=256, out_features=256, scale=0.015089426189661026, zero_point=64, qscheme=torch.per_channel_affine)\n",
       "        (3): ReLU()\n",
       "      )\n",
       "      (dropout): QuantizedDropout(p=0.0, inplace=False)\n",
       "      (add0): QFunctional(\n",
       "        scale=0.037603043019771576, zero_point=70\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "      (add1): QFunctional(\n",
       "        scale=0.06792785972356796, zero_point=64\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "      (mul): QFunctional(\n",
       "        scale=1.0, zero_point=0\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "    (1): SelfAttentionLayer(\n",
       "      (act): ReLU()\n",
       "      (mha): QuantizedMultiheadAttention(\n",
       "        (out_proj): QuantizedLinear(in_features=256, out_features=256, scale=0.012880779802799225, zero_point=64, qscheme=torch.per_channel_affine)\n",
       "        (linear_Q): QuantizedLinear(in_features=256, out_features=256, scale=0.03923025727272034, zero_point=67, qscheme=torch.per_channel_affine)\n",
       "        (linear_K): QuantizedLinear(in_features=256, out_features=256, scale=0.04177446663379669, zero_point=62, qscheme=torch.per_channel_affine)\n",
       "        (linear_V): QuantizedLinear(in_features=256, out_features=256, scale=0.040986567735672, zero_point=66, qscheme=torch.per_channel_affine)\n",
       "        (q_scaling_product): QFunctional(\n",
       "          scale=1.0, zero_point=0\n",
       "          (activation_post_process): Identity()\n",
       "        )\n",
       "        (quant_attn_output): Quantize(scale=tensor([0.0206]), zero_point=tensor([72]), dtype=torch.quint8)\n",
       "        (quant_attn_output_weights): Quantize(scale=tensor([0.0003]), zero_point=tensor([0]), dtype=torch.quint8)\n",
       "        (dequant_q): DeQuantize()\n",
       "        (dequant_k): DeQuantize()\n",
       "        (dequant_v): DeQuantize()\n",
       "      )\n",
       "      (norm0): QuantizedLayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm1): QuantizedLayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (seq): Sequential(\n",
       "        (0): QuantizedLinear(in_features=256, out_features=256, scale=0.03723521530628204, zero_point=65, qscheme=torch.per_channel_affine)\n",
       "        (1): ReLU()\n",
       "        (2): QuantizedLinear(in_features=256, out_features=256, scale=0.014803867787122726, zero_point=59, qscheme=torch.per_channel_affine)\n",
       "        (3): ReLU()\n",
       "      )\n",
       "      (dropout): QuantizedDropout(p=0.0, inplace=False)\n",
       "      (add0): QFunctional(\n",
       "        scale=0.06730220466852188, zero_point=61\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "      (add1): QFunctional(\n",
       "        scale=0.06438025832176208, zero_point=62\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "      (mul): QFunctional(\n",
       "        scale=1.0, zero_point=0\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (nn_id): Sequential(\n",
       "    (0): QuantizedLinear(in_features=273, out_features=256, scale=4.907003402709961, zero_point=66, qscheme=torch.per_channel_affine)\n",
       "    (1): ReLU()\n",
       "    (2): QuantizedLayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    (3): QuantizedDropout(p=0.0, inplace=False)\n",
       "    (4): QuantizedLinear(in_features=256, out_features=6, scale=0.03486904129385948, zero_point=50, qscheme=torch.per_channel_affine)\n",
       "  )\n",
       "  (nn_pt): RegressionOutput(\n",
       "    (dequant): DeQuantize()\n",
       "    (nn): Sequential(\n",
       "      (0): QuantizedLinear(in_features=279, out_features=256, scale=5.123387813568115, zero_point=69, qscheme=torch.per_channel_affine)\n",
       "      (1): ReLU()\n",
       "      (2): QuantizedLayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (3): QuantizedDropout(p=0.0, inplace=False)\n",
       "      (4): QuantizedLinear(in_features=256, out_features=1, scale=0.0075817410834133625, zero_point=112, qscheme=torch.per_channel_affine)\n",
       "    )\n",
       "  )\n",
       "  (nn_eta): RegressionOutput(\n",
       "    (dequant): DeQuantize()\n",
       "    (nn): Sequential(\n",
       "      (0): QuantizedLinear(in_features=279, out_features=256, scale=4.423364162445068, zero_point=69, qscheme=torch.per_channel_affine)\n",
       "      (1): ReLU()\n",
       "      (2): QuantizedLayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (3): QuantizedDropout(p=0.0, inplace=False)\n",
       "      (4): QuantizedLinear(in_features=256, out_features=1, scale=0.0031506186351180077, zero_point=66, qscheme=torch.per_channel_affine)\n",
       "    )\n",
       "  )\n",
       "  (nn_sin_phi): RegressionOutput(\n",
       "    (dequant): DeQuantize()\n",
       "    (nn): Sequential(\n",
       "      (0): QuantizedLinear(in_features=279, out_features=256, scale=4.739449977874756, zero_point=65, qscheme=torch.per_channel_affine)\n",
       "      (1): ReLU()\n",
       "      (2): QuantizedLayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (3): QuantizedDropout(p=0.0, inplace=False)\n",
       "      (4): QuantizedLinear(in_features=256, out_features=1, scale=0.004237048793584108, zero_point=67, qscheme=torch.per_channel_affine)\n",
       "    )\n",
       "  )\n",
       "  (nn_cos_phi): RegressionOutput(\n",
       "    (dequant): DeQuantize()\n",
       "    (nn): Sequential(\n",
       "      (0): QuantizedLinear(in_features=279, out_features=256, scale=4.489536285400391, zero_point=63, qscheme=torch.per_channel_affine)\n",
       "      (1): ReLU()\n",
       "      (2): QuantizedLayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (3): QuantizedDropout(p=0.0, inplace=False)\n",
       "      (4): QuantizedLinear(in_features=256, out_features=1, scale=0.003441917011514306, zero_point=62, qscheme=torch.per_channel_affine)\n",
       "    )\n",
       "  )\n",
       "  (nn_energy): RegressionOutput(\n",
       "    (dequant): DeQuantize()\n",
       "    (nn): Sequential(\n",
       "      (0): QuantizedLinear(in_features=279, out_features=256, scale=4.966396331787109, zero_point=65, qscheme=torch.per_channel_affine)\n",
       "      (1): ReLU()\n",
       "      (2): QuantizedLayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (3): QuantizedDropout(p=0.0, inplace=False)\n",
       "      (4): QuantizedLinear(in_features=256, out_features=1, scale=0.00821786280721426, zero_point=101, qscheme=torch.per_channel_affine)\n",
       "    )\n",
       "  )\n",
       "  (quant): QuantizeFeaturesStub(\n",
       "    (quants): ModuleList(\n",
       "      (0): Quantize(scale=tensor([0.0157]), zero_point=tensor([0]), dtype=torch.quint8)\n",
       "      (1): Quantize(scale=tensor([0.0489]), zero_point=tensor([46]), dtype=torch.quint8)\n",
       "      (2): Quantize(scale=tensor([0.0315]), zero_point=tensor([70]), dtype=torch.quint8)\n",
       "      (3-4): 2 x Quantize(scale=tensor([0.0157]), zero_point=tensor([64]), dtype=torch.quint8)\n",
       "      (5): Quantize(scale=tensor([0.0510]), zero_point=tensor([39]), dtype=torch.quint8)\n",
       "      (6): Quantize(scale=tensor([30.6385]), zero_point=tensor([74]), dtype=torch.quint8)\n",
       "      (7): Quantize(scale=tensor([29.3899]), zero_point=tensor([65]), dtype=torch.quint8)\n",
       "      (8): Quantize(scale=tensor([44.5062]), zero_point=tensor([63]), dtype=torch.quint8)\n",
       "      (9): Quantize(scale=tensor([0.0229]), zero_point=tensor([0]), dtype=torch.quint8)\n",
       "      (10): Quantize(scale=tensor([2.6954]), zero_point=tensor([0]), dtype=torch.quint8)\n",
       "      (11): Quantize(scale=tensor([0.1419]), zero_point=tensor([31]), dtype=torch.quint8)\n",
       "      (12): Quantize(scale=tensor([0.0875]), zero_point=tensor([49]), dtype=torch.quint8)\n",
       "      (13): Quantize(scale=tensor([4.2263]), zero_point=tensor([0]), dtype=torch.quint8)\n",
       "      (14): Quantize(scale=tensor([3.6075]), zero_point=tensor([2]), dtype=torch.quint8)\n",
       "      (15): Quantize(scale=tensor([2.6614]), zero_point=tensor([0]), dtype=torch.quint8)\n",
       "      (16): Quantize(scale=tensor([6.0954]), zero_point=tensor([0]), dtype=torch.quint8)\n",
       "      (17-19): 3 x Quantize(scale=tensor([1.]), zero_point=tensor([0]), dtype=torch.quint8)\n",
       "    )\n",
       "  )\n",
       "  (dequant_id): DeQuantize()\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_int8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698dc268",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "acbb14a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=126.59\n",
      "Loss=125.94\n",
      "Loss=125.11\n",
      "Loss=127.54\n",
      "Loss=125.67\n",
      "Loss=126.45\n",
      "Loss=127.67\n",
      "Loss=127.13\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/sraj/ipykernel_649402/1286620476.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mind\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minds_train\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mds_elems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mds_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mind\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mevents_per_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mX_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"X\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0melem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mds_elems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mX_features_padded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_first\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/sraj/ipykernel_649402/1286620476.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mind\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minds_train\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mds_elems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mds_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mind\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mevents_per_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mX_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"X\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0melem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mds_elems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mX_features_padded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_first\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/tensorflow_datasets/core/data_sources/array_record.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, record_key)\u001b[0m\n\u001b[1;32m     93\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mrecord\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_source\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrecord_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m     return self.dataset_info.features.deserialize_example_np(\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0mrecord\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoders\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     )\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/tensorflow_datasets/core/features/top_level_feature.py\u001b[0m in \u001b[0;36mdeserialize_example_np\u001b[0;34m(self, serialized_example, decoders)\u001b[0m\n\u001b[1;32m    156\u001b[0m       \u001b[0mdecoders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m   ) -> utils.NpArrayOrScalarDict:\n\u001b[0;32m--> 158\u001b[0;31m     \u001b[0mexample_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_example_parser_np\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_example\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserialized_example\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode_example_np\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/tensorflow_datasets/core/example_parser.py\u001b[0m in \u001b[0;36mparse_example\u001b[0;34m(self, serialized_example)\u001b[0m\n\u001b[1;32m    109\u001b[0m   ) -> type_utils.NpArrayOrScalarDict:\n\u001b[1;32m    110\u001b[0m     \u001b[0mexample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_example_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFromString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserialized_example\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m     \u001b[0mnp_example\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_features_to_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_example_specs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_as_nest_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp_example\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexample_specs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/tensorflow_datasets/core/example_parser.py\u001b[0m in \u001b[0;36m_features_to_numpy\u001b[0;34m(features, flat_example_specs)\u001b[0m\n\u001b[1;32m    131\u001b[0m   \u001b[0mparsed_example\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m   \u001b[0mfeature_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeature_map\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mflat_example_specs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m       raise KeyError(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "max_events_train = 1000\n",
    "events_per_batch = 10\n",
    "quantized_losses = []\n",
    "\n",
    "# Training loop\n",
    "inds_train = range(0, max_events_train, events_per_batch)\n",
    "for ind in inds_train:\n",
    "    optimizer.zero_grad()\n",
    "    ds_elems = [ds_train[i] for i in range(ind, ind + events_per_batch)]\n",
    "    X_features = [torch.tensor(elem[\"X\"]).to(torch.float32) for elem in ds_elems]\n",
    "    X_features_padded = pad_sequence(X_features, batch_first=True)\n",
    "    y_targets = [torch.tensor(elem[\"ygen\"]).to(torch.float32) for elem in ds_elems]\n",
    "    y_targets_padded = pad_sequence(y_targets, batch_first=True)\n",
    "    \n",
    "    mask = X_features_padded[:, :, 0] != 0\n",
    "\n",
    "    preds = model_int8(X_features_padded, mask)\n",
    "    preds_unpacked = unpack_predictions(preds)\n",
    "    targets_unpacked = unpack_target(y_targets_padded)\n",
    "\n",
    "    loss = mlpf_loss(targets_unpacked, preds_unpacked)\n",
    "    \n",
    "    # Ensure all tensors contributing to the loss have requires_grad = True\n",
    "    for key, value in loss.items():\n",
    "        if value.requires_grad is False:\n",
    "            value.requires_grad = True\n",
    "\n",
    "    loss_total = loss[\"Total\"].sum()  \n",
    "    loss_total.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    current_loss = loss_total.detach().item()\n",
    "    quantized_losses.append(current_loss)\n",
    "    print(\"Loss={:.2f}\".format(current_loss))\n",
    "\n",
    "# Plot\n",
    "plt.plot(quantized_losses)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Quantized Training Loss Curve')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ee44fb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses, label='Fp32')\n",
    "plt.plot(quantized_losses, label='Int8')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Training Loss')\n",
    "plt.legend()\n",
    "# plt.title('Quantized Training Loss Curve')\n",
    "plt.title('x86')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fcc54e9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantized Model Loss with x86: 125.51\n"
     ]
    }
   ],
   "source": [
    "# Assuming X_data and y_targets are your input data and ground truth targets\n",
    "X_data_quantized = [torch.tensor(elem[\"X\"]).to(torch.float32) for elem in ds_elems]\n",
    "X_data_quantized_padded = pad_sequence(X_data_quantized, batch_first=True)\n",
    "\n",
    "mask_quantized = X_data_quantized_padded[:, :, 0] != 0  # Assuming mask is required\n",
    "\n",
    "# Perform inference with the quantized model\n",
    "with torch.no_grad():\n",
    "    preds_quantized = model_int8(X_data_quantized_padded, mask_quantized)\n",
    "\n",
    "# Unpack predictions and targets if necessary\n",
    "preds_quantized_unpacked = unpack_predictions(preds_quantized)\n",
    "targets_unpacked = unpack_target(y_targets_padded)\n",
    "\n",
    "# Compute loss\n",
    "loss_quantized = mlpf_loss(targets_unpacked, preds_quantized_unpacked)\n",
    "\n",
    "# Print the total loss\n",
    "print(\"Quantized Model Loss with x86: {:.2f}\".format(loss_quantized[\"Total\"].item()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653d4c31",
   "metadata": {},
   "source": [
    "**Quantized Model Loss with onednn: 121.74 \\\n",
    "Quantized Model Loss with x86: 125.51 \\\n",
    "Unquantized model loss: 29.26**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d4cbd5",
   "metadata": {},
   "source": [
    "**Dataset Information:**\n",
    "\n",
    "X: the reconstruction input features, i.e. tracks and clusters\n",
    "\n",
    "ygen: the ground truth particles with the features [\"PDG\", \"charge\", \"pt\", \"eta\", \"sin_phi\", \"cos_phi\", \"energy\", \"jet_idx\"], with \"jet_idx\" corresponding to the gen-jet assignment of this particle\n",
    "\n",
    "https://zenodo.org/records/8409592"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06a4896",
   "metadata": {},
   "source": [
    "**To Do:**\n",
    "* ultimately reproduce Fig 9 from the [paper](https://arxiv.org/pdf/2309.06782.pdf), adding additional an int8-quantized MLPF model (e.g. dashed orange line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6b32c680",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 248])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets_unpacked['pt'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a6f53851",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 201])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets_unpacked_unq['pt'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d5e56b7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[29.3308, 16.3776, 11.0753,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [11.4296, 11.2534,  7.4814,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [81.4108, 19.7446,  3.0669,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        ...,\n",
       "        [11.9754, 11.1559,  7.4632,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 2.0538, 11.2622, 11.8753,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 4.5375, 30.6604, 13.4644,  ...,  0.0000,  0.0000,  0.0000]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets_unpacked['pt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "32e1bf30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5.2084, 10.8834,  9.6858,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [12.7611, 10.4114, 10.9317,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [10.4192, 14.1023,  1.7646,  ..., 11.3411,  4.4822,  0.0000],\n",
       "        ...,\n",
       "        [ 3.9776, 19.7735, 11.2324,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 8.0681,  7.6773, 21.1527,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [11.5500, 48.6111,  8.4631,  ...,  0.0000,  0.0000,  0.0000]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets_unpacked_unq['pt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c4ac44d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_val = torch.min(targets_unpacked['pt']).item()\n",
    "max_val = torch.max(targets_unpacked['pt']).item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4ce37d38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 81.4107666015625)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_val, max_val "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bf35c92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_val = torch.min(targets_unpacked_unq['pt']).item()\n",
    "max_val = torch.max(targets_unpacked_unq['pt']).item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fb0a7d18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 81.24093627929688)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_val, max_val "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6033b60a",
   "metadata": {},
   "source": [
    "```python\n",
    "msk_true_particle = torch.unsqueeze((y[\"cls_id\"] != 0).to(dtype=torch.float32), axis=-1)        \n",
    "px = ypred[\"momentum\"][..., 0:1] * ypred[\"momentum\"][..., 3:4] * msk_true_particle\n",
    "py = ypred[\"momentum\"][..., 0:1] * ypred[\"momentum\"][..., 2:3] * msk_true_particle\n",
    "pred_met = torch.sqrt(torch.sum(px, axis=-2) ** 2 + torch.sum(py, axis=-2) ** 2)\n",
    "\n",
    "px = y[\"momentum\"][..., 0:1] * y[\"momentum\"][..., 3:4] * msk_true_particle\n",
    "py = y[\"momentum\"][..., 0:1] * y[\"momentum\"][..., 2:3] * msk_true_particle\n",
    "true_met = torch.sqrt(torch.sum(px, axis=-2) ** 2 + torch.sum(py, axis=-2) ** 2)\n",
    "```\n",
    "        \n",
    "        \n",
    "if you do something like this, you can compute the true and predicted MET\n",
    "\n",
    "\n",
    "and compare their distributions and response=pred_met/true_met"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "eb961381",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "msk_true_particle = torch.unsqueeze((targets_unpacked_unq[\"cls_id\"] != 0).to(dtype=torch.float32), axis=-1)\n",
    "px = preds_unpacked_unq[\"momentum\"][..., 0:1] * preds_unpacked_unq[\"momentum\"][..., 3:4] * msk_true_particle\n",
    "py = preds_unpacked_unq[\"momentum\"][..., 0:1] * preds_unpacked_unq[\"momentum\"][..., 2:3] * msk_true_particle\n",
    "# pred_met is \\sqrt(px**2+py**2)\n",
    "px_sum = torch.sum(px, axis=-2)\n",
    "py_sum = torch.sum(py, axis=-2)\n",
    "pred_met = torch.sqrt(px_sum ** 2 + py_sum ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "27ffa730",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[17.0119],\n",
       "        [61.4280],\n",
       "        [30.6598],\n",
       "        [16.8550],\n",
       "        [ 3.2127],\n",
       "        [73.5539],\n",
       "        [90.8664],\n",
       "        [57.6672],\n",
       "        [40.3295],\n",
       "        [ 3.8403]], grad_fn=<SqrtBackward0>)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_met"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0926d19d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/sraj/ipykernel_649402/2019659273.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Compute msk_true_particle for y tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmsk_true_particle_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"cls_id\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Compute px for y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpx_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"momentum\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"momentum\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmsk_true_particle_y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y' is not defined"
     ]
    }
   ],
   "source": [
    "# Compute msk_true_particle for y tensor\n",
    "msk_true_particle_y = torch.unsqueeze((yp[\"cls_id\"] != 0).to(dtype=torch.float32), axis=-1)\n",
    "\n",
    "# Compute px for y\n",
    "px_y = y[\"momentum\"][..., 0:1] * y[\"momentum\"][..., 3:4] * msk_true_particle_y\n",
    "\n",
    "# Compute py for y\n",
    "py_y = y[\"momentum\"][..., 0:1] * y[\"momentum\"][..., 2:3] * msk_true_particle_y\n",
    "\n",
    "# Compute true_met\n",
    "px_sum_y = torch.sum(px_y, axis=-2)\n",
    "py_sum_y = torch.sum(py_y, axis=-2)\n",
    "true_met = torch.sqrt(px_sum_y ** 2 + py_sum_y ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2aa963c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.0000e+00,  1.0000e+00,  2.1273e+01,  ...,  9.6941e-01,\n",
       "           2.2023e+01,  3.0000e+00],\n",
       "         [ 1.0000e+00,  1.0000e+00,  1.8855e+01,  ..., -5.9503e-01,\n",
       "           2.0037e+01,  2.0000e+00],\n",
       "         [ 1.0000e+00,  1.0000e+00,  1.2961e+01,  ...,  4.2384e-01,\n",
       "           1.2973e+01,  5.0000e+00],\n",
       "         ...,\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "        [[ 1.0000e+00,  1.0000e+00,  1.6827e+00,  ..., -9.9965e-01,\n",
       "           1.8183e+00,  3.0000e+00],\n",
       "         [ 1.0000e+00, -1.0000e+00,  1.0281e+01,  ..., -3.4482e-02,\n",
       "           1.0299e+01,  2.0000e+00],\n",
       "         [ 1.0000e+00, -1.0000e+00,  1.0511e+01,  ...,  9.0784e-01,\n",
       "           1.4937e+01,  4.0000e+00],\n",
       "         ...,\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "        [[ 1.0000e+00, -1.0000e+00,  6.7413e+00,  ...,  2.2737e-01,\n",
       "           8.1888e+00,  1.0000e+00],\n",
       "         [ 1.0000e+00, -1.0000e+00,  8.2358e+00,  ..., -9.8171e-01,\n",
       "           8.4732e+00,  3.0000e+00],\n",
       "         [ 1.0000e+00,  1.0000e+00,  4.7458e+00,  ..., -1.4743e-01,\n",
       "           4.7611e+00,  4.0000e+00],\n",
       "         ...,\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 5.0000e+00,  1.0000e+00,  4.0206e+01,  ...,  8.2111e-01,\n",
       "           6.3450e+01,  2.0000e+00],\n",
       "         [ 5.0000e+00, -1.0000e+00,  2.5845e+01,  ...,  5.2157e-01,\n",
       "           7.2160e+01,  4.0000e+00],\n",
       "         [ 1.0000e+00, -1.0000e+00,  1.9983e+01,  ..., -9.4931e-01,\n",
       "           2.0719e+01,  3.0000e+00],\n",
       "         ...,\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "        [[ 4.0000e+00, -1.0000e+00,  3.7227e+01,  ...,  9.1730e-01,\n",
       "           3.7384e+01,  3.0000e+00],\n",
       "         [ 1.0000e+00, -1.0000e+00,  5.4352e+00,  ...,  2.3121e-01,\n",
       "           2.3424e+01,  4.0000e+00],\n",
       "         [ 1.0000e+00,  1.0000e+00,  1.2910e+01,  ...,  9.3100e-01,\n",
       "           1.2942e+01,  2.0000e+00],\n",
       "         ...,\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "        [[ 1.0000e+00, -1.0000e+00,  2.3284e+01,  ..., -7.3236e-01,\n",
       "           2.3316e+01,  3.0000e+00],\n",
       "         [ 4.0000e+00,  1.0000e+00,  2.5830e+01,  ...,  9.3863e-01,\n",
       "           2.6304e+01,  4.0000e+00],\n",
       "         [ 1.0000e+00,  1.0000e+00,  1.6682e+01,  ..., -7.1535e-01,\n",
       "           1.6757e+01,  3.0000e+00],\n",
       "         ...,\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00]]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_targets_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947355b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6b1c8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ee1d71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae6e557",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571c124f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02082726",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5df5ae0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae490d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca4e67e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23256421",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "42649ec7",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88b1f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fp16 = model.to(torch.float16)\n",
    "\n",
    "model_fp16\n",
    "\n",
    "model_fp16 = model.to(torch.float16)\n",
    "model_quantized_fp16 = torch.quantization.quantize_dynamic(\n",
    "    model_fp16, {torch.nn.Linear}, dtype=torch.float16\n",
    ")\n",
    "\n",
    "\n",
    "model_quantized_fp16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf66a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_events_train = 1000\n",
    "events_per_batch = 10\n",
    "quantized_losses = []\n",
    "\n",
    "# Training loop\n",
    "inds_train = range(0, max_events_train, events_per_batch)\n",
    "for ind in inds_train:\n",
    "    optimizer.zero_grad()\n",
    "    ds_elems = [ds_train[i] for i in range(ind, ind + events_per_batch)]\n",
    "    X_features = [torch.tensor(elem[\"X\"]).to(torch.float32) for elem in ds_elems]\n",
    "    X_features_padded = pad_sequence(X_features, batch_first=True)\n",
    "    y_targets = [torch.tensor(elem[\"ygen\"]).to(torch.float32) for elem in ds_elems]\n",
    "    y_targets_padded = pad_sequence(y_targets, batch_first=True)\n",
    "    \n",
    "    mask = X_features_padded[:, :, 0] != 0\n",
    "\n",
    "    preds = model_int8(X_features_padded, mask)\n",
    "    preds_unpacked = unpack_predictions(preds)\n",
    "    targets_unpacked = unpack_target(y_targets_padded)\n",
    "\n",
    "    loss = mlpf_loss(targets_unpacked, preds_unpacked)\n",
    "    \n",
    "    # Ensure all tensors contributing to the loss have requires_grad = True\n",
    "    for key, value in loss.items():\n",
    "        if value.requires_grad is False:\n",
    "            value.requires_grad = True\n",
    "\n",
    "    # Convert the loss tensor to a scalar before calling backward\n",
    "    loss_total = loss[\"Total\"].sum()  \n",
    "    loss_total.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    current_loss = loss_total.detach().item()\n",
    "    losses.append(current_loss)\n",
    "    print(\"Loss={:.2f}\".format(current_loss))\n",
    "\n",
    "\n",
    "plt.plot(quantized_losses)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Quantized Training Loss Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44174bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 1\n",
    "for epoch in range(num_epochs):\n",
    "    losses_quantized = []\n",
    "\n",
    "    for ind in inds_train:\n",
    "        optimizer.zero_grad()\n",
    "        ds_elems = [ds_train[i] for i in range(ind, ind + events_per_batch)]\n",
    "        X_features = [torch.tensor(elem[\"X\"]).to(torch.float32) for elem in ds_elems]\n",
    "        X_features_padded = pad_sequence(X_features, batch_first=True)\n",
    "        y_targets = [torch.tensor(elem[\"ygen\"]).to(torch.float32) for elem in ds_elems]\n",
    "        y_targets_padded = pad_sequence(y_targets, batch_first=True)\n",
    "\n",
    "        mask = X_features_padded[:, :, 0] != 0\n",
    "\n",
    "        preds = model_int8(X_features_padded, mask)  # Use quantized model here\n",
    "        preds_unpacked = unpack_predictions(preds)\n",
    "        targets_unpacked = unpack_target(y_targets_padded)\n",
    "        loss = mlpf_loss(targets_unpacked, preds_unpacked)\n",
    "        \n",
    "        # Ensure all tensors contributing to the loss have requires_grad = True\n",
    "        for key, value in loss.items():\n",
    "            if value.requires_grad is False:\n",
    "                value.requires_grad = True\n",
    "        \n",
    "        loss[\"Total\"].backward()\n",
    "        optimizer.step()\n",
    "        current_loss = loss[\"Total\"].detach().item()\n",
    "        losses_quantized.append(current_loss)\n",
    "        print(\"Iteration: {}, Loss: {:.2f}\".format(ind, loss[\"Total\"].detach().item()))\n",
    "\n",
    "    # Plot training loss\n",
    "    plt.plot(losses_quantized)\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training Loss Curve (Quantized Model) - Epoch {}'.format(epoch + 1))\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8f9c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting both losses on the same plot\n",
    "plt.plot(losses, label='Original Model')\n",
    "plt.plot(quantized_losses, label='Quantized Model')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss Curve')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "595acac5",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/sraj/ipykernel_649402/1211407540.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_FEATURES_CL\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pT'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b0edf1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
