{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b1d3a1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.set_num_threads(1)\n",
    "from torch import nn, Tensor\n",
    "import tensorflow_datasets as tfds\n",
    "import torch_geometric\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4104391c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../../mlpf/tensorflow_datasets/\"\n",
    "dataset = \"clic_edm_ttbar_pf\"\n",
    "\n",
    "#Load dataset\n",
    "builder = tfds.builder(dataset, data_dir=data_dir)\n",
    "ds_train = builder.as_data_source(split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cc706b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_FEATURES_TRK = [\n",
    "    \"elemtype\",\n",
    "    \"pt\",\n",
    "    \"eta\",\n",
    "    \"sin_phi\",\n",
    "    \"cos_phi\",\n",
    "    \"p\",\n",
    "    \"chi2\",\n",
    "    \"ndf\",\n",
    "    \"dEdx\",\n",
    "    \"dEdxError\",\n",
    "    \"radiusOfInnermostHit\",\n",
    "    \"tanLambda\",\n",
    "    \"D0\",\n",
    "    \"omega\",\n",
    "    \"Z0\",\n",
    "    \"time\",\n",
    "]\n",
    "X_FEATURES_CL = [\n",
    "    \"elemtype\",\n",
    "    \"et\",\n",
    "    \"eta\",\n",
    "    \"sin_phi\",\n",
    "    \"cos_phi\",\n",
    "    \"energy\",\n",
    "    \"position.x\",\n",
    "    \"position.y\",\n",
    "    \"position.z\",\n",
    "    \"iTheta\",\n",
    "    \"energy_ecal\",\n",
    "    \"energy_hcal\",\n",
    "    \"energy_other\",\n",
    "    \"num_hits\",\n",
    "    \"sigma_x\",\n",
    "    \"sigma_y\",\n",
    "    \"sigma_z\",\n",
    "]\n",
    "Y_FEATURES = [\"cls_id\", \"charge\", \"pt\", \"eta\", \"sin_phi\", \"cos_phi\", \"energy\"]\n",
    "Y_CLASSES = [0, 211, 130, 22, 11, 13]\n",
    "\n",
    "INPUT_DIM = max(len(X_FEATURES_TRK), len(X_FEATURES_CL))\n",
    "NUM_CLASSES = len(Y_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4b8d66ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    \"\"\"Focal Loss, as described in https://arxiv.org/abs/1708.02002.\n",
    "    It is essentially an enhancement to cross entropy loss and is\n",
    "    useful for classification tasks when there is a large class imbalance.\n",
    "    x is expected to contain raw, unnormalized scores for each class.\n",
    "    y is expected to contain class labels.\n",
    "    Shape:\n",
    "        - x: (batch_size, C) or (batch_size, C, d1, d2, ..., dK), K > 0.\n",
    "        - y: (batch_size,) or (batch_size, d1, d2, ..., dK), K > 0.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, alpha = None, gamma = 0.0, reduction = \"mean\", ignore_index = -100\n",
    "    ):\n",
    "        \"\"\"Constructor.\n",
    "        Args:\n",
    "            alpha (Tensor, optional): Weights for each class. Defaults to None.\n",
    "            gamma (float, optional): A constant, as described in the paper.\n",
    "                Defaults to 0.\n",
    "            reduction (str, optional): 'mean', 'sum' or 'none'.\n",
    "                Defaults to 'mean'.\n",
    "            ignore_index (int, optional): class label to ignore.\n",
    "                Defaults to -100.\n",
    "        \"\"\"\n",
    "        if reduction not in (\"mean\", \"sum\", \"none\"):\n",
    "            raise ValueError('Reduction must be one of: \"mean\", \"sum\", \"none\".')\n",
    "\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "        self.nll_loss = nn.NLLLoss(weight=alpha, reduction=\"none\")\n",
    "\n",
    "    def __repr__(self):\n",
    "        arg_keys = [\"alpha\", \"gamma\", \"reduction\"]\n",
    "        arg_vals = [self.__dict__[k] for k in arg_keys]\n",
    "        arg_strs = [f\"{k}={v!r}\" for k, v in zip(arg_keys, arg_vals)]\n",
    "        arg_str = \", \".join(arg_strs)\n",
    "        return f\"{type(self).__name__}({arg_str})\"\n",
    "\n",
    "    def forward(self, x: Tensor, y: Tensor) -> Tensor:\n",
    "        if x.ndim > 2:\n",
    "            # (N, C, d1, d2, ..., dK) --> (N * d1 * ... * dK, C)\n",
    "            c = x.shape[1]\n",
    "            x = x.permute(0, *range(2, x.ndim), 1).reshape(-1, c)\n",
    "            # (N, d1, d2, ..., dK) --> (N * d1 * ... * dK,)\n",
    "            y = y.view(-1)\n",
    "\n",
    "        # compute weighted cross entropy term: -alpha * log(pt)\n",
    "        # (alpha is already part of self.nll_loss)\n",
    "        log_p = F.log_softmax(x, dim=-1)\n",
    "        ce = self.nll_loss(log_p, y)\n",
    "\n",
    "        # get true class column from each row\n",
    "        # this is slow due to indexing\n",
    "        # all_rows = torch.arange(len(x))\n",
    "        # log_pt = log_p[all_rows, y]\n",
    "        log_pt = torch.gather(log_p, 1, y.unsqueeze(axis=-1)).squeeze(axis=-1)\n",
    "\n",
    "        # compute focal term: (1 - pt)^gamma\n",
    "        pt = log_pt.exp()\n",
    "        focal_term = (1 - pt) ** self.gamma\n",
    "\n",
    "        # the full loss: -alpha * ((1 - pt)^gamma) * log(pt)\n",
    "        loss = focal_term * ce\n",
    "\n",
    "        if self.reduction == \"mean\":\n",
    "            loss = loss.mean()\n",
    "        elif self.reduction == \"sum\":\n",
    "            loss = loss.sum()\n",
    "\n",
    "        return loss\n",
    "\n",
    "class QuantizeFeaturesStub(torch.nn.Module):\n",
    "    def __init__(self, num_feats):\n",
    "        super().__init__()\n",
    "        self.num_feats = num_feats\n",
    "        self.quants = torch.nn.ModuleList()\n",
    "        for ifeat in range(self.num_feats):\n",
    "            self.quants.append(torch.ao.quantization.QuantStub())\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.cat([self.quants[ifeat](x[..., ifeat:ifeat+1]) for ifeat in range(self.num_feats)], axis=-1)\n",
    "        \n",
    "def mlpf_loss(y, ypred):\n",
    "    loss = {}\n",
    "    loss_obj_id = FocalLoss(gamma=2.0, reduction=\"none\")\n",
    "\n",
    "    msk_true_particle = torch.unsqueeze((y[\"cls_id\"] != 0).to(dtype=torch.float32), axis=-1)\n",
    "    npart = y[\"pt\"].numel()\n",
    "\n",
    "    ypred[\"momentum\"] = ypred[\"momentum\"] * msk_true_particle\n",
    "    y[\"momentum\"] = y[\"momentum\"] * msk_true_particle\n",
    "\n",
    "    ypred[\"cls_id_onehot\"] = ypred[\"cls_id_onehot\"].permute((0, 2, 1))\n",
    "\n",
    "    loss_classification = 100 * loss_obj_id(ypred[\"cls_id_onehot\"], y[\"cls_id\"]).reshape(y[\"cls_id\"].shape)\n",
    "    loss_regression = 10 * torch.nn.functional.huber_loss(ypred[\"momentum\"], y[\"momentum\"], reduction=\"none\")\n",
    "    \n",
    "    # average over all particles\n",
    "    loss[\"Classification\"] = loss_classification.sum() / npart\n",
    "    loss[\"Regression\"] = loss_regression.sum() / npart\n",
    "\n",
    "    loss[\"Total\"] = loss[\"Classification\"] + loss[\"Regression\"]\n",
    "    return loss\n",
    "    \n",
    "class SelfAttentionLayer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        embedding_dim=128,\n",
    "        num_heads=2,\n",
    "        width=128,\n",
    "        dropout_mha=0.1,\n",
    "        dropout_ff=0.1,\n",
    "        attention_type=\"efficient\",\n",
    "    ):\n",
    "        super(SelfAttentionLayer, self).__init__()\n",
    "\n",
    "        self.attention_type = attention_type\n",
    "        self.act = nn.ReLU()\n",
    "        self.mha = torch.nn.MultiheadAttention(embedding_dim, num_heads, dropout=dropout_mha, batch_first=True)\n",
    "        self.norm0 = torch.nn.LayerNorm(embedding_dim)\n",
    "        self.norm1 = torch.nn.LayerNorm(embedding_dim)\n",
    "        self.seq = torch.nn.Sequential(\n",
    "            nn.Linear(embedding_dim, width), self.act, nn.Linear(width, embedding_dim), self.act\n",
    "        )\n",
    "\n",
    "        self.dropout = torch.nn.Dropout(dropout_ff)\n",
    "\n",
    "        self.add0 = torch.ao.nn.quantized.FloatFunctional()\n",
    "        self.add1 = torch.ao.nn.quantized.FloatFunctional()\n",
    "        self.mul = torch.ao.nn.quantized.FloatFunctional()\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        mha_out = self.mha(x, x, x, need_weights=False)[0]\n",
    "        x = self.add0.add(x, mha_out)\n",
    "        x = self.norm0(x)\n",
    "        x = self.add1.add(x, self.seq(x))\n",
    "        x = self.norm1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.mul.mul(x, mask.to(x.dtype).unsqueeze(-1))\n",
    "        return x\n",
    "\n",
    "class RegressionOutput(nn.Module):\n",
    "    def __init__(self, embed_dim, width, act, dropout):\n",
    "        super(RegressionOutput, self).__init__()\n",
    "        self.dequant = torch.ao.quantization.DeQuantStub()\n",
    "        self.nn = ffn(embed_dim, 1, width, act, dropout)\n",
    "\n",
    "    def forward(self, elems, x, orig_value):\n",
    "        nn_out = self.nn(x)\n",
    "        nn_out = self.dequant(nn_out)\n",
    "        return orig_value + nn_out\n",
    "\n",
    "def ffn(input_dim, output_dim, width, act, dropout):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(input_dim, width),\n",
    "        act(),\n",
    "        torch.nn.LayerNorm(width),\n",
    "        nn.Dropout(dropout),\n",
    "        nn.Linear(width, output_dim),\n",
    "    )\n",
    "\n",
    "def transform_batch(Xbatch):\n",
    "    Xbatch = Xbatch.clone()\n",
    "    Xbatch[..., 1] = torch.log(Xbatch[..., 1])\n",
    "    Xbatch[..., 5] = torch.log(Xbatch[..., 5])\n",
    "    Xbatch[torch.isnan(Xbatch)] = 0.0\n",
    "    Xbatch[torch.isinf(Xbatch)] = 0.0\n",
    "    return Xbatch\n",
    "    \n",
    "def unpack_target(y):\n",
    "    ret = {}\n",
    "    ret[\"cls_id\"] = y[..., 0].long()\n",
    "\n",
    "    for i, feat in enumerate(Y_FEATURES):\n",
    "        if i >= 2:  # skip the cls and charge as they are defined above\n",
    "            ret[feat] = y[..., i].to(dtype=torch.float32)\n",
    "    ret[\"phi\"] = torch.atan2(ret[\"sin_phi\"], ret[\"cos_phi\"])\n",
    "    \n",
    "    # note ~ momentum = [\"pt\", \"eta\", \"sin_phi\", \"cos_phi\", \"energy\"]\n",
    "    ret[\"momentum\"] = y[..., 2:7].to(dtype=torch.float32)\n",
    "    ret[\"p4\"] = torch.cat(\n",
    "        [ret[\"pt\"].unsqueeze(1), ret[\"eta\"].unsqueeze(1), ret[\"phi\"].unsqueeze(1), ret[\"energy\"].unsqueeze(1)], axis=1\n",
    "    )\n",
    "\n",
    "    return ret\n",
    "\n",
    "\n",
    "def unpack_predictions(preds):\n",
    "    ret = {}\n",
    "    ret[\"cls_id_onehot\"], ret[\"momentum\"] = preds\n",
    "\n",
    "    ret[\"pt\"] = ret[\"momentum\"][..., 0]\n",
    "    ret[\"eta\"] = ret[\"momentum\"][..., 1]\n",
    "    ret[\"sin_phi\"] = ret[\"momentum\"][..., 2]\n",
    "    ret[\"cos_phi\"] = ret[\"momentum\"][..., 3]\n",
    "    ret[\"energy\"] = ret[\"momentum\"][..., 4]\n",
    "\n",
    "    ret[\"cls_id\"] = torch.argmax(ret[\"cls_id_onehot\"], axis=-1)\n",
    "    ret[\"phi\"] = torch.atan2(ret[\"sin_phi\"], ret[\"cos_phi\"])\n",
    "    ret[\"p4\"] = torch.cat(\n",
    "        [\n",
    "            ret[\"pt\"].unsqueeze(axis=-1),\n",
    "            ret[\"eta\"].unsqueeze(axis=-1),\n",
    "            ret[\"phi\"].unsqueeze(axis=-1),\n",
    "            ret[\"energy\"].unsqueeze(axis=-1),\n",
    "        ],\n",
    "        axis=-1,\n",
    "    )\n",
    "\n",
    "    return ret\n",
    "\n",
    "class MLPF(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim=16,\n",
    "        num_classes=6,\n",
    "        num_convs=2,\n",
    "        dropout_ff=0.0,\n",
    "        dropout_conv_reg_mha=0.0,\n",
    "        dropout_conv_reg_ff=0.0,\n",
    "        dropout_conv_id_mha=0.0,\n",
    "        dropout_conv_id_ff=0.0,\n",
    "        num_heads=16,\n",
    "        head_dim=16,\n",
    "        elemtypes=[0,1,2],\n",
    "    ):\n",
    "        super(MLPF, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.act = nn.ReLU  # Change activation function here\n",
    "        self.elemtypes = elemtypes\n",
    "        self.num_elemtypes = len(self.elemtypes)\n",
    "\n",
    "        embedding_dim = num_heads * head_dim\n",
    "        width = num_heads * head_dim\n",
    "        \n",
    "        self.nn0_id = ffn(self.input_dim, embedding_dim, width, self.act, dropout_ff)\n",
    "        self.nn0_reg = ffn(self.input_dim, embedding_dim, width, self.act, dropout_ff)\n",
    "        \n",
    "        self.conv_id = nn.ModuleList()\n",
    "        self.conv_reg = nn.ModuleList()\n",
    "\n",
    "        for i in range(num_convs):\n",
    "            self.conv_id.append(\n",
    "                SelfAttentionLayer(\n",
    "                    embedding_dim=embedding_dim,\n",
    "                    num_heads=num_heads,\n",
    "                    width=width,\n",
    "                    dropout_mha=dropout_conv_id_mha,\n",
    "                    dropout_ff=dropout_conv_id_ff,\n",
    "                )\n",
    "            )\n",
    "            self.conv_reg.append(\n",
    "                SelfAttentionLayer(\n",
    "                    embedding_dim=embedding_dim,\n",
    "                    num_heads=num_heads,\n",
    "                    width=width,\n",
    "                    dropout_mha=dropout_conv_reg_mha,\n",
    "                    dropout_ff=dropout_conv_reg_ff,\n",
    "                )\n",
    "            )\n",
    "\n",
    "        decoding_dim = self.input_dim + embedding_dim\n",
    "\n",
    "        # DNN that acts on the node level to predict the PID\n",
    "        self.nn_id = ffn(decoding_dim, num_classes, width, self.act, dropout_ff)\n",
    "\n",
    "        # elementwise DNN for node momentum regression\n",
    "        embed_dim = decoding_dim + num_classes\n",
    "        self.nn_pt = RegressionOutput(embed_dim, width, self.act, dropout_ff)\n",
    "        self.nn_eta = RegressionOutput(embed_dim, width, self.act, dropout_ff)\n",
    "        self.nn_sin_phi = RegressionOutput(embed_dim, width, self.act, dropout_ff)\n",
    "        self.nn_cos_phi = RegressionOutput(embed_dim, width, self.act, dropout_ff)\n",
    "        self.nn_energy = RegressionOutput(embed_dim, width, self.act, dropout_ff)\n",
    "        \n",
    "        self.quant = QuantizeFeaturesStub(self.input_dim + len(self.elemtypes))\n",
    "        self.dequant_id = torch.ao.quantization.DeQuantStub()\n",
    "\n",
    "    def forward(self, X_features, mask):\n",
    "        Xfeat_transformed = transform_batch(X_features)\n",
    "        Xfeat_normed = self.quant(Xfeat_transformed)\n",
    "\n",
    "        embeddings_id, embeddings_reg = [], []\n",
    "        embedding_id = self.nn0_id(Xfeat_normed)\n",
    "        embedding_reg = self.nn0_reg(Xfeat_normed)\n",
    "        for num, conv in enumerate(self.conv_id):\n",
    "            conv_input = embedding_id if num == 0 else embeddings_id[-1]\n",
    "            out_padded = conv(conv_input, mask)\n",
    "            embeddings_id.append(out_padded)\n",
    "        for num, conv in enumerate(self.conv_reg):\n",
    "            conv_input = embedding_reg if num == 0 else embeddings_reg[-1]\n",
    "            out_padded = conv(conv_input, mask)\n",
    "            embeddings_reg.append(out_padded)\n",
    "\n",
    "        final_embedding_id = torch.cat([Xfeat_normed] + [embeddings_id[-1]], axis=-1)\n",
    "        preds_id = self.nn_id(final_embedding_id)\n",
    "\n",
    "        final_embedding_reg = torch.cat([Xfeat_normed] + [embeddings_reg[-1]] + [preds_id], axis=-1)\n",
    "        preds_pt = self.nn_pt(X_features, final_embedding_reg, X_features[..., 1:2])\n",
    "        preds_eta = self.nn_eta(X_features, final_embedding_reg, X_features[..., 2:3])\n",
    "        preds_sin_phi = self.nn_sin_phi(X_features, final_embedding_reg, X_features[..., 3:4])\n",
    "        preds_cos_phi = self.nn_cos_phi(X_features, final_embedding_reg, X_features[..., 4:5])\n",
    "        preds_energy = self.nn_energy(X_features, final_embedding_reg, X_features[..., 5:6])\n",
    "        preds_momentum = torch.cat([preds_pt, preds_eta, preds_sin_phi, preds_cos_phi, preds_energy], axis=-1)\n",
    "        \n",
    "        preds_id = self.dequant_id(preds_id)\n",
    "        return preds_id, preds_momentum\n",
    "\n",
    "\n",
    "model = MLPF(input_dim=INPUT_DIM, num_classes=NUM_CLASSES)\n",
    "optimizer = torch.optim.Adam(lr=1e-4, params=model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9647cc4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=146.23\n",
      "Loss=134.96\n",
      "Loss=135.68\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/sraj/ipykernel_1588190/1124641245.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mtargets_unpacked\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpack_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_targets_padded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmlpf_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets_unpacked\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds_unpacked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Total\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mcurrent_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Total\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cvmfs/sft.cern.ch/lcg/views/LCG_105/x86_64-el9-gcc13-opt/lib/python3.9/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    490\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             )\n\u001b[0;32m--> 492\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    493\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         )\n",
      "\u001b[0;32m/cvmfs/sft.cern.ch/lcg/views/LCG_105/x86_64-el9-gcc13-opt/lib/python3.9/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    252\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "max_events_train = 1000\n",
    "events_per_batch = 10\n",
    "\n",
    "losses = []\n",
    "\n",
    "#Training loop\n",
    "inds_train = range(0,max_events_train,events_per_batch)\n",
    "for ind in inds_train:\n",
    "    optimizer.zero_grad()\n",
    "    ds_elems = [ds_train[i] for i in range(ind,ind+events_per_batch)]\n",
    "    X_features = [torch.tensor(elem[\"X\"]).to(torch.float32) for elem in ds_elems]\n",
    "    X_features_padded = pad_sequence(X_features, batch_first=True)\n",
    "    y_targets = [torch.tensor(elem[\"ygen\"]).to(torch.float32) for elem in ds_elems]\n",
    "    y_targets_padded = pad_sequence(y_targets, batch_first=True)\n",
    "    \n",
    "    mask = X_features_padded[:, :, 0]!=0\n",
    "\n",
    "    preds = model(X_features_padded, mask)\n",
    "    preds_unpacked = unpack_predictions(preds)\n",
    "    targets_unpacked = unpack_target(y_targets_padded)\n",
    "    loss = mlpf_loss(targets_unpacked, preds_unpacked)\n",
    "    loss[\"Total\"].backward()\n",
    "    optimizer.step()\n",
    "    current_loss = loss[\"Total\"].detach().item()\n",
    "    losses.append(current_loss)\n",
    "    print(\"Loss={:.2f}\".format(loss[\"Total\"].detach().item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "484683d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab79643",
   "metadata": {},
   "source": [
    "## Quantized model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a8b60eb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cvmfs/sft.cern.ch/lcg/views/LCG_105/x86_64-el9-gcc13-opt/lib/python3.9/site-packages/torch/ao/quantization/observer.py:214: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
      "  warnings.warn(\n",
      "/cvmfs/sft.cern.ch/lcg/views/LCG_105/x86_64-el9-gcc13-opt/lib/python3.9/site-packages/torch/ao/quantization/observer.py:1207: UserWarning: must run observer before calling calculate_qparams.                                    Returning default scale and zero point \n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "model.qconfig = torch.ao.quantization.get_default_qconfig('x86')\n",
    "model_prepared = torch.ao.quantization.prepare(model)\n",
    "\n",
    "#calibrate on data\n",
    "num_events_to_calibrate = 1\n",
    "for ind in range(1000,1000+num_events_to_calibrate):\n",
    "    X = torch.unsqueeze(torch.tensor(ds_train[ind][\"X\"]).to(torch.float32), 0)\n",
    "    mask = X[:, :, 0]!=0\n",
    "    model_prepared(X, mask)\n",
    "\n",
    "model_int8 = torch.ao.quantization.convert(model_prepared)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ad3335",
   "metadata": {},
   "source": [
    "## Training on the quantized model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1631487b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPF(\n",
       "  (nn0_id): Sequential(\n",
       "    (0): QuantizedLinear(in_features=17, out_features=256, scale=18.83978271484375, zero_point=62, qscheme=torch.per_channel_affine)\n",
       "    (1): ReLU()\n",
       "    (2): QuantizedLayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    (3): QuantizedDropout(p=0.0, inplace=False)\n",
       "    (4): QuantizedLinear(in_features=256, out_features=256, scale=0.03470222279429436, zero_point=63, qscheme=torch.per_channel_affine)\n",
       "  )\n",
       "  (nn0_reg): Sequential(\n",
       "    (0): QuantizedLinear(in_features=17, out_features=256, scale=18.78470230102539, zero_point=61, qscheme=torch.per_channel_affine)\n",
       "    (1): ReLU()\n",
       "    (2): QuantizedLayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    (3): QuantizedDropout(p=0.0, inplace=False)\n",
       "    (4): QuantizedLinear(in_features=256, out_features=256, scale=0.03149465471506119, zero_point=66, qscheme=torch.per_channel_affine)\n",
       "  )\n",
       "  (conv_id): ModuleList(\n",
       "    (0): SelfAttentionLayer(\n",
       "      (act): ReLU()\n",
       "      (mha): QuantizedMultiheadAttention(\n",
       "        (out_proj): QuantizedLinear(in_features=256, out_features=256, scale=0.009221071377396584, zero_point=72, qscheme=torch.per_channel_affine)\n",
       "        (linear_Q): QuantizedLinear(in_features=256, out_features=256, scale=0.025950858369469643, zero_point=70, qscheme=torch.per_channel_affine)\n",
       "        (linear_K): QuantizedLinear(in_features=256, out_features=256, scale=0.025587817654013634, zero_point=60, qscheme=torch.per_channel_affine)\n",
       "        (linear_V): QuantizedLinear(in_features=256, out_features=256, scale=0.026439329609274864, zero_point=68, qscheme=torch.per_channel_affine)\n",
       "        (q_scaling_product): QFunctional(\n",
       "          scale=1.0, zero_point=0\n",
       "          (activation_post_process): Identity()\n",
       "        )\n",
       "        (quant_attn_output): Quantize(scale=tensor([0.0132]), zero_point=tensor([76]), dtype=torch.quint8)\n",
       "        (quant_attn_output_weights): Quantize(scale=tensor([0.0001]), zero_point=tensor([0]), dtype=torch.quint8)\n",
       "        (dequant_q): DeQuantize()\n",
       "        (dequant_k): DeQuantize()\n",
       "        (dequant_v): DeQuantize()\n",
       "      )\n",
       "      (norm0): QuantizedLayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm1): QuantizedLayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (seq): Sequential(\n",
       "        (0): QuantizedLinear(in_features=256, out_features=256, scale=0.04378572106361389, zero_point=66, qscheme=torch.per_channel_affine)\n",
       "        (1): ReLU()\n",
       "        (2): QuantizedLinear(in_features=256, out_features=256, scale=0.019504958763718605, zero_point=62, qscheme=torch.per_channel_affine)\n",
       "        (3): ReLU()\n",
       "      )\n",
       "      (dropout): QuantizedDropout(p=0.0, inplace=False)\n",
       "      (add0): QFunctional(\n",
       "        scale=0.035685986280441284, zero_point=65\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "      (add1): QFunctional(\n",
       "        scale=0.05668731406331062, zero_point=67\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "      (mul): QFunctional(\n",
       "        scale=0.054789356887340546, zero_point=68\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "    (1): SelfAttentionLayer(\n",
       "      (act): ReLU()\n",
       "      (mha): QuantizedMultiheadAttention(\n",
       "        (out_proj): QuantizedLinear(in_features=256, out_features=256, scale=0.01978025771677494, zero_point=63, qscheme=torch.per_channel_affine)\n",
       "        (linear_Q): QuantizedLinear(in_features=256, out_features=256, scale=0.039231076836586, zero_point=65, qscheme=torch.per_channel_affine)\n",
       "        (linear_K): QuantizedLinear(in_features=256, out_features=256, scale=0.04101167619228363, zero_point=64, qscheme=torch.per_channel_affine)\n",
       "        (linear_V): QuantizedLinear(in_features=256, out_features=256, scale=0.044374752789735794, zero_point=55, qscheme=torch.per_channel_affine)\n",
       "        (q_scaling_product): QFunctional(\n",
       "          scale=1.0, zero_point=0\n",
       "          (activation_post_process): Identity()\n",
       "        )\n",
       "        (quant_attn_output): Quantize(scale=tensor([0.0243]), zero_point=tensor([64]), dtype=torch.quint8)\n",
       "        (quant_attn_output_weights): Quantize(scale=tensor([0.0018]), zero_point=tensor([0]), dtype=torch.quint8)\n",
       "        (dequant_q): DeQuantize()\n",
       "        (dequant_k): DeQuantize()\n",
       "        (dequant_v): DeQuantize()\n",
       "      )\n",
       "      (norm0): QuantizedLayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm1): QuantizedLayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (seq): Sequential(\n",
       "        (0): QuantizedLinear(in_features=256, out_features=256, scale=0.04396577924489975, zero_point=63, qscheme=torch.per_channel_affine)\n",
       "        (1): ReLU()\n",
       "        (2): QuantizedLinear(in_features=256, out_features=256, scale=0.024432756006717682, zero_point=57, qscheme=torch.per_channel_affine)\n",
       "        (3): ReLU()\n",
       "      )\n",
       "      (dropout): QuantizedDropout(p=0.0, inplace=False)\n",
       "      (add0): QFunctional(\n",
       "        scale=0.057352397590875626, zero_point=66\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "      (add1): QFunctional(\n",
       "        scale=0.061659976840019226, zero_point=60\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "      (mul): QFunctional(\n",
       "        scale=0.05561864376068115, zero_point=66\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (conv_reg): ModuleList(\n",
       "    (0): SelfAttentionLayer(\n",
       "      (act): ReLU()\n",
       "      (mha): QuantizedMultiheadAttention(\n",
       "        (out_proj): QuantizedLinear(in_features=256, out_features=256, scale=0.007607951294630766, zero_point=73, qscheme=torch.per_channel_affine)\n",
       "        (linear_Q): QuantizedLinear(in_features=256, out_features=256, scale=0.02327846921980381, zero_point=60, qscheme=torch.per_channel_affine)\n",
       "        (linear_K): QuantizedLinear(in_features=256, out_features=256, scale=0.024619953706860542, zero_point=63, qscheme=torch.per_channel_affine)\n",
       "        (linear_V): QuantizedLinear(in_features=256, out_features=256, scale=0.025578908622264862, zero_point=70, qscheme=torch.per_channel_affine)\n",
       "        (q_scaling_product): QFunctional(\n",
       "          scale=1.0, zero_point=0\n",
       "          (activation_post_process): Identity()\n",
       "        )\n",
       "        (quant_attn_output): Quantize(scale=tensor([0.0087]), zero_point=tensor([60]), dtype=torch.quint8)\n",
       "        (quant_attn_output_weights): Quantize(scale=tensor([0.0001]), zero_point=tensor([0]), dtype=torch.quint8)\n",
       "        (dequant_q): DeQuantize()\n",
       "        (dequant_k): DeQuantize()\n",
       "        (dequant_v): DeQuantize()\n",
       "      )\n",
       "      (norm0): QuantizedLayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm1): QuantizedLayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (seq): Sequential(\n",
       "        (0): QuantizedLinear(in_features=256, out_features=256, scale=0.0356711745262146, zero_point=63, qscheme=torch.per_channel_affine)\n",
       "        (1): ReLU()\n",
       "        (2): QuantizedLinear(in_features=256, out_features=256, scale=0.013998350128531456, zero_point=62, qscheme=torch.per_channel_affine)\n",
       "        (3): ReLU()\n",
       "      )\n",
       "      (dropout): QuantizedDropout(p=0.0, inplace=False)\n",
       "      (add0): QFunctional(\n",
       "        scale=0.032009467482566833, zero_point=64\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "      (add1): QFunctional(\n",
       "        scale=0.05264836177229881, zero_point=62\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "      (mul): QFunctional(\n",
       "        scale=0.0525432713329792, zero_point=63\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "    (1): SelfAttentionLayer(\n",
       "      (act): ReLU()\n",
       "      (mha): QuantizedMultiheadAttention(\n",
       "        (out_proj): QuantizedLinear(in_features=256, out_features=256, scale=0.012570573017001152, zero_point=66, qscheme=torch.per_channel_affine)\n",
       "        (linear_Q): QuantizedLinear(in_features=256, out_features=256, scale=0.04137823358178139, zero_point=65, qscheme=torch.per_channel_affine)\n",
       "        (linear_K): QuantizedLinear(in_features=256, out_features=256, scale=0.03887088596820831, zero_point=68, qscheme=torch.per_channel_affine)\n",
       "        (linear_V): QuantizedLinear(in_features=256, out_features=256, scale=0.0393090546131134, zero_point=68, qscheme=torch.per_channel_affine)\n",
       "        (q_scaling_product): QFunctional(\n",
       "          scale=1.0, zero_point=0\n",
       "          (activation_post_process): Identity()\n",
       "        )\n",
       "        (quant_attn_output): Quantize(scale=tensor([0.0191]), zero_point=tensor([59]), dtype=torch.quint8)\n",
       "        (quant_attn_output_weights): Quantize(scale=tensor([0.0003]), zero_point=tensor([0]), dtype=torch.quint8)\n",
       "        (dequant_q): DeQuantize()\n",
       "        (dequant_k): DeQuantize()\n",
       "        (dequant_v): DeQuantize()\n",
       "      )\n",
       "      (norm0): QuantizedLayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm1): QuantizedLayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (seq): Sequential(\n",
       "        (0): QuantizedLinear(in_features=256, out_features=256, scale=0.0360560268163681, zero_point=58, qscheme=torch.per_channel_affine)\n",
       "        (1): ReLU()\n",
       "        (2): QuantizedLinear(in_features=256, out_features=256, scale=0.016513841226696968, zero_point=59, qscheme=torch.per_channel_affine)\n",
       "        (3): ReLU()\n",
       "      )\n",
       "      (dropout): QuantizedDropout(p=0.0, inplace=False)\n",
       "      (add0): QFunctional(\n",
       "        scale=0.05312876030802727, zero_point=67\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "      (add1): QFunctional(\n",
       "        scale=0.054405827075242996, zero_point=64\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "      (mul): QFunctional(\n",
       "        scale=0.05338559299707413, zero_point=67\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (nn_id): Sequential(\n",
       "    (0): QuantizedLinear(in_features=273, out_features=256, scale=4.953759670257568, zero_point=69, qscheme=torch.per_channel_affine)\n",
       "    (1): ReLU()\n",
       "    (2): QuantizedLayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    (3): QuantizedDropout(p=0.0, inplace=False)\n",
       "    (4): QuantizedLinear(in_features=256, out_features=6, scale=0.03840237110853195, zero_point=64, qscheme=torch.per_channel_affine)\n",
       "  )\n",
       "  (nn_pt): RegressionOutput(\n",
       "    (dequant): DeQuantize()\n",
       "    (nn): Sequential(\n",
       "      (0): QuantizedLinear(in_features=279, out_features=256, scale=5.159435272216797, zero_point=64, qscheme=torch.per_channel_affine)\n",
       "      (1): ReLU()\n",
       "      (2): QuantizedLayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (3): QuantizedDropout(p=0.0, inplace=False)\n",
       "      (4): QuantizedLinear(in_features=256, out_features=1, scale=0.0052044084295630455, zero_point=108, qscheme=torch.per_channel_affine)\n",
       "    )\n",
       "  )\n",
       "  (nn_eta): RegressionOutput(\n",
       "    (dequant): DeQuantize()\n",
       "    (nn): Sequential(\n",
       "      (0): QuantizedLinear(in_features=279, out_features=256, scale=4.59193754196167, zero_point=60, qscheme=torch.per_channel_affine)\n",
       "      (1): ReLU()\n",
       "      (2): QuantizedLayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (3): QuantizedDropout(p=0.0, inplace=False)\n",
       "      (4): QuantizedLinear(in_features=256, out_features=1, scale=0.003042892087250948, zero_point=79, qscheme=torch.per_channel_affine)\n",
       "    )\n",
       "  )\n",
       "  (nn_sin_phi): RegressionOutput(\n",
       "    (dequant): DeQuantize()\n",
       "    (nn): Sequential(\n",
       "      (0): QuantizedLinear(in_features=279, out_features=256, scale=4.702180862426758, zero_point=72, qscheme=torch.per_channel_affine)\n",
       "      (1): ReLU()\n",
       "      (2): QuantizedLayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (3): QuantizedDropout(p=0.0, inplace=False)\n",
       "      (4): QuantizedLinear(in_features=256, out_features=1, scale=0.0035637349355965853, zero_point=49, qscheme=torch.per_channel_affine)\n",
       "    )\n",
       "  )\n",
       "  (nn_cos_phi): RegressionOutput(\n",
       "    (dequant): DeQuantize()\n",
       "    (nn): Sequential(\n",
       "      (0): QuantizedLinear(in_features=279, out_features=256, scale=4.839432239532471, zero_point=67, qscheme=torch.per_channel_affine)\n",
       "      (1): ReLU()\n",
       "      (2): QuantizedLayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (3): QuantizedDropout(p=0.0, inplace=False)\n",
       "      (4): QuantizedLinear(in_features=256, out_features=1, scale=0.003083720337599516, zero_point=69, qscheme=torch.per_channel_affine)\n",
       "    )\n",
       "  )\n",
       "  (nn_energy): RegressionOutput(\n",
       "    (dequant): DeQuantize()\n",
       "    (nn): Sequential(\n",
       "      (0): QuantizedLinear(in_features=279, out_features=256, scale=4.941447734832764, zero_point=63, qscheme=torch.per_channel_affine)\n",
       "      (1): ReLU()\n",
       "      (2): QuantizedLayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (3): QuantizedDropout(p=0.0, inplace=False)\n",
       "      (4): QuantizedLinear(in_features=256, out_features=1, scale=0.007276138756424189, zero_point=111, qscheme=torch.per_channel_affine)\n",
       "    )\n",
       "  )\n",
       "  (quant): QuantizeFeaturesStub(\n",
       "    (quants): ModuleList(\n",
       "      (0): Quantize(scale=tensor([0.0157]), zero_point=tensor([0]), dtype=torch.quint8)\n",
       "      (1): Quantize(scale=tensor([0.0489]), zero_point=tensor([46]), dtype=torch.quint8)\n",
       "      (2): Quantize(scale=tensor([0.0315]), zero_point=tensor([70]), dtype=torch.quint8)\n",
       "      (3-4): 2 x Quantize(scale=tensor([0.0157]), zero_point=tensor([64]), dtype=torch.quint8)\n",
       "      (5): Quantize(scale=tensor([0.0510]), zero_point=tensor([39]), dtype=torch.quint8)\n",
       "      (6): Quantize(scale=tensor([30.6385]), zero_point=tensor([74]), dtype=torch.quint8)\n",
       "      (7): Quantize(scale=tensor([29.3899]), zero_point=tensor([65]), dtype=torch.quint8)\n",
       "      (8): Quantize(scale=tensor([44.5062]), zero_point=tensor([63]), dtype=torch.quint8)\n",
       "      (9): Quantize(scale=tensor([0.0229]), zero_point=tensor([0]), dtype=torch.quint8)\n",
       "      (10): Quantize(scale=tensor([2.6954]), zero_point=tensor([0]), dtype=torch.quint8)\n",
       "      (11): Quantize(scale=tensor([0.1419]), zero_point=tensor([31]), dtype=torch.quint8)\n",
       "      (12): Quantize(scale=tensor([0.0875]), zero_point=tensor([49]), dtype=torch.quint8)\n",
       "      (13): Quantize(scale=tensor([4.2263]), zero_point=tensor([0]), dtype=torch.quint8)\n",
       "      (14): Quantize(scale=tensor([3.6075]), zero_point=tensor([2]), dtype=torch.quint8)\n",
       "      (15): Quantize(scale=tensor([2.6614]), zero_point=tensor([0]), dtype=torch.quint8)\n",
       "      (16): Quantize(scale=tensor([6.0954]), zero_point=tensor([0]), dtype=torch.quint8)\n",
       "      (17-19): 3 x Quantize(scale=tensor([1.]), zero_point=tensor([0]), dtype=torch.quint8)\n",
       "    )\n",
       "  )\n",
       "  (dequant_id): DeQuantize()\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_int8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "698dc268",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "empty_strided not supported on quantized tensors yet see https://github.com/pytorch/pytorch/issues/74540",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/sraj/ipykernel_1588190/3187738737.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;31m# Forward pass through the quantized model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# No need to compute gradients during calibration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mpreds_int8\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_int8\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_features_padded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mpreds_unpacked_int8\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpack_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds_int8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mtargets_unpacked\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpack_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_targets_padded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cvmfs/sft.cern.ch/lcg/views/LCG_105/x86_64-el9-gcc13-opt/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cvmfs/sft.cern.ch/lcg/views/LCG_105/x86_64-el9-gcc13-opt/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/sraj/ipykernel_1588190/696816197.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, X_features, mask)\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mnum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m             \u001b[0mconv_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding_id\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnum\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0membeddings_id\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 290\u001b[0;31m             \u001b[0mout_padded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    291\u001b[0m             \u001b[0membeddings_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_padded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mnum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_reg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cvmfs/sft.cern.ch/lcg/views/LCG_105/x86_64-el9-gcc13-opt/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cvmfs/sft.cern.ch/lcg/views/LCG_105/x86_64-el9-gcc13-opt/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/sraj/ipykernel_1588190/696816197.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: empty_strided not supported on quantized tensors yet see https://github.com/pytorch/pytorch/issues/74540"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Define your loss function (mlpf_loss) and optimizer (optimizer) here\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model_int8.eval()\n",
    "\n",
    "# Define the number of events to process\n",
    "max_events_calibrate = 1000\n",
    "events_per_batch = 10\n",
    "\n",
    "# List to store losses\n",
    "losses_int8 = []\n",
    "\n",
    "# Calibration loop\n",
    "for ind in range(max_events_calibrate, max_events_calibrate + num_events_to_calibrate, events_per_batch):\n",
    "    # Reset gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Prepare input data\n",
    "    ds_elems = [ds_train[i] for i in range(ind, ind + events_per_batch)]\n",
    "    X_features = [torch.tensor(elem[\"X\"]).to(torch.float32) for elem in ds_elems]\n",
    "    X_features_padded = torch.nn.utils.rnn.pad_sequence(X_features, batch_first=True)\n",
    "    mask = X_features_padded[:, :, 0] != 0\n",
    "\n",
    "    # Forward pass through the quantized model\n",
    "    with torch.no_grad():  # No need to compute gradients during calibration\n",
    "        preds_int8 = model_int8(X_features_padded, mask)\n",
    "        preds_unpacked_int8 = unpack_predictions(preds_int8)\n",
    "        targets_unpacked = unpack_target(y_targets_padded)\n",
    "        loss_int8 = mlpf_loss(targets_unpacked, preds_unpacked_int8)\n",
    "        current_loss_int8 = loss_int8[\"Total\"].item()\n",
    "        losses_int8.append(current_loss_int8)\n",
    "\n",
    "    # Print the loss for monitoring\n",
    "    print(\"Quantized Loss={:.2f}\".format(current_loss_int8))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70da64e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44174bc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8f9c20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e002729",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
