{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9eef64e5",
   "metadata": {},
   "source": [
    "Task:\n",
    "1. Run the notebook as written https://github.com/jpata/particleflow/blob/int8_quant/notebooks/clic/mlpf-pytorch-transformer-standalone.ipynb \n",
    "    1. Understand everything\n",
    "    2. recompute the loss using the quantized model for larger number of samples\n",
    "    3. To understand the contributions of loss you can check the regression and classification loss seperately.\n",
    "    3. add more physics validation checks\n",
    "    4. Sticking with 'x86' try to work on fine-tuning of qconfig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1d3a1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.set_num_threads(1)\n",
    "from torch import nn, Tensor\n",
    "import tensorflow_datasets as tfds\n",
    "import torch_geometric\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4104391c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../../mlpf/tensorflow_datasets/\"\n",
    "dataset = \"clic_edm_ttbar_pf\"\n",
    "\n",
    "#Load dataset\n",
    "builder = tfds.builder(dataset, data_dir=data_dir)\n",
    "ds_train = builder.as_data_source(split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc706b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_FEATURES_TRK = [\n",
    "    \"elemtype\",\n",
    "    \"pt\",\n",
    "    \"eta\",\n",
    "    \"sin_phi\",\n",
    "    \"cos_phi\",\n",
    "    \"p\",\n",
    "    \"chi2\",\n",
    "    \"ndf\",\n",
    "    \"dEdx\",\n",
    "    \"dEdxError\",\n",
    "    \"radiusOfInnermostHit\",\n",
    "    \"tanLambda\",\n",
    "    \"D0\",\n",
    "    \"omega\",\n",
    "    \"Z0\",\n",
    "    \"time\",\n",
    "]\n",
    "X_FEATURES_CL = [\n",
    "    \"elemtype\",\n",
    "    \"et\",\n",
    "    \"eta\",\n",
    "    \"sin_phi\",\n",
    "    \"cos_phi\",\n",
    "    \"energy\",\n",
    "    \"position.x\",\n",
    "    \"position.y\",\n",
    "    \"position.z\",\n",
    "    \"iTheta\",\n",
    "    \"energy_ecal\",\n",
    "    \"energy_hcal\",\n",
    "    \"energy_other\",\n",
    "    \"num_hits\",\n",
    "    \"sigma_x\",\n",
    "    \"sigma_y\",\n",
    "    \"sigma_z\",\n",
    "]\n",
    "Y_FEATURES = [\"cls_id\", \"charge\", \"pt\", \"eta\", \"sin_phi\", \"cos_phi\", \"energy\"]\n",
    "Y_CLASSES = [0, 211, 130, 22, 11, 13]\n",
    "\n",
    "INPUT_DIM = max(len(X_FEATURES_TRK), len(X_FEATURES_CL))\n",
    "NUM_CLASSES = len(Y_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4b8d66ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    \"\"\"Focal Loss, as described in https://arxiv.org/abs/1708.02002.\n",
    "    It is essentially an enhancement to cross entropy loss and is\n",
    "    useful for classification tasks when there is a large class imbalance.\n",
    "    x is expected to contain raw, unnormalized scores for each class.\n",
    "    y is expected to contain class labels.\n",
    "    Shape:\n",
    "        - x: (batch_size, C) or (batch_size, C, d1, d2, ..., dK), K > 0.\n",
    "        - y: (batch_size,) or (batch_size, d1, d2, ..., dK), K > 0.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, alpha = None, gamma = 0.0, reduction = \"mean\", ignore_index = -100\n",
    "    ):\n",
    "        \"\"\"Constructor.\n",
    "        Args:\n",
    "            alpha (Tensor, optional): Weights for each class. Defaults to None.\n",
    "            gamma (float, optional): A constant, as described in the paper.\n",
    "                Defaults to 0.\n",
    "            reduction (str, optional): 'mean', 'sum' or 'none'.\n",
    "                Defaults to 'mean'.\n",
    "            ignore_index (int, optional): class label to ignore.\n",
    "                Defaults to -100.\n",
    "        \"\"\"\n",
    "        if reduction not in (\"mean\", \"sum\", \"none\"):\n",
    "            raise ValueError('Reduction must be one of: \"mean\", \"sum\", \"none\".')\n",
    "\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "        self.nll_loss = nn.NLLLoss(weight=alpha, reduction=\"none\")\n",
    "\n",
    "    def __repr__(self):\n",
    "        arg_keys = [\"alpha\", \"gamma\", \"reduction\"]\n",
    "        arg_vals = [self.__dict__[k] for k in arg_keys]\n",
    "        arg_strs = [f\"{k}={v!r}\" for k, v in zip(arg_keys, arg_vals)]\n",
    "        arg_str = \", \".join(arg_strs)\n",
    "        return f\"{type(self).__name__}({arg_str})\"\n",
    "\n",
    "    def forward(self, x: Tensor, y: Tensor) -> Tensor:\n",
    "        if x.ndim > 2:\n",
    "            # (N, C, d1, d2, ..., dK) --> (N * d1 * ... * dK, C)\n",
    "            c = x.shape[1]\n",
    "            x = x.permute(0, *range(2, x.ndim), 1).reshape(-1, c)\n",
    "            # (N, d1, d2, ..., dK) --> (N * d1 * ... * dK,)\n",
    "            y = y.view(-1)\n",
    "\n",
    "        # compute weighted cross entropy term: -alpha * log(pt)\n",
    "        # (alpha is already part of self.nll_loss)\n",
    "        log_p = F.log_softmax(x, dim=-1)\n",
    "        ce = self.nll_loss(log_p, y)\n",
    "\n",
    "        # get true class column from each row\n",
    "        # this is slow due to indexing\n",
    "        # all_rows = torch.arange(len(x))\n",
    "        # log_pt = log_p[all_rows, y]\n",
    "        log_pt = torch.gather(log_p, 1, y.unsqueeze(axis=-1)).squeeze(axis=-1)\n",
    "\n",
    "        # compute focal term: (1 - pt)^gamma\n",
    "        pt = log_pt.exp()\n",
    "        focal_term = (1 - pt) ** self.gamma\n",
    "\n",
    "        # the full loss: -alpha * ((1 - pt)^gamma) * log(pt)\n",
    "        loss = focal_term * ce\n",
    "\n",
    "        if self.reduction == \"mean\":\n",
    "            loss = loss.mean()\n",
    "        elif self.reduction == \"sum\":\n",
    "            loss = loss.sum()\n",
    "\n",
    "        return loss\n",
    "\n",
    "class QuantizeFeaturesStub(torch.nn.Module):\n",
    "    def __init__(self, num_feats):\n",
    "        super().__init__()\n",
    "        self.num_feats = num_feats\n",
    "        self.quants = torch.nn.ModuleList()\n",
    "        for ifeat in range(self.num_feats):\n",
    "            self.quants.append(torch.ao.quantization.QuantStub())\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.cat([self.quants[ifeat](x[..., ifeat:ifeat+1]) for ifeat in range(self.num_feats)], axis=-1)\n",
    "        \n",
    "def mlpf_loss(y, ypred):\n",
    "    loss = {}\n",
    "    loss_obj_id = FocalLoss(gamma=2.0, reduction=\"none\")\n",
    "\n",
    "    msk_true_particle = torch.unsqueeze((y[\"cls_id\"] != 0).to(dtype=torch.float32), axis=-1)\n",
    "    npart = y[\"pt\"].numel()\n",
    "\n",
    "    ypred[\"momentum\"] = ypred[\"momentum\"] * msk_true_particle\n",
    "    y[\"momentum\"] = y[\"momentum\"] * msk_true_particle\n",
    "\n",
    "    ypred[\"cls_id_onehot\"] = ypred[\"cls_id_onehot\"].permute((0, 2, 1))\n",
    "\n",
    "    loss_classification = 100 * loss_obj_id(ypred[\"cls_id_onehot\"], y[\"cls_id\"]).reshape(y[\"cls_id\"].shape)\n",
    "    loss_regression = 10 * torch.nn.functional.huber_loss(ypred[\"momentum\"], y[\"momentum\"], reduction=\"none\")\n",
    "    \n",
    "    # average over all particles\n",
    "    loss[\"Classification\"] = loss_classification.sum() / npart\n",
    "    loss[\"Regression\"] = loss_regression.sum() / npart\n",
    "    print(f'classification', loss[\"Classification\"])\n",
    "    print(f'regression', loss[\"Regression\"])\n",
    "\n",
    "    loss[\"Total\"] = loss[\"Classification\"] + loss[\"Regression\"]\n",
    "    print(f'Total loss', loss[\"Total\"])\n",
    "    return loss\n",
    "    \n",
    "class SelfAttentionLayer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        embedding_dim=128,\n",
    "        num_heads=2,\n",
    "        width=128,\n",
    "        dropout_mha=0.1,\n",
    "        dropout_ff=0.1,\n",
    "        attention_type=\"efficient\",\n",
    "    ):\n",
    "        super(SelfAttentionLayer, self).__init__()\n",
    "\n",
    "        self.attention_type = attention_type\n",
    "        self.act = nn.ReLU()\n",
    "        self.mha = torch.nn.MultiheadAttention(embedding_dim, num_heads, dropout=dropout_mha, batch_first=True)\n",
    "        self.norm0 = torch.nn.LayerNorm(embedding_dim)\n",
    "        self.norm1 = torch.nn.LayerNorm(embedding_dim)\n",
    "        self.seq = torch.nn.Sequential(\n",
    "            nn.Linear(embedding_dim, width), self.act, nn.Linear(width, embedding_dim), self.act\n",
    "        )\n",
    "\n",
    "        self.dropout = torch.nn.Dropout(dropout_ff)\n",
    "\n",
    "        self.add0 = torch.ao.nn.quantized.FloatFunctional()\n",
    "        self.add1 = torch.ao.nn.quantized.FloatFunctional()\n",
    "        self.mul = torch.ao.nn.quantized.FloatFunctional()\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        mha_out = self.mha(x, x, x, need_weights=False)[0]\n",
    "        x = self.add0.add(x, mha_out)\n",
    "        x = self.norm0(x)\n",
    "        x = self.add1.add(x, self.seq(x))\n",
    "        x = self.norm1(x)\n",
    "        x = self.dropout(x)\n",
    "#         mask = mask.to(x.dtype)        \n",
    "#         x = x * mask.unsqueeze(-1).expand(-1, -1, x.size(2))\n",
    "\n",
    "        \n",
    "        return x\n",
    "\n",
    "class RegressionOutput(nn.Module):\n",
    "    def __init__(self, embed_dim, width, act, dropout):\n",
    "        super(RegressionOutput, self).__init__()\n",
    "        self.dequant = torch.ao.quantization.DeQuantStub()\n",
    "        self.nn = ffn(embed_dim, 1, width, act, dropout)\n",
    "\n",
    "    def forward(self, elems, x, orig_value):\n",
    "        nn_out = self.nn(x)\n",
    "        nn_out = self.dequant(nn_out)\n",
    "        return orig_value + nn_out\n",
    "\n",
    "def ffn(input_dim, output_dim, width, act, dropout):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(input_dim, width),\n",
    "        act(),\n",
    "        torch.nn.LayerNorm(width),\n",
    "        nn.Dropout(dropout),\n",
    "        nn.Linear(width, output_dim),\n",
    "    )\n",
    "\n",
    "def transform_batch(Xbatch):\n",
    "    Xbatch = Xbatch.clone()\n",
    "    Xbatch[..., 1] = torch.log(Xbatch[..., 1])\n",
    "    Xbatch[..., 5] = torch.log(Xbatch[..., 5])\n",
    "    Xbatch[torch.isnan(Xbatch)] = 0.0\n",
    "    Xbatch[torch.isinf(Xbatch)] = 0.0\n",
    "    return Xbatch\n",
    "    \n",
    "def unpack_target(y):\n",
    "    ret = {}\n",
    "    ret[\"cls_id\"] = y[..., 0].long()\n",
    "\n",
    "    for i, feat in enumerate(Y_FEATURES):\n",
    "        if i >= 2:  # skip the cls and charge as they are defined above\n",
    "            ret[feat] = y[..., i].to(dtype=torch.float32)\n",
    "    ret[\"phi\"] = torch.atan2(ret[\"sin_phi\"], ret[\"cos_phi\"])\n",
    "    \n",
    "    # note ~ momentum = [\"pt\", \"eta\", \"sin_phi\", \"cos_phi\", \"energy\"]\n",
    "    ret[\"momentum\"] = y[..., 2:7].to(dtype=torch.float32)\n",
    "    ret[\"p4\"] = torch.cat(\n",
    "        [ret[\"pt\"].unsqueeze(1), ret[\"eta\"].unsqueeze(1), ret[\"phi\"].unsqueeze(1), ret[\"energy\"].unsqueeze(1)], axis=1\n",
    "    )\n",
    "\n",
    "    return ret\n",
    "\n",
    "\n",
    "def unpack_predictions(preds):\n",
    "    ret = {}\n",
    "    ret[\"cls_id_onehot\"], ret[\"momentum\"] = preds\n",
    "\n",
    "    ret[\"pt\"] = ret[\"momentum\"][..., 0]\n",
    "    ret[\"eta\"] = ret[\"momentum\"][..., 1]\n",
    "    ret[\"sin_phi\"] = ret[\"momentum\"][..., 2]\n",
    "    ret[\"cos_phi\"] = ret[\"momentum\"][..., 3]\n",
    "    ret[\"energy\"] = ret[\"momentum\"][..., 4]\n",
    "\n",
    "    ret[\"cls_id\"] = torch.argmax(ret[\"cls_id_onehot\"], axis=-1)\n",
    "    ret[\"phi\"] = torch.atan2(ret[\"sin_phi\"], ret[\"cos_phi\"])\n",
    "    ret[\"p4\"] = torch.cat(\n",
    "        [\n",
    "            ret[\"pt\"].unsqueeze(axis=-1),\n",
    "            ret[\"eta\"].unsqueeze(axis=-1),\n",
    "            ret[\"phi\"].unsqueeze(axis=-1),\n",
    "            ret[\"energy\"].unsqueeze(axis=-1),\n",
    "        ],\n",
    "        axis=-1,\n",
    "    )\n",
    "\n",
    "    return ret\n",
    "\n",
    "class MLPF(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim=16,\n",
    "        num_classes=6,\n",
    "        num_convs=2,\n",
    "        dropout_ff=0.0,\n",
    "        dropout_conv_reg_mha=0.0,\n",
    "        dropout_conv_reg_ff=0.0,\n",
    "        dropout_conv_id_mha=0.0,\n",
    "        dropout_conv_id_ff=0.0,\n",
    "        num_heads=16,\n",
    "        head_dim=16,\n",
    "        elemtypes=[0,1,2],\n",
    "    ):\n",
    "        super(MLPF, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.act = nn.ReLU  # Change activation function here\n",
    "        self.elemtypes = elemtypes\n",
    "        self.num_elemtypes = len(self.elemtypes)\n",
    "\n",
    "        embedding_dim = num_heads * head_dim\n",
    "        width = num_heads * head_dim\n",
    "        \n",
    "        self.nn0_id = ffn(self.input_dim, embedding_dim, width, self.act, dropout_ff)\n",
    "        self.nn0_reg = ffn(self.input_dim, embedding_dim, width, self.act, dropout_ff)\n",
    "        \n",
    "        self.conv_id = nn.ModuleList()\n",
    "        self.conv_reg = nn.ModuleList()\n",
    "\n",
    "        for i in range(num_convs):\n",
    "            self.conv_id.append(\n",
    "                SelfAttentionLayer(\n",
    "                    embedding_dim=embedding_dim,\n",
    "                    num_heads=num_heads,\n",
    "                    width=width,\n",
    "                    dropout_mha=dropout_conv_id_mha,\n",
    "                    dropout_ff=dropout_conv_id_ff,\n",
    "                )\n",
    "            )\n",
    "            self.conv_reg.append(\n",
    "                SelfAttentionLayer(\n",
    "                    embedding_dim=embedding_dim,\n",
    "                    num_heads=num_heads,\n",
    "                    width=width,\n",
    "                    dropout_mha=dropout_conv_reg_mha,\n",
    "                    dropout_ff=dropout_conv_reg_ff,\n",
    "                )\n",
    "            )\n",
    "\n",
    "        decoding_dim = self.input_dim + embedding_dim\n",
    "\n",
    "        # DNN that acts on the node level to predict the PID\n",
    "        self.nn_id = ffn(decoding_dim, num_classes, width, self.act, dropout_ff)\n",
    "\n",
    "        # elementwise DNN for node momentum regression\n",
    "        embed_dim = decoding_dim + num_classes\n",
    "        self.nn_pt = RegressionOutput(embed_dim, width, self.act, dropout_ff)\n",
    "        self.nn_eta = RegressionOutput(embed_dim, width, self.act, dropout_ff)\n",
    "        self.nn_sin_phi = RegressionOutput(embed_dim, width, self.act, dropout_ff)\n",
    "        self.nn_cos_phi = RegressionOutput(embed_dim, width, self.act, dropout_ff)\n",
    "        self.nn_energy = RegressionOutput(embed_dim, width, self.act, dropout_ff)\n",
    "        \n",
    "        self.quant = QuantizeFeaturesStub(self.input_dim + len(self.elemtypes))\n",
    "        self.dequant_id = torch.ao.quantization.DeQuantStub()\n",
    "\n",
    "    def forward(self, X_features, mask):\n",
    "        Xfeat_transformed = transform_batch(X_features)\n",
    "        Xfeat_normed = self.quant(Xfeat_transformed)\n",
    "\n",
    "        embeddings_id, embeddings_reg = [], []\n",
    "        embedding_id = self.nn0_id(Xfeat_normed)\n",
    "        embedding_reg = self.nn0_reg(Xfeat_normed)\n",
    "        for num, conv in enumerate(self.conv_id):\n",
    "            conv_input = embedding_id if num == 0 else embeddings_id[-1]\n",
    "            out_padded = conv(conv_input, mask)\n",
    "            embeddings_id.append(out_padded)\n",
    "        for num, conv in enumerate(self.conv_reg):\n",
    "            conv_input = embedding_reg if num == 0 else embeddings_reg[-1]\n",
    "            out_padded = conv(conv_input, mask)\n",
    "            embeddings_reg.append(out_padded)\n",
    "\n",
    "        final_embedding_id = torch.cat([Xfeat_normed] + [embeddings_id[-1]], axis=-1)\n",
    "        preds_id = self.nn_id(final_embedding_id)\n",
    "\n",
    "        final_embedding_reg = torch.cat([Xfeat_normed] + [embeddings_reg[-1]] + [preds_id], axis=-1)\n",
    "        preds_pt = self.nn_pt(X_features, final_embedding_reg, X_features[..., 1:2])\n",
    "        preds_eta = self.nn_eta(X_features, final_embedding_reg, X_features[..., 2:3])\n",
    "        preds_sin_phi = self.nn_sin_phi(X_features, final_embedding_reg, X_features[..., 3:4])\n",
    "        preds_cos_phi = self.nn_cos_phi(X_features, final_embedding_reg, X_features[..., 4:5])\n",
    "        preds_energy = self.nn_energy(X_features, final_embedding_reg, X_features[..., 5:6])\n",
    "        preds_momentum = torch.cat([preds_pt, preds_eta, preds_sin_phi, preds_cos_phi, preds_energy], axis=-1)\n",
    "        \n",
    "        preds_id = self.dequant_id(preds_id)\n",
    "        return preds_id, preds_momentum\n",
    "\n",
    "\n",
    "model = MLPF(input_dim=INPUT_DIM, num_classes=NUM_CLASSES)\n",
    "optimizer = torch.optim.Adam(lr=1e-4, params=model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "474a4c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.set_grad_enabled(True)  # Context-manager \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9647cc4f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=155.23\n",
      "Loss=123.46\n",
      "Loss=89.45\n",
      "Loss=96.62\n",
      "Loss=73.19\n",
      "Loss=75.12\n",
      "Loss=87.52\n",
      "Loss=77.18\n",
      "Loss=67.36\n",
      "Loss=69.89\n",
      "Loss=72.84\n",
      "Loss=76.07\n",
      "Loss=69.45\n",
      "Loss=88.33\n",
      "Loss=69.88\n",
      "Loss=70.09\n",
      "Loss=59.19\n",
      "Loss=55.33\n",
      "Loss=64.51\n",
      "Loss=72.77\n",
      "Loss=46.86\n",
      "Loss=59.42\n",
      "Loss=50.22\n",
      "Loss=61.57\n",
      "Loss=68.01\n",
      "Loss=64.40\n",
      "Loss=54.55\n",
      "Loss=58.13\n",
      "Loss=52.28\n",
      "Loss=63.64\n",
      "Loss=55.36\n",
      "Loss=44.04\n",
      "Loss=54.39\n",
      "Loss=49.73\n",
      "Loss=50.17\n",
      "Loss=47.59\n",
      "Loss=45.60\n",
      "Loss=51.65\n",
      "Loss=50.15\n",
      "Loss=40.24\n",
      "Loss=52.90\n",
      "Loss=45.78\n",
      "Loss=46.76\n",
      "Loss=37.63\n",
      "Loss=47.76\n",
      "Loss=45.85\n",
      "Loss=49.82\n",
      "Loss=50.32\n",
      "Loss=46.68\n",
      "Loss=43.60\n",
      "Loss=45.43\n",
      "Loss=42.18\n",
      "Loss=32.32\n",
      "Loss=40.34\n",
      "Loss=43.29\n",
      "Loss=40.46\n",
      "Loss=32.17\n",
      "Loss=36.47\n",
      "Loss=41.74\n",
      "Loss=37.30\n",
      "Loss=44.58\n",
      "Loss=39.63\n",
      "Loss=39.91\n",
      "Loss=40.11\n",
      "Loss=39.79\n",
      "Loss=36.98\n",
      "Loss=44.50\n",
      "Loss=37.26\n",
      "Loss=49.72\n",
      "Loss=36.88\n",
      "Loss=40.98\n",
      "Loss=37.53\n",
      "Loss=42.94\n",
      "Loss=37.81\n",
      "Loss=38.90\n",
      "Loss=40.75\n",
      "Loss=36.38\n",
      "Loss=33.50\n",
      "Loss=33.61\n",
      "Loss=31.63\n",
      "Loss=33.10\n",
      "Loss=32.33\n",
      "Loss=32.85\n",
      "Loss=35.19\n",
      "Loss=33.86\n",
      "Loss=34.94\n",
      "Loss=33.83\n",
      "Loss=32.21\n",
      "Loss=34.55\n",
      "Loss=36.78\n",
      "Loss=36.01\n",
      "Loss=29.95\n",
      "Loss=26.41\n",
      "Loss=35.83\n",
      "Loss=32.37\n",
      "Loss=40.15\n",
      "Loss=33.74\n",
      "Loss=31.29\n",
      "Loss=29.71\n",
      "Loss=28.33\n"
     ]
    }
   ],
   "source": [
    "max_events_train = 1000\n",
    "max_events_eval = 1000\n",
    "events_per_batch = 10\n",
    "\n",
    "losses = []\n",
    "\n",
    "#Training loop\n",
    "inds_train = range(0,max_events_train,events_per_batch)\n",
    "loss_vals = []\n",
    "\n",
    "for ind in inds_train:\n",
    "    optimizer.zero_grad()\n",
    "    ds_elems = [ds_train[i] for i in range(ind,ind+events_per_batch)]\n",
    "    X_features = [torch.tensor(elem[\"X\"]).to(torch.float32) for elem in ds_elems]\n",
    "    X_features_padded = pad_sequence(X_features, batch_first=True)\n",
    "    y_targets = [torch.tensor(elem[\"ygen\"]).to(torch.float32) for elem in ds_elems]\n",
    "    y_targets_padded = pad_sequence(y_targets, batch_first=True)\n",
    "    \n",
    "    mask = X_features_padded[:, :, 0]!=0\n",
    "\n",
    "    preds = model(X_features_padded, mask)\n",
    "    preds_unpacked_unq = unpack_predictions(preds)\n",
    "    targets_unpacked_unq = unpack_target(y_targets_padded)\n",
    "    \n",
    "    loss = mlpf_loss(targets_unpacked_unq, preds_unpacked_unq)\n",
    "    loss[\"Total\"].backward()\n",
    "    optimizer.step()\n",
    "    current_loss = loss[\"Total\"].detach().item()\n",
    "    losses.append(current_loss)\n",
    "    print(\"Loss={:.2f}\".format(loss[\"Total\"].detach().item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06f673c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "484683d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e691bd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# losses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab79643",
   "metadata": {},
   "source": [
    "## Quantized model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8b60eb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cvmfs/sft.cern.ch/lcg/views/LCG_105/x86_64-el9-gcc13-opt/lib/python3.9/site-packages/torch/ao/quantization/observer.py:214: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
      "  warnings.warn(\n",
      "/cvmfs/sft.cern.ch/lcg/views/LCG_105/x86_64-el9-gcc13-opt/lib/python3.9/site-packages/torch/ao/quantization/observer.py:1207: UserWarning: must run observer before calling calculate_qparams.                                    Returning default scale and zero point \n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# torch.backends.quantized.engine = 'onednn'\n",
    "\n",
    "model.eval()\n",
    "model.qconfig = torch.ao.quantization.get_default_qconfig('x86')\n",
    "model_prepared = torch.ao.quantization.prepare(model)\n",
    "\n",
    "\n",
    "#calibrate on data\n",
    "num_events_to_calibrate = 1\n",
    "for ind in range(1000,1000+num_events_to_calibrate):\n",
    "    X = torch.unsqueeze(torch.tensor(ds_train[ind][\"X\"]).to(torch.float32), 0)\n",
    "    mask = X[:, :, 0]!=0\n",
    "    model_prepared(X, mask)\n",
    "\n",
    "model_int8 = torch.ao.quantization.convert(model_prepared)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ad3335",
   "metadata": {},
   "source": [
    "## Training on the quantized model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1631487b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPF(\n",
       "  (nn0_id): Sequential(\n",
       "    (0): QuantizedLinear(in_features=17, out_features=256, scale=17.288698196411133, zero_point=68, qscheme=torch.per_channel_affine)\n",
       "    (1): ReLU()\n",
       "    (2): QuantizedLayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    (3): QuantizedDropout(p=0.0, inplace=False)\n",
       "    (4): QuantizedLinear(in_features=256, out_features=256, scale=0.03569576516747475, zero_point=69, qscheme=torch.per_channel_affine)\n",
       "  )\n",
       "  (nn0_reg): Sequential(\n",
       "    (0): QuantizedLinear(in_features=17, out_features=256, scale=20.763954162597656, zero_point=71, qscheme=torch.per_channel_affine)\n",
       "    (1): ReLU()\n",
       "    (2): QuantizedLayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    (3): QuantizedDropout(p=0.0, inplace=False)\n",
       "    (4): QuantizedLinear(in_features=256, out_features=256, scale=0.03111262619495392, zero_point=64, qscheme=torch.per_channel_affine)\n",
       "  )\n",
       "  (conv_id): ModuleList(\n",
       "    (0): SelfAttentionLayer(\n",
       "      (act): ReLU()\n",
       "      (mha): QuantizedMultiheadAttention(\n",
       "        (out_proj): QuantizedLinear(in_features=256, out_features=256, scale=0.008812063373625278, zero_point=59, qscheme=torch.per_channel_affine)\n",
       "        (linear_Q): QuantizedLinear(in_features=256, out_features=256, scale=0.025402072817087173, zero_point=68, qscheme=torch.per_channel_affine)\n",
       "        (linear_K): QuantizedLinear(in_features=256, out_features=256, scale=0.026112306863069534, zero_point=59, qscheme=torch.per_channel_affine)\n",
       "        (linear_V): QuantizedLinear(in_features=256, out_features=256, scale=0.024653423577547073, zero_point=61, qscheme=torch.per_channel_affine)\n",
       "        (q_scaling_product): QFunctional(\n",
       "          scale=1.0, zero_point=0\n",
       "          (activation_post_process): Identity()\n",
       "        )\n",
       "        (quant_attn_output): Quantize(scale=tensor([0.0120]), zero_point=tensor([65]), dtype=torch.quint8)\n",
       "        (quant_attn_output_weights): Quantize(scale=tensor([0.0001]), zero_point=tensor([0]), dtype=torch.quint8)\n",
       "        (dequant_q): DeQuantize()\n",
       "        (dequant_k): DeQuantize()\n",
       "        (dequant_v): DeQuantize()\n",
       "      )\n",
       "      (norm0): QuantizedLayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm1): QuantizedLayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (seq): Sequential(\n",
       "        (0): QuantizedLinear(in_features=256, out_features=256, scale=0.03250433877110481, zero_point=61, qscheme=torch.per_channel_affine)\n",
       "        (1): ReLU()\n",
       "        (2): QuantizedLinear(in_features=256, out_features=256, scale=0.015955911949276924, zero_point=63, qscheme=torch.per_channel_affine)\n",
       "        (3): ReLU()\n",
       "      )\n",
       "      (dropout): QuantizedDropout(p=0.0, inplace=False)\n",
       "      (add0): QFunctional(\n",
       "        scale=0.03733089566230774, zero_point=68\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "      (add1): QFunctional(\n",
       "        scale=0.06180152669548988, zero_point=66\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "      (mul): QFunctional(\n",
       "        scale=1.0, zero_point=0\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "    (1): SelfAttentionLayer(\n",
       "      (act): ReLU()\n",
       "      (mha): QuantizedMultiheadAttention(\n",
       "        (out_proj): QuantizedLinear(in_features=256, out_features=256, scale=0.015096193179488182, zero_point=66, qscheme=torch.per_channel_affine)\n",
       "        (linear_Q): QuantizedLinear(in_features=256, out_features=256, scale=0.03976430743932724, zero_point=63, qscheme=torch.per_channel_affine)\n",
       "        (linear_K): QuantizedLinear(in_features=256, out_features=256, scale=0.044085826724767685, zero_point=70, qscheme=torch.per_channel_affine)\n",
       "        (linear_V): QuantizedLinear(in_features=256, out_features=256, scale=0.04420548677444458, zero_point=59, qscheme=torch.per_channel_affine)\n",
       "        (q_scaling_product): QFunctional(\n",
       "          scale=1.0, zero_point=0\n",
       "          (activation_post_process): Identity()\n",
       "        )\n",
       "        (quant_attn_output): Quantize(scale=tensor([0.0187]), zero_point=tensor([62]), dtype=torch.quint8)\n",
       "        (quant_attn_output_weights): Quantize(scale=tensor([0.0011]), zero_point=tensor([0]), dtype=torch.quint8)\n",
       "        (dequant_q): DeQuantize()\n",
       "        (dequant_k): DeQuantize()\n",
       "        (dequant_v): DeQuantize()\n",
       "      )\n",
       "      (norm0): QuantizedLayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm1): QuantizedLayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (seq): Sequential(\n",
       "        (0): QuantizedLinear(in_features=256, out_features=256, scale=0.04635179787874222, zero_point=65, qscheme=torch.per_channel_affine)\n",
       "        (1): ReLU()\n",
       "        (2): QuantizedLinear(in_features=256, out_features=256, scale=0.01981150172650814, zero_point=56, qscheme=torch.per_channel_affine)\n",
       "        (3): ReLU()\n",
       "      )\n",
       "      (dropout): QuantizedDropout(p=0.0, inplace=False)\n",
       "      (add0): QFunctional(\n",
       "        scale=0.0612831749022007, zero_point=68\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "      (add1): QFunctional(\n",
       "        scale=0.05968298017978668, zero_point=63\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "      (mul): QFunctional(\n",
       "        scale=1.0, zero_point=0\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (conv_reg): ModuleList(\n",
       "    (0): SelfAttentionLayer(\n",
       "      (act): ReLU()\n",
       "      (mha): QuantizedMultiheadAttention(\n",
       "        (out_proj): QuantizedLinear(in_features=256, out_features=256, scale=0.007044837810099125, zero_point=66, qscheme=torch.per_channel_affine)\n",
       "        (linear_Q): QuantizedLinear(in_features=256, out_features=256, scale=0.022355232387781143, zero_point=57, qscheme=torch.per_channel_affine)\n",
       "        (linear_K): QuantizedLinear(in_features=256, out_features=256, scale=0.02003517933189869, zero_point=61, qscheme=torch.per_channel_affine)\n",
       "        (linear_V): QuantizedLinear(in_features=256, out_features=256, scale=0.02867085672914982, zero_point=62, qscheme=torch.per_channel_affine)\n",
       "        (q_scaling_product): QFunctional(\n",
       "          scale=1.0, zero_point=0\n",
       "          (activation_post_process): Identity()\n",
       "        )\n",
       "        (quant_attn_output): Quantize(scale=tensor([0.0086]), zero_point=tensor([54]), dtype=torch.quint8)\n",
       "        (quant_attn_output_weights): Quantize(scale=tensor([0.0001]), zero_point=tensor([0]), dtype=torch.quint8)\n",
       "        (dequant_q): DeQuantize()\n",
       "        (dequant_k): DeQuantize()\n",
       "        (dequant_v): DeQuantize()\n",
       "      )\n",
       "      (norm0): QuantizedLayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm1): QuantizedLayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (seq): Sequential(\n",
       "        (0): QuantizedLinear(in_features=256, out_features=256, scale=0.032981548458337784, zero_point=64, qscheme=torch.per_channel_affine)\n",
       "        (1): ReLU()\n",
       "        (2): QuantizedLinear(in_features=256, out_features=256, scale=0.01312987506389618, zero_point=61, qscheme=torch.per_channel_affine)\n",
       "        (3): ReLU()\n",
       "      )\n",
       "      (dropout): QuantizedDropout(p=0.0, inplace=False)\n",
       "      (add0): QFunctional(\n",
       "        scale=0.03290868178009987, zero_point=64\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "      (add1): QFunctional(\n",
       "        scale=0.057500213384628296, zero_point=60\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "      (mul): QFunctional(\n",
       "        scale=1.0, zero_point=0\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "    (1): SelfAttentionLayer(\n",
       "      (act): ReLU()\n",
       "      (mha): QuantizedMultiheadAttention(\n",
       "        (out_proj): QuantizedLinear(in_features=256, out_features=256, scale=0.012705447152256966, zero_point=64, qscheme=torch.per_channel_affine)\n",
       "        (linear_Q): QuantizedLinear(in_features=256, out_features=256, scale=0.043248165398836136, zero_point=69, qscheme=torch.per_channel_affine)\n",
       "        (linear_K): QuantizedLinear(in_features=256, out_features=256, scale=0.04342852532863617, zero_point=62, qscheme=torch.per_channel_affine)\n",
       "        (linear_V): QuantizedLinear(in_features=256, out_features=256, scale=0.04425366595387459, zero_point=70, qscheme=torch.per_channel_affine)\n",
       "        (q_scaling_product): QFunctional(\n",
       "          scale=1.0, zero_point=0\n",
       "          (activation_post_process): Identity()\n",
       "        )\n",
       "        (quant_attn_output): Quantize(scale=tensor([0.0187]), zero_point=tensor([62]), dtype=torch.quint8)\n",
       "        (quant_attn_output_weights): Quantize(scale=tensor([0.0003]), zero_point=tensor([0]), dtype=torch.quint8)\n",
       "        (dequant_q): DeQuantize()\n",
       "        (dequant_k): DeQuantize()\n",
       "        (dequant_v): DeQuantize()\n",
       "      )\n",
       "      (norm0): QuantizedLayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm1): QuantizedLayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (seq): Sequential(\n",
       "        (0): QuantizedLinear(in_features=256, out_features=256, scale=0.034290611743927, zero_point=63, qscheme=torch.per_channel_affine)\n",
       "        (1): ReLU()\n",
       "        (2): QuantizedLinear(in_features=256, out_features=256, scale=0.014845549128949642, zero_point=64, qscheme=torch.per_channel_affine)\n",
       "        (3): ReLU()\n",
       "      )\n",
       "      (dropout): QuantizedDropout(p=0.0, inplace=False)\n",
       "      (add0): QFunctional(\n",
       "        scale=0.05855826288461685, zero_point=61\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "      (add1): QFunctional(\n",
       "        scale=0.05653809756040573, zero_point=59\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "      (mul): QFunctional(\n",
       "        scale=1.0, zero_point=0\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (nn_id): Sequential(\n",
       "    (0): QuantizedLinear(in_features=273, out_features=256, scale=4.665538311004639, zero_point=66, qscheme=torch.per_channel_affine)\n",
       "    (1): ReLU()\n",
       "    (2): QuantizedLayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    (3): QuantizedDropout(p=0.0, inplace=False)\n",
       "    (4): QuantizedLinear(in_features=256, out_features=6, scale=0.03553812578320503, zero_point=46, qscheme=torch.per_channel_affine)\n",
       "  )\n",
       "  (nn_pt): RegressionOutput(\n",
       "    (dequant): DeQuantize()\n",
       "    (nn): Sequential(\n",
       "      (0): QuantizedLinear(in_features=279, out_features=256, scale=5.505131721496582, zero_point=61, qscheme=torch.per_channel_affine)\n",
       "      (1): ReLU()\n",
       "      (2): QuantizedLayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (3): QuantizedDropout(p=0.0, inplace=False)\n",
       "      (4): QuantizedLinear(in_features=256, out_features=1, scale=0.005202557425945997, zero_point=102, qscheme=torch.per_channel_affine)\n",
       "    )\n",
       "  )\n",
       "  (nn_eta): RegressionOutput(\n",
       "    (dequant): DeQuantize()\n",
       "    (nn): Sequential(\n",
       "      (0): QuantizedLinear(in_features=279, out_features=256, scale=5.3206071853637695, zero_point=62, qscheme=torch.per_channel_affine)\n",
       "      (1): ReLU()\n",
       "      (2): QuantizedLayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (3): QuantizedDropout(p=0.0, inplace=False)\n",
       "      (4): QuantizedLinear(in_features=256, out_features=1, scale=0.004676548298448324, zero_point=67, qscheme=torch.per_channel_affine)\n",
       "    )\n",
       "  )\n",
       "  (nn_sin_phi): RegressionOutput(\n",
       "    (dequant): DeQuantize()\n",
       "    (nn): Sequential(\n",
       "      (0): QuantizedLinear(in_features=279, out_features=256, scale=5.064384460449219, zero_point=69, qscheme=torch.per_channel_affine)\n",
       "      (1): ReLU()\n",
       "      (2): QuantizedLayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (3): QuantizedDropout(p=0.0, inplace=False)\n",
       "      (4): QuantizedLinear(in_features=256, out_features=1, scale=0.0030970326624810696, zero_point=59, qscheme=torch.per_channel_affine)\n",
       "    )\n",
       "  )\n",
       "  (nn_cos_phi): RegressionOutput(\n",
       "    (dequant): DeQuantize()\n",
       "    (nn): Sequential(\n",
       "      (0): QuantizedLinear(in_features=279, out_features=256, scale=4.830129146575928, zero_point=67, qscheme=torch.per_channel_affine)\n",
       "      (1): ReLU()\n",
       "      (2): QuantizedLayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (3): QuantizedDropout(p=0.0, inplace=False)\n",
       "      (4): QuantizedLinear(in_features=256, out_features=1, scale=0.003233908209949732, zero_point=71, qscheme=torch.per_channel_affine)\n",
       "    )\n",
       "  )\n",
       "  (nn_energy): RegressionOutput(\n",
       "    (dequant): DeQuantize()\n",
       "    (nn): Sequential(\n",
       "      (0): QuantizedLinear(in_features=279, out_features=256, scale=4.747920513153076, zero_point=70, qscheme=torch.per_channel_affine)\n",
       "      (1): ReLU()\n",
       "      (2): QuantizedLayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (3): QuantizedDropout(p=0.0, inplace=False)\n",
       "      (4): QuantizedLinear(in_features=256, out_features=1, scale=0.005486173555254936, zero_point=112, qscheme=torch.per_channel_affine)\n",
       "    )\n",
       "  )\n",
       "  (quant): QuantizeFeaturesStub(\n",
       "    (quants): ModuleList(\n",
       "      (0): Quantize(scale=tensor([0.0157]), zero_point=tensor([0]), dtype=torch.quint8)\n",
       "      (1): Quantize(scale=tensor([0.0489]), zero_point=tensor([46]), dtype=torch.quint8)\n",
       "      (2): Quantize(scale=tensor([0.0315]), zero_point=tensor([70]), dtype=torch.quint8)\n",
       "      (3-4): 2 x Quantize(scale=tensor([0.0157]), zero_point=tensor([64]), dtype=torch.quint8)\n",
       "      (5): Quantize(scale=tensor([0.0510]), zero_point=tensor([39]), dtype=torch.quint8)\n",
       "      (6): Quantize(scale=tensor([30.6385]), zero_point=tensor([74]), dtype=torch.quint8)\n",
       "      (7): Quantize(scale=tensor([29.3899]), zero_point=tensor([65]), dtype=torch.quint8)\n",
       "      (8): Quantize(scale=tensor([44.5062]), zero_point=tensor([63]), dtype=torch.quint8)\n",
       "      (9): Quantize(scale=tensor([0.0229]), zero_point=tensor([0]), dtype=torch.quint8)\n",
       "      (10): Quantize(scale=tensor([2.6954]), zero_point=tensor([0]), dtype=torch.quint8)\n",
       "      (11): Quantize(scale=tensor([0.1419]), zero_point=tensor([31]), dtype=torch.quint8)\n",
       "      (12): Quantize(scale=tensor([0.0875]), zero_point=tensor([49]), dtype=torch.quint8)\n",
       "      (13): Quantize(scale=tensor([4.2263]), zero_point=tensor([0]), dtype=torch.quint8)\n",
       "      (14): Quantize(scale=tensor([3.6075]), zero_point=tensor([2]), dtype=torch.quint8)\n",
       "      (15): Quantize(scale=tensor([2.6614]), zero_point=tensor([0]), dtype=torch.quint8)\n",
       "      (16): Quantize(scale=tensor([6.0954]), zero_point=tensor([0]), dtype=torch.quint8)\n",
       "      (17-19): 3 x Quantize(scale=tensor([1.]), zero_point=tensor([0]), dtype=torch.quint8)\n",
       "    )\n",
       "  )\n",
       "  (dequant_id): DeQuantize()\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_int8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698dc268",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "acbb14a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification tensor(122.5970)\n",
      "classification tensor(3.4397)\n",
      "Total loss tensor(126.0367)\n",
      "Loss=126.04\n",
      "classification tensor(122.6972)\n",
      "classification tensor(2.9952)\n",
      "Total loss tensor(125.6924)\n",
      "Loss=125.69\n",
      "classification tensor(121.8849)\n",
      "classification tensor(2.4634)\n",
      "Total loss tensor(124.3483)\n",
      "Loss=124.35\n",
      "classification tensor(122.7388)\n",
      "classification tensor(4.5265)\n",
      "Total loss tensor(127.2653)\n",
      "Loss=127.27\n",
      "classification tensor(122.0704)\n",
      "classification tensor(2.9142)\n",
      "Total loss tensor(124.9846)\n",
      "Loss=124.98\n",
      "classification tensor(122.2450)\n",
      "classification tensor(3.4814)\n",
      "Total loss tensor(125.7264)\n",
      "Loss=125.73\n",
      "classification tensor(122.6516)\n",
      "classification tensor(4.6377)\n",
      "Total loss tensor(127.2893)\n",
      "Loss=127.29\n",
      "classification tensor(122.5752)\n",
      "classification tensor(4.2769)\n",
      "Total loss tensor(126.8521)\n",
      "Loss=126.85\n",
      "classification tensor(122.0044)\n",
      "classification tensor(3.6601)\n",
      "Total loss tensor(125.6645)\n",
      "Loss=125.66\n",
      "classification tensor(122.5522)\n",
      "classification tensor(3.2466)\n",
      "Total loss tensor(125.7988)\n",
      "Loss=125.80\n",
      "classification tensor(122.4197)\n",
      "classification tensor(4.9304)\n",
      "Total loss tensor(127.3501)\n",
      "Loss=127.35\n",
      "classification tensor(122.9461)\n",
      "classification tensor(3.1465)\n",
      "Total loss tensor(126.0926)\n",
      "Loss=126.09\n",
      "classification tensor(122.5893)\n",
      "classification tensor(4.1463)\n",
      "Total loss tensor(126.7356)\n",
      "Loss=126.74\n",
      "classification tensor(122.8378)\n",
      "classification tensor(4.6805)\n",
      "Total loss tensor(127.5183)\n",
      "Loss=127.52\n",
      "classification tensor(122.5844)\n",
      "classification tensor(3.5154)\n",
      "Total loss tensor(126.0999)\n",
      "Loss=126.10\n",
      "classification tensor(122.5170)\n",
      "classification tensor(3.1586)\n",
      "Total loss tensor(125.6756)\n",
      "Loss=125.68\n",
      "classification tensor(122.1467)\n",
      "classification tensor(5.6369)\n",
      "Total loss tensor(127.7836)\n",
      "Loss=127.78\n",
      "classification tensor(122.1086)\n",
      "classification tensor(1.7820)\n",
      "Total loss tensor(123.8907)\n",
      "Loss=123.89\n",
      "classification tensor(122.3794)\n",
      "classification tensor(4.6690)\n",
      "Total loss tensor(127.0484)\n",
      "Loss=127.05\n",
      "classification tensor(122.9314)\n",
      "classification tensor(5.6889)\n",
      "Total loss tensor(128.6204)\n",
      "Loss=128.62\n",
      "classification tensor(121.6753)\n",
      "classification tensor(2.3886)\n",
      "Total loss tensor(124.0638)\n",
      "Loss=124.06\n",
      "classification tensor(122.3031)\n",
      "classification tensor(2.5750)\n",
      "Total loss tensor(124.8780)\n",
      "Loss=124.88\n",
      "classification tensor(121.9636)\n",
      "classification tensor(2.8978)\n",
      "Total loss tensor(124.8614)\n",
      "Loss=124.86\n",
      "classification tensor(122.3984)\n",
      "classification tensor(3.8726)\n",
      "Total loss tensor(126.2710)\n",
      "Loss=126.27\n",
      "classification tensor(122.9055)\n",
      "classification tensor(2.8812)\n",
      "Total loss tensor(125.7867)\n",
      "Loss=125.79\n",
      "classification tensor(122.4909)\n",
      "classification tensor(3.6599)\n",
      "Total loss tensor(126.1508)\n",
      "Loss=126.15\n",
      "classification tensor(122.3049)\n",
      "classification tensor(3.5582)\n",
      "Total loss tensor(125.8632)\n",
      "Loss=125.86\n",
      "classification tensor(122.3369)\n",
      "classification tensor(3.1199)\n",
      "Total loss tensor(125.4568)\n",
      "Loss=125.46\n",
      "classification tensor(122.1839)\n",
      "classification tensor(3.1709)\n",
      "Total loss tensor(125.3548)\n",
      "Loss=125.35\n",
      "classification tensor(122.7877)\n",
      "classification tensor(5.1697)\n",
      "Total loss tensor(127.9574)\n",
      "Loss=127.96\n",
      "classification tensor(122.4132)\n",
      "classification tensor(3.6279)\n",
      "Total loss tensor(126.0411)\n",
      "Loss=126.04\n",
      "classification tensor(121.8167)\n",
      "classification tensor(3.2916)\n",
      "Total loss tensor(125.1083)\n",
      "Loss=125.11\n",
      "classification tensor(122.3507)\n",
      "classification tensor(3.5414)\n",
      "Total loss tensor(125.8921)\n",
      "Loss=125.89\n",
      "classification tensor(122.4129)\n",
      "classification tensor(3.0827)\n",
      "Total loss tensor(125.4956)\n",
      "Loss=125.50\n",
      "classification tensor(122.2644)\n",
      "classification tensor(2.9312)\n",
      "Total loss tensor(125.1956)\n",
      "Loss=125.20\n",
      "classification tensor(122.2359)\n",
      "classification tensor(2.6752)\n",
      "Total loss tensor(124.9112)\n",
      "Loss=124.91\n",
      "classification tensor(122.0397)\n",
      "classification tensor(3.5575)\n",
      "Total loss tensor(125.5972)\n",
      "Loss=125.60\n",
      "classification tensor(122.4458)\n",
      "classification tensor(3.4646)\n",
      "Total loss tensor(125.9104)\n",
      "Loss=125.91\n",
      "classification tensor(122.4113)\n",
      "classification tensor(2.8626)\n",
      "Total loss tensor(125.2739)\n",
      "Loss=125.27\n",
      "classification tensor(121.8553)\n",
      "classification tensor(3.1256)\n",
      "Total loss tensor(124.9809)\n",
      "Loss=124.98\n",
      "classification tensor(122.4090)\n",
      "classification tensor(5.8043)\n",
      "Total loss tensor(128.2132)\n",
      "Loss=128.21\n",
      "classification tensor(122.2401)\n",
      "classification tensor(4.5574)\n",
      "Total loss tensor(126.7975)\n",
      "Loss=126.80\n",
      "classification tensor(122.1443)\n",
      "classification tensor(3.2302)\n",
      "Total loss tensor(125.3745)\n",
      "Loss=125.37\n",
      "classification tensor(121.8850)\n",
      "classification tensor(2.5045)\n",
      "Total loss tensor(124.3894)\n",
      "Loss=124.39\n",
      "classification tensor(122.1932)\n",
      "classification tensor(3.8621)\n",
      "Total loss tensor(126.0552)\n",
      "Loss=126.06\n",
      "classification tensor(122.3732)\n",
      "classification tensor(2.6129)\n",
      "Total loss tensor(124.9861)\n",
      "Loss=124.99\n",
      "classification tensor(122.5919)\n",
      "classification tensor(4.2183)\n",
      "Total loss tensor(126.8102)\n",
      "Loss=126.81\n",
      "classification tensor(122.7759)\n",
      "classification tensor(4.1343)\n",
      "Total loss tensor(126.9101)\n",
      "Loss=126.91\n",
      "classification tensor(122.4966)\n",
      "classification tensor(3.1623)\n",
      "Total loss tensor(125.6590)\n",
      "Loss=125.66\n",
      "classification tensor(122.4300)\n",
      "classification tensor(3.6849)\n",
      "Total loss tensor(126.1149)\n",
      "Loss=126.11\n",
      "classification tensor(122.5588)\n",
      "classification tensor(3.3732)\n",
      "Total loss tensor(125.9320)\n",
      "Loss=125.93\n",
      "classification tensor(122.2367)\n",
      "classification tensor(2.6622)\n",
      "Total loss tensor(124.8989)\n",
      "Loss=124.90\n",
      "classification tensor(121.4675)\n",
      "classification tensor(2.2419)\n",
      "Total loss tensor(123.7094)\n",
      "Loss=123.71\n",
      "classification tensor(122.0980)\n",
      "classification tensor(2.9058)\n",
      "Total loss tensor(125.0039)\n",
      "Loss=125.00\n",
      "classification tensor(122.1680)\n",
      "classification tensor(3.8894)\n",
      "Total loss tensor(126.0575)\n",
      "Loss=126.06\n",
      "classification tensor(122.3439)\n",
      "classification tensor(2.5195)\n",
      "Total loss tensor(124.8633)\n",
      "Loss=124.86\n",
      "classification tensor(121.8731)\n",
      "classification tensor(2.1586)\n",
      "Total loss tensor(124.0317)\n",
      "Loss=124.03\n",
      "classification tensor(121.9281)\n",
      "classification tensor(2.7585)\n",
      "Total loss tensor(124.6867)\n",
      "Loss=124.69\n",
      "classification tensor(122.3444)\n",
      "classification tensor(4.5366)\n",
      "Total loss tensor(126.8810)\n",
      "Loss=126.88\n",
      "classification tensor(122.0629)\n",
      "classification tensor(2.6013)\n",
      "Total loss tensor(124.6642)\n",
      "Loss=124.66\n",
      "classification tensor(122.7895)\n",
      "classification tensor(4.6887)\n",
      "Total loss tensor(127.4782)\n",
      "Loss=127.48\n",
      "classification tensor(122.3295)\n",
      "classification tensor(2.6930)\n",
      "Total loss tensor(125.0225)\n",
      "Loss=125.02\n",
      "classification tensor(122.3336)\n",
      "classification tensor(3.7814)\n",
      "Total loss tensor(126.1150)\n",
      "Loss=126.12\n",
      "classification tensor(122.3050)\n",
      "classification tensor(4.3720)\n",
      "Total loss tensor(126.6770)\n",
      "Loss=126.68\n",
      "classification tensor(122.4040)\n",
      "classification tensor(4.1262)\n",
      "Total loss tensor(126.5302)\n",
      "Loss=126.53\n",
      "classification tensor(122.4925)\n",
      "classification tensor(2.4128)\n",
      "Total loss tensor(124.9053)\n",
      "Loss=124.91\n",
      "classification tensor(122.5964)\n",
      "classification tensor(4.2745)\n",
      "Total loss tensor(126.8709)\n",
      "Loss=126.87\n",
      "classification tensor(122.5284)\n",
      "classification tensor(2.2981)\n",
      "Total loss tensor(124.8266)\n",
      "Loss=124.83\n",
      "classification tensor(122.9547)\n",
      "classification tensor(8.7285)\n",
      "Total loss tensor(131.6831)\n",
      "Loss=131.68\n",
      "classification tensor(122.0750)\n",
      "classification tensor(2.6547)\n",
      "Total loss tensor(124.7297)\n",
      "Loss=124.73\n",
      "classification tensor(122.6233)\n",
      "classification tensor(3.3469)\n",
      "Total loss tensor(125.9702)\n",
      "Loss=125.97\n",
      "classification tensor(122.4092)\n",
      "classification tensor(4.1094)\n",
      "Total loss tensor(126.5186)\n",
      "Loss=126.52\n",
      "classification tensor(122.5692)\n",
      "classification tensor(5.3859)\n",
      "Total loss tensor(127.9552)\n",
      "Loss=127.96\n",
      "classification tensor(122.2951)\n",
      "classification tensor(4.8144)\n",
      "Total loss tensor(127.1095)\n",
      "Loss=127.11\n",
      "classification tensor(122.3956)\n",
      "classification tensor(4.8716)\n",
      "Total loss tensor(127.2672)\n",
      "Loss=127.27\n",
      "classification tensor(122.6057)\n",
      "classification tensor(4.3106)\n",
      "Total loss tensor(126.9164)\n",
      "Loss=126.92\n",
      "classification tensor(122.3609)\n",
      "classification tensor(3.1775)\n",
      "Total loss tensor(125.5384)\n",
      "Loss=125.54\n",
      "classification tensor(122.2912)\n",
      "classification tensor(2.8668)\n",
      "Total loss tensor(125.1580)\n",
      "Loss=125.16\n",
      "classification tensor(122.1137)\n",
      "classification tensor(3.5628)\n",
      "Total loss tensor(125.6765)\n",
      "Loss=125.68\n",
      "classification tensor(122.1221)\n",
      "classification tensor(3.7997)\n",
      "Total loss tensor(125.9217)\n",
      "Loss=125.92\n",
      "classification tensor(122.1771)\n",
      "classification tensor(2.8085)\n",
      "Total loss tensor(124.9856)\n",
      "Loss=124.99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification tensor(122.1720)\n",
      "classification tensor(3.5528)\n",
      "Total loss tensor(125.7248)\n",
      "Loss=125.72\n",
      "classification tensor(122.1201)\n",
      "classification tensor(3.5591)\n",
      "Total loss tensor(125.6792)\n",
      "Loss=125.68\n",
      "classification tensor(122.4754)\n",
      "classification tensor(3.4831)\n",
      "Total loss tensor(125.9585)\n",
      "Loss=125.96\n",
      "classification tensor(122.2484)\n",
      "classification tensor(3.7255)\n",
      "Total loss tensor(125.9739)\n",
      "Loss=125.97\n",
      "classification tensor(122.4637)\n",
      "classification tensor(3.2031)\n",
      "Total loss tensor(125.6668)\n",
      "Loss=125.67\n",
      "classification tensor(122.2160)\n",
      "classification tensor(4.0647)\n",
      "Total loss tensor(126.2808)\n",
      "Loss=126.28\n",
      "classification tensor(122.3675)\n",
      "classification tensor(4.1453)\n",
      "Total loss tensor(126.5127)\n",
      "Loss=126.51\n",
      "classification tensor(122.6147)\n",
      "classification tensor(3.0485)\n",
      "Total loss tensor(125.6632)\n",
      "Loss=125.66\n",
      "classification tensor(122.5678)\n",
      "classification tensor(3.5332)\n",
      "Total loss tensor(126.1009)\n",
      "Loss=126.10\n",
      "classification tensor(122.2823)\n",
      "classification tensor(5.3489)\n",
      "Total loss tensor(127.6312)\n",
      "Loss=127.63\n",
      "classification tensor(122.1633)\n",
      "classification tensor(3.4400)\n",
      "Total loss tensor(125.6033)\n",
      "Loss=125.60\n",
      "classification tensor(121.8015)\n",
      "classification tensor(3.2517)\n",
      "Total loss tensor(125.0532)\n",
      "Loss=125.05\n",
      "classification tensor(122.5573)\n",
      "classification tensor(4.3109)\n",
      "Total loss tensor(126.8681)\n",
      "Loss=126.87\n",
      "classification tensor(122.2060)\n",
      "classification tensor(3.8624)\n",
      "Total loss tensor(126.0684)\n",
      "Loss=126.07\n",
      "classification tensor(122.1451)\n",
      "classification tensor(12.6563)\n",
      "Total loss tensor(134.8014)\n",
      "Loss=134.80\n",
      "classification tensor(122.1904)\n",
      "classification tensor(4.2646)\n",
      "Total loss tensor(126.4550)\n",
      "Loss=126.45\n",
      "classification tensor(122.4351)\n",
      "classification tensor(3.3166)\n",
      "Total loss tensor(125.7517)\n",
      "Loss=125.75\n",
      "classification tensor(122.3498)\n",
      "classification tensor(2.7370)\n",
      "Total loss tensor(125.0868)\n",
      "Loss=125.09\n",
      "classification tensor(122.1236)\n",
      "classification tensor(2.8665)\n",
      "Total loss tensor(124.9901)\n",
      "Loss=124.99\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_events_train = 1000\n",
    "events_per_batch = 10\n",
    "quantized_losses = []\n",
    "\n",
    "# Training loop\n",
    "inds_train = range(0, max_events_train, events_per_batch)\n",
    "for ind in inds_train:\n",
    "    optimizer.zero_grad()\n",
    "    ds_elems = [ds_train[i] for i in range(ind, ind + events_per_batch)]\n",
    "    X_features = [torch.tensor(elem[\"X\"]).to(torch.float32) for elem in ds_elems]\n",
    "    X_features_padded = pad_sequence(X_features, batch_first=True)\n",
    "    y_targets = [torch.tensor(elem[\"ygen\"]).to(torch.float32) for elem in ds_elems]\n",
    "    y_targets_padded = pad_sequence(y_targets, batch_first=True)\n",
    "    \n",
    "    mask = X_features_padded[:, :, 0] != 0\n",
    "\n",
    "    preds = model_int8(X_features_padded, mask)\n",
    "    preds_unpacked = unpack_predictions(preds)\n",
    "    targets_unpacked = unpack_target(y_targets_padded)\n",
    "\n",
    "    loss = mlpf_loss(targets_unpacked, preds_unpacked)\n",
    "    \n",
    "    # Ensure all tensors contributing to the loss have requires_grad = True\n",
    "    for key, value in loss.items():\n",
    "        if value.requires_grad is False:\n",
    "            value.requires_grad = True\n",
    "\n",
    "    loss_total = loss[\"Total\"].sum()  \n",
    "    loss_total.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    current_loss = loss_total.detach().item()\n",
    "    quantized_losses.append(current_loss)\n",
    "    print(\"Loss={:.2f}\".format(current_loss))\n",
    "\n",
    "# Plot\n",
    "plt.plot(quantized_losses)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Quantized Training Loss Curve')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ee44fb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses, label='Fp32')\n",
    "plt.plot(quantized_losses, label='Int8')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Training Loss')\n",
    "plt.legend()\n",
    "# plt.title('Quantized Training Loss Curve')\n",
    "plt.title('x86')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fcc54e9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification tensor(122.1236)\n",
      "classification tensor(2.8665)\n",
      "Total loss tensor(124.9901)\n",
      "Quantized Model Loss with x86: 124.99\n"
     ]
    }
   ],
   "source": [
    "X_data_quantized = [torch.tensor(elem[\"X\"]).to(torch.float32) for elem in ds_elems]\n",
    "X_data_quantized_padded = pad_sequence(X_data_quantized, batch_first=True)\n",
    "mask_quantized = X_data_quantized_padded[:, :, 0] != 0  \n",
    "#pred\n",
    "with torch.no_grad():\n",
    "    preds_quantized = model_int8(X_data_quantized_padded, mask_quantized)\n",
    "    \n",
    "preds_quantized_unpacked = unpack_predictions(preds_quantized)\n",
    "targets_unpacked = unpack_target(y_targets_padded)\n",
    "\n",
    "#loss\n",
    "loss_quantized = mlpf_loss(targets_unpacked, preds_quantized_unpacked)\n",
    "\n",
    "print(\"Quantized Model Loss with x86: {:.2f}\".format(loss_quantized[\"Total\"].item()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653d4c31",
   "metadata": {},
   "source": [
    "**Quantized Model Loss with onednn: 121.74 \\\n",
    "Quantized Model Loss with x86: 125.51 \\\n",
    "Unquantized model loss: 29.26**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d4cbd5",
   "metadata": {},
   "source": [
    "**Dataset Information:**\n",
    "\n",
    "X: the reconstruction input features, i.e. tracks and clusters\n",
    "\n",
    "ygen: the ground truth particles with the features [\"PDG\", \"charge\", \"pt\", \"eta\", \"sin_phi\", \"cos_phi\", \"energy\", \"jet_idx\"], with \"jet_idx\" corresponding to the gen-jet assignment of this particle\n",
    "\n",
    "https://zenodo.org/records/8409592"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06a4896",
   "metadata": {},
   "source": [
    "**To Do:**\n",
    "* ultimately reproduce Fig 9 from the [paper](https://arxiv.org/pdf/2309.06782.pdf), adding additional an int8-quantized MLPF model (e.g. dashed orange line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6b32c680",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 248])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets_unpacked['pt'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a6f53851",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 201])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets_unpacked_unq['pt'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d5e56b7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[29.3308, 16.3776, 11.0753,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [11.4296, 11.2534,  7.4814,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [81.4108, 19.7446,  3.0669,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        ...,\n",
       "        [11.9754, 11.1559,  7.4632,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 2.0538, 11.2622, 11.8753,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 4.5375, 30.6604, 13.4644,  ...,  0.0000,  0.0000,  0.0000]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets_unpacked['pt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "32e1bf30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5.2084, 10.8834,  9.6858,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [12.7611, 10.4114, 10.9317,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [10.4192, 14.1023,  1.7646,  ..., 11.3411,  4.4822,  0.0000],\n",
       "        ...,\n",
       "        [ 3.9776, 19.7735, 11.2324,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 8.0681,  7.6773, 21.1527,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [11.5500, 48.6111,  8.4631,  ...,  0.0000,  0.0000,  0.0000]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets_unpacked_unq['pt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c4ac44d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_val = torch.min(targets_unpacked['pt']).item()\n",
    "max_val = torch.max(targets_unpacked['pt']).item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4ce37d38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 81.4107666015625)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_val, max_val "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bf35c92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_val = torch.min(targets_unpacked_unq['pt']).item()\n",
    "max_val = torch.max(targets_unpacked_unq['pt']).item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fb0a7d18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 81.24093627929688)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_val, max_val "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6033b60a",
   "metadata": {},
   "source": [
    "```python\n",
    "msk_true_particle = torch.unsqueeze((y[\"cls_id\"] != 0).to(dtype=torch.float32), axis=-1)        \n",
    "px = ypred[\"momentum\"][..., 0:1] * ypred[\"momentum\"][..., 3:4] * msk_true_particle\n",
    "py = ypred[\"momentum\"][..., 0:1] * ypred[\"momentum\"][..., 2:3] * msk_true_particle\n",
    "pred_met = torch.sqrt(torch.sum(px, axis=-2) ** 2 + torch.sum(py, axis=-2) ** 2)\n",
    "\n",
    "px = y[\"momentum\"][..., 0:1] * y[\"momentum\"][..., 3:4] * msk_true_particle\n",
    "py = y[\"momentum\"][..., 0:1] * y[\"momentum\"][..., 2:3] * msk_true_particle\n",
    "true_met = torch.sqrt(torch.sum(px, axis=-2) ** 2 + torch.sum(py, axis=-2) ** 2)\n",
    "```\n",
    "        \n",
    "        \n",
    "if you do something like this, you can compute the true and predicted MET\n",
    "\n",
    "\n",
    "and compare their distributions and response=pred_met/true_met"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb961381",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'targets_unpacked_unq' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/sraj/ipykernel_2341133/3773369572.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmsk_true_particle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets_unpacked_unq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"cls_id\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreds_unpacked_unq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"momentum\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mpreds_unpacked_unq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"momentum\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmsk_true_particle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreds_unpacked_unq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"momentum\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mpreds_unpacked_unq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"momentum\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmsk_true_particle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# pred_met is \\sqrt(px**2+py**2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpx_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'targets_unpacked_unq' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "msk_true_particle = torch.unsqueeze((targets_unpacked_unq[\"cls_id\"] != 0).to(dtype=torch.float32), axis=-1)\n",
    "px = preds_unpacked_unq[\"momentum\"][..., 0:1] * preds_unpacked_unq[\"momentum\"][..., 3:4] * msk_true_particle\n",
    "py = preds_unpacked_unq[\"momentum\"][..., 0:1] * preds_unpacked_unq[\"momentum\"][..., 2:3] * msk_true_particle\n",
    "# pred_met is \\sqrt(px**2+py**2)\n",
    "px_sum = torch.sum(px, axis=-2)\n",
    "py_sum = torch.sum(py, axis=-2)\n",
    "pred_met = torch.sqrt(px_sum ** 2 + py_sum ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "27ffa730",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[17.0119],\n",
       "        [61.4280],\n",
       "        [30.6598],\n",
       "        [16.8550],\n",
       "        [ 3.2127],\n",
       "        [73.5539],\n",
       "        [90.8664],\n",
       "        [57.6672],\n",
       "        [40.3295],\n",
       "        [ 3.8403]], grad_fn=<SqrtBackward0>)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_met"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0926d19d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/sraj/ipykernel_649402/2019659273.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Compute msk_true_particle for y tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmsk_true_particle_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"cls_id\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Compute px for y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpx_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"momentum\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"momentum\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmsk_true_particle_y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y' is not defined"
     ]
    }
   ],
   "source": [
    "# Compute msk_true_particle for y tensor\n",
    "msk_true_particle_y = torch.unsqueeze((yp[\"cls_id\"] != 0).to(dtype=torch.float32), axis=-1)\n",
    "\n",
    "# Compute px for y\n",
    "px_y = y[\"momentum\"][..., 0:1] * y[\"momentum\"][..., 3:4] * msk_true_particle_y\n",
    "\n",
    "# Compute py for y\n",
    "py_y = y[\"momentum\"][..., 0:1] * y[\"momentum\"][..., 2:3] * msk_true_particle_y\n",
    "\n",
    "# Compute true_met\n",
    "px_sum_y = torch.sum(px_y, axis=-2)\n",
    "py_sum_y = torch.sum(py_y, axis=-2)\n",
    "true_met = torch.sqrt(px_sum_y ** 2 + py_sum_y ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2aa963c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.0000e+00,  1.0000e+00,  2.1273e+01,  ...,  9.6941e-01,\n",
       "           2.2023e+01,  3.0000e+00],\n",
       "         [ 1.0000e+00,  1.0000e+00,  1.8855e+01,  ..., -5.9503e-01,\n",
       "           2.0037e+01,  2.0000e+00],\n",
       "         [ 1.0000e+00,  1.0000e+00,  1.2961e+01,  ...,  4.2384e-01,\n",
       "           1.2973e+01,  5.0000e+00],\n",
       "         ...,\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "        [[ 1.0000e+00,  1.0000e+00,  1.6827e+00,  ..., -9.9965e-01,\n",
       "           1.8183e+00,  3.0000e+00],\n",
       "         [ 1.0000e+00, -1.0000e+00,  1.0281e+01,  ..., -3.4482e-02,\n",
       "           1.0299e+01,  2.0000e+00],\n",
       "         [ 1.0000e+00, -1.0000e+00,  1.0511e+01,  ...,  9.0784e-01,\n",
       "           1.4937e+01,  4.0000e+00],\n",
       "         ...,\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "        [[ 1.0000e+00, -1.0000e+00,  6.7413e+00,  ...,  2.2737e-01,\n",
       "           8.1888e+00,  1.0000e+00],\n",
       "         [ 1.0000e+00, -1.0000e+00,  8.2358e+00,  ..., -9.8171e-01,\n",
       "           8.4732e+00,  3.0000e+00],\n",
       "         [ 1.0000e+00,  1.0000e+00,  4.7458e+00,  ..., -1.4743e-01,\n",
       "           4.7611e+00,  4.0000e+00],\n",
       "         ...,\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 5.0000e+00,  1.0000e+00,  4.0206e+01,  ...,  8.2111e-01,\n",
       "           6.3450e+01,  2.0000e+00],\n",
       "         [ 5.0000e+00, -1.0000e+00,  2.5845e+01,  ...,  5.2157e-01,\n",
       "           7.2160e+01,  4.0000e+00],\n",
       "         [ 1.0000e+00, -1.0000e+00,  1.9983e+01,  ..., -9.4931e-01,\n",
       "           2.0719e+01,  3.0000e+00],\n",
       "         ...,\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "        [[ 4.0000e+00, -1.0000e+00,  3.7227e+01,  ...,  9.1730e-01,\n",
       "           3.7384e+01,  3.0000e+00],\n",
       "         [ 1.0000e+00, -1.0000e+00,  5.4352e+00,  ...,  2.3121e-01,\n",
       "           2.3424e+01,  4.0000e+00],\n",
       "         [ 1.0000e+00,  1.0000e+00,  1.2910e+01,  ...,  9.3100e-01,\n",
       "           1.2942e+01,  2.0000e+00],\n",
       "         ...,\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "        [[ 1.0000e+00, -1.0000e+00,  2.3284e+01,  ..., -7.3236e-01,\n",
       "           2.3316e+01,  3.0000e+00],\n",
       "         [ 4.0000e+00,  1.0000e+00,  2.5830e+01,  ...,  9.3863e-01,\n",
       "           2.6304e+01,  4.0000e+00],\n",
       "         [ 1.0000e+00,  1.0000e+00,  1.6682e+01,  ..., -7.1535e-01,\n",
       "           1.6757e+01,  3.0000e+00],\n",
       "         ...,\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00]]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_targets_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947355b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6b1c8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ee1d71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae6e557",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571c124f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02082726",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5df5ae0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae490d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca4e67e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23256421",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "42649ec7",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88b1f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fp16 = model.to(torch.float16)\n",
    "\n",
    "model_fp16\n",
    "\n",
    "model_fp16 = model.to(torch.float16)\n",
    "model_quantized_fp16 = torch.quantization.quantize_dynamic(\n",
    "    model_fp16, {torch.nn.Linear}, dtype=torch.float16\n",
    ")\n",
    "\n",
    "\n",
    "model_quantized_fp16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf66a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_events_train = 1000\n",
    "events_per_batch = 10\n",
    "quantized_losses = []\n",
    "\n",
    "# Training loop\n",
    "inds_train = range(0, max_events_train, events_per_batch)\n",
    "for ind in inds_train:\n",
    "    optimizer.zero_grad()\n",
    "    ds_elems = [ds_train[i] for i in range(ind, ind + events_per_batch)]\n",
    "    X_features = [torch.tensor(elem[\"X\"]).to(torch.float32) for elem in ds_elems]\n",
    "    X_features_padded = pad_sequence(X_features, batch_first=True)\n",
    "    y_targets = [torch.tensor(elem[\"ygen\"]).to(torch.float32) for elem in ds_elems]\n",
    "    y_targets_padded = pad_sequence(y_targets, batch_first=True)\n",
    "    \n",
    "    mask = X_features_padded[:, :, 0] != 0\n",
    "\n",
    "    preds = model_int8(X_features_padded, mask)\n",
    "    preds_unpacked = unpack_predictions(preds)\n",
    "    targets_unpacked = unpack_target(y_targets_padded)\n",
    "\n",
    "    loss = mlpf_loss(targets_unpacked, preds_unpacked)\n",
    "    \n",
    "    # Ensure all tensors contributing to the loss have requires_grad = True\n",
    "    for key, value in loss.items():\n",
    "        if value.requires_grad is False:\n",
    "            value.requires_grad = True\n",
    "\n",
    "    # Convert the loss tensor to a scalar before calling backward\n",
    "    loss_total = loss[\"Total\"].sum()  \n",
    "    loss_total.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    current_loss = loss_total.detach().item()\n",
    "    losses.append(current_loss)\n",
    "    print(\"Loss={:.2f}\".format(current_loss))\n",
    "\n",
    "\n",
    "plt.plot(quantized_losses)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Quantized Training Loss Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44174bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 1\n",
    "for epoch in range(num_epochs):\n",
    "    losses_quantized = []\n",
    "\n",
    "    for ind in inds_train:\n",
    "        optimizer.zero_grad()\n",
    "        ds_elems = [ds_train[i] for i in range(ind, ind + events_per_batch)]\n",
    "        X_features = [torch.tensor(elem[\"X\"]).to(torch.float32) for elem in ds_elems]\n",
    "        X_features_padded = pad_sequence(X_features, batch_first=True)\n",
    "        y_targets = [torch.tensor(elem[\"ygen\"]).to(torch.float32) for elem in ds_elems]\n",
    "        y_targets_padded = pad_sequence(y_targets, batch_first=True)\n",
    "\n",
    "        mask = X_features_padded[:, :, 0] != 0\n",
    "\n",
    "        preds = model_int8(X_features_padded, mask)  # Use quantized model here\n",
    "        preds_unpacked = unpack_predictions(preds)\n",
    "        targets_unpacked = unpack_target(y_targets_padded)\n",
    "        loss = mlpf_loss(targets_unpacked, preds_unpacked)\n",
    "        \n",
    "        # Ensure all tensors contributing to the loss have requires_grad = True\n",
    "        for key, value in loss.items():\n",
    "            if value.requires_grad is False:\n",
    "                value.requires_grad = True\n",
    "        \n",
    "        loss[\"Total\"].backward()\n",
    "        optimizer.step()\n",
    "        current_loss = loss[\"Total\"].detach().item()\n",
    "        losses_quantized.append(current_loss)\n",
    "        print(\"Iteration: {}, Loss: {:.2f}\".format(ind, loss[\"Total\"].detach().item()))\n",
    "\n",
    "    # Plot training loss\n",
    "    plt.plot(losses_quantized)\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training Loss Curve (Quantized Model) - Epoch {}'.format(epoch + 1))\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8f9c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting both losses on the same plot\n",
    "plt.plot(losses, label='Original Model')\n",
    "plt.plot(quantized_losses, label='Quantized Model')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss Curve')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "595acac5",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/sraj/ipykernel_649402/1211407540.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_FEATURES_CL\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pT'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b0edf1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
