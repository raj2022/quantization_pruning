{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d554c673-86f3-4201-94fa-249fa9b1c8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39607f7d-cab2-469b-874e-c835e0c78865",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, Tensor\n",
    "import tensorflow_datasets as tfds\n",
    "import torch_geometric\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f57959f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of available GPUs: 1\n",
      "Current GPU: Tesla T4\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    gpu_count = torch.cuda.device_count()\n",
    "    print(f\"Number of available GPUs: {gpu_count}\")\n",
    "\n",
    "    # Get the name of the current GPU\n",
    "    current_gpu = torch.cuda.get_device_name(0)\n",
    "    print(f\"Current GPU: {current_gpu}\")\n",
    "else:\n",
    "    print(\"CUDA is not available. PyTorch is running on CPU.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb7fa6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2460cf92-75be-4622-bfb2-8392978e2ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../../mlpf/tensorflow_datasets/\"\n",
    "dataset = \"clic_edm_ttbar_pf\"\n",
    "\n",
    "#Load dataset\n",
    "builder = tfds.builder(dataset, data_dir=data_dir)\n",
    "ds_train = builder.as_data_source(split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86bd3286-c7a9-4bcb-a945-162cad36eec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_FEATURES_TRK = [\n",
    "    \"elemtype\",\n",
    "    \"pt\",\n",
    "    \"eta\",\n",
    "    \"sin_phi\",\n",
    "    \"cos_phi\",\n",
    "    \"p\",\n",
    "    \"chi2\",\n",
    "    \"ndf\",\n",
    "    \"dEdx\",\n",
    "    \"dEdxError\",\n",
    "    \"radiusOfInnermostHit\",\n",
    "    \"tanLambda\",\n",
    "    \"D0\",\n",
    "    \"omega\",\n",
    "    \"Z0\",\n",
    "    \"time\",\n",
    "]\n",
    "X_FEATURES_CL = [\n",
    "    \"elemtype\",\n",
    "    \"et\",\n",
    "    \"eta\",\n",
    "    \"sin_phi\",\n",
    "    \"cos_phi\",\n",
    "    \"energy\",\n",
    "    \"position.x\",\n",
    "    \"position.y\",\n",
    "    \"position.z\",\n",
    "    \"iTheta\",\n",
    "    \"energy_ecal\",\n",
    "    \"energy_hcal\",\n",
    "    \"energy_other\",\n",
    "    \"num_hits\",\n",
    "    \"sigma_x\",\n",
    "    \"sigma_y\",\n",
    "    \"sigma_z\",\n",
    "]\n",
    "Y_FEATURES = [\"cls_id\", \"charge\", \"pt\", \"eta\", \"sin_phi\", \"cos_phi\", \"energy\"]\n",
    "Y_CLASSES = [0, 211, 130, 22, 11, 13]\n",
    "\n",
    "INPUT_DIM = max(len(X_FEATURES_TRK), len(X_FEATURES_CL))\n",
    "NUM_CLASSES = len(Y_CLASSES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409952b1-db7a-47f6-b57c-8d0ce37e0872",
   "metadata": {},
   "source": [
    "## Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d581d65-1794-4ac5-b65f-96461a4b9c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as nnF\n",
    "\n",
    "from torch import Tensor\n",
    "from typing import Optional, Tuple\n",
    "\n",
    "class QuantizeableMultiheadAttention(nn.MultiheadAttention):\n",
    "    _FLOAT_MODULE = nn.MultiheadAttention\n",
    "\n",
    "    r\"\"\"Quantizable implementation of the MultiheadAttention.\n",
    "\n",
    "    Note::\n",
    "        Please, refer to :class:`~torch.nn.MultiheadAttention` for more\n",
    "        information\n",
    "\n",
    "    Allows the model to jointly attend to information from different\n",
    "    representation subspaces.\n",
    "    See reference: Attention Is All You Need\n",
    "\n",
    "    The original MHA module is not quantizable.\n",
    "    This reimplements it by explicitly instantiating the linear layers.\n",
    "\n",
    "    .. math::\n",
    "        \\text{MultiHead}(Q, K, V) = \\text{Concat}(head_1,\\dots,head_h)W^O\n",
    "        \\text{where} head_i = \\text{Attention}(QW_i^Q, KW_i^K, VW_i^V)\n",
    "\n",
    "    Args:\n",
    "        embed_dim: total dimension of the model.\n",
    "        num_heads: parallel attention heads.\n",
    "        dropout: a Dropout layer on attn_output_weights. Default: 0.0.\n",
    "        bias: add bias as module parameter. Default: True.\n",
    "        add_bias_kv: add bias to the key and value sequences at dim=0.\n",
    "        add_zero_attn: add a new batch of zeros to the key and\n",
    "                       value sequences at dim=1.\n",
    "        kdim: total number of features in key. Default: None.\n",
    "        vdim: total number of features in value. Default: None.\n",
    "        batch_first: If ``True``, then the input and output tensors are provided\n",
    "            as (batch, seq, feature). Default: ``False`` (seq, batch, feature).\n",
    "\n",
    "    Note that if :attr:`kdim` and :attr:`vdim` are None, they will be set\n",
    "    to :attr:`embed_dim` such that query, key, and value have the same\n",
    "    number of features.\n",
    "\n",
    "    Examples::\n",
    "\n",
    "        >>> import torch.ao.nn.quantizable as nnqa\n",
    "        >>> multihead_attn = nnqa.MultiheadAttention(embed_dim, num_heads)\n",
    "        >>> attn_output, attn_output_weights = multihead_attn(query, key, value)\n",
    "\n",
    "    Note::\n",
    "        Please, follow the quantization flow to convert the quantizable MHA.\n",
    "    \"\"\"\n",
    "    __constants__ = ['batch_first']\n",
    "\n",
    "    def __init__(self, embed_dim: int, num_heads: int,\n",
    "                 dropout: float = 0., bias: bool = True,\n",
    "                 add_bias_kv: bool = False, add_zero_attn: bool = False,\n",
    "                 kdim: Optional[int] = None, vdim: Optional[int] = None, batch_first: bool = False,\n",
    "                 device=None, dtype=None) -> None:\n",
    "        factory_kwargs = {'device': device, 'dtype': dtype}\n",
    "        super().__init__(embed_dim, num_heads, dropout,\n",
    "                         bias, add_bias_kv,\n",
    "                         add_zero_attn, kdim, vdim, batch_first,\n",
    "                         **factory_kwargs)\n",
    "        self.linear_Q = nn.Linear(self.embed_dim, self.embed_dim, bias=bias, **factory_kwargs)\n",
    "        self.linear_K = nn.Linear(self.kdim, self.embed_dim, bias=bias, **factory_kwargs)\n",
    "        self.linear_V = nn.Linear(self.vdim, self.embed_dim, bias=bias, **factory_kwargs)\n",
    "        # for the type: ignore, see https://github.com/pytorch/pytorch/issues/58969\n",
    "        self.out_proj = nn.Linear(self.embed_dim, self.embed_dim, bias=bias, **factory_kwargs)  # type: ignore[assignment]\n",
    "\n",
    "        # Functionals\n",
    "        # self.q_scaling_product = torch.ao.nn.quantized.FloatFunctional()\n",
    "        # note: importing torch.ao.nn.quantized at top creates a circular import\n",
    "\n",
    "        # Quant/Dequant\n",
    "        self.quant_attn_output = torch.ao.quantization.QuantStub()\n",
    "        self.quant_attn_output_weights = torch.ao.quantization.QuantStub()\n",
    "        self.dequant_q = torch.ao.quantization.DeQuantStub()\n",
    "        self.dequant_k = torch.ao.quantization.DeQuantStub()\n",
    "        self.dequant_v = torch.ao.quantization.DeQuantStub()\n",
    "\n",
    "    def _get_name(self):\n",
    "        return 'QuantizableMultiheadAttention'\n",
    "\n",
    "    @classmethod\n",
    "    def from_float(cls, other):\n",
    "        assert type(other) == cls._FLOAT_MODULE\n",
    "        assert hasattr(other, 'qconfig'), \"The float module must have 'qconfig'\"\n",
    "        # Setting the dropout to 0.0!\n",
    "        observed = cls(other.embed_dim, other.num_heads, other.dropout,\n",
    "                       (other.in_proj_bias is not None),\n",
    "                       (other.bias_k is not None),\n",
    "                       other.add_zero_attn, other.kdim, other.vdim,\n",
    "                       other.batch_first)\n",
    "        observed.bias_k = other.bias_k\n",
    "        observed.bias_v = other.bias_v\n",
    "        observed.qconfig = other.qconfig\n",
    "\n",
    "        # Set the linear weights\n",
    "        # for the type: ignores, see https://github.com/pytorch/pytorch/issues/58969\n",
    "        observed.out_proj.weight = other.out_proj.weight  # type: ignore[has-type]\n",
    "        observed.out_proj.bias = other.out_proj.bias  # type: ignore[has-type]\n",
    "        if other._qkv_same_embed_dim:\n",
    "            # Use separate params\n",
    "            bias = other.in_proj_bias\n",
    "            _start = 0\n",
    "            _end = _start + other.embed_dim\n",
    "            weight = other.in_proj_weight[_start:_end, :]\n",
    "            if bias is not None:\n",
    "                bias = torch.nn.Parameter(bias[_start:_end], bias.requires_grad)\n",
    "            observed.linear_Q.weight = torch.nn.Parameter(weight,\n",
    "                                                          weight.requires_grad)\n",
    "            observed.linear_Q.bias = bias\n",
    "\n",
    "            bias = other.in_proj_bias\n",
    "            _start = _end\n",
    "            _end = _start + other.embed_dim\n",
    "            weight = other.in_proj_weight[_start:_end, :]\n",
    "            if bias is not None:\n",
    "                bias = torch.nn.Parameter(bias[_start:_end], bias.requires_grad)\n",
    "            observed.linear_K.weight = torch.nn.Parameter(weight,\n",
    "                                                          weight.requires_grad)\n",
    "            observed.linear_K.bias = bias\n",
    "\n",
    "            bias = other.in_proj_bias\n",
    "            _start = _end\n",
    "            weight = other.in_proj_weight[_start:, :]\n",
    "            if bias is not None:\n",
    "                bias = torch.nn.Parameter(bias[_start:], bias.requires_grad)\n",
    "            observed.linear_V.weight = torch.nn.Parameter(weight,\n",
    "                                                          weight.requires_grad)\n",
    "            observed.linear_V.bias = bias\n",
    "        else:\n",
    "            observed.linear_Q.weight = nn.Parameter(other.q_proj_weight)\n",
    "            observed.linear_K.weight = nn.Parameter(other.k_proj_weight)\n",
    "            observed.linear_V.weight = nn.Parameter(other.v_proj_weight)\n",
    "            if other.in_proj_bias is None:\n",
    "                observed.linear_Q.bias = None  # type: ignore[assignment]\n",
    "                observed.linear_K.bias = None  # type: ignore[assignment]\n",
    "                observed.linear_V.bias = None  # type: ignore[assignment]\n",
    "            else:\n",
    "                observed.linear_Q.bias = nn.Parameter(other.in_proj_bias[0:other.embed_dim])\n",
    "                observed.linear_K.bias = nn.Parameter(other.in_proj_bias[other.embed_dim:(other.embed_dim * 2)])\n",
    "                observed.linear_V.bias = nn.Parameter(other.in_proj_bias[(other.embed_dim * 2):])\n",
    "        observed.eval()\n",
    "        # Explicit prepare\n",
    "        observed = torch.ao.quantization.prepare(observed, inplace=True)\n",
    "        return observed\n",
    "\n",
    "    @torch.jit.unused\n",
    "    def dequantize(self):\n",
    "        r\"\"\"Utility to convert the quantized MHA back to float.\n",
    "\n",
    "        The motivation for this is that it is not trivial to conver the weights\n",
    "        from the format that is used in the quantized version back to the\n",
    "        float.\n",
    "        \"\"\"\n",
    "        fp = self._FLOAT_MODULE(self.embed_dim, self.num_heads, self.dropout,\n",
    "                                (self.linear_Q._weight_bias()[1] is not None),\n",
    "                                (self.bias_k is not None),\n",
    "                                self.add_zero_attn, self.kdim, self.vdim, self.batch_first)\n",
    "        assert fp._qkv_same_embed_dim == self._qkv_same_embed_dim\n",
    "        if self.bias_k is not None:\n",
    "            fp.bias_k = nn.Parameter(self.bias_k.dequantize())\n",
    "        if self.bias_v is not None:\n",
    "            fp.bias_v = nn.Parameter(self.bias_v.dequantize())\n",
    "\n",
    "        # Set the linear weights\n",
    "        # Note: Because the linear layers are quantized, mypy does not nkow how\n",
    "        # to deal with them -- might need to ignore the typing checks.\n",
    "        # for the type: ignore[has-type], see https://github.com/pytorch/pytorch/issues/58969\n",
    "        w, b = self.out_proj._weight_bias()  # type: ignore[operator, has-type]\n",
    "        fp.out_proj.weight = nn.Parameter(w.dequantize())\n",
    "        if b is not None:\n",
    "            fp.out_proj.bias = nn.Parameter(b)\n",
    "\n",
    "        wQ, bQ = self.linear_Q._weight_bias()  # type: ignore[operator]\n",
    "        wQ = wQ.dequantize()\n",
    "        wK, bK = self.linear_K._weight_bias()  # type: ignore[operator]\n",
    "        wK = wK.dequantize()\n",
    "        wV, bV = self.linear_V._weight_bias()  # type: ignore[operator]\n",
    "        wV = wV.dequantize()\n",
    "        if fp._qkv_same_embed_dim:\n",
    "            # Use separate params\n",
    "            _start = 0\n",
    "            _end = _start + fp.embed_dim\n",
    "            fp.in_proj_weight[_start:_end, :] = wQ\n",
    "            if fp.in_proj_bias is not None:\n",
    "                assert all(bQ == 0)\n",
    "                fp.in_proj_bias[_start:_end] = bQ\n",
    "\n",
    "            _start = _end\n",
    "            _end = _start + fp.embed_dim\n",
    "            fp.in_proj_weight[_start:_end, :] = wK\n",
    "            if fp.in_proj_bias is not None:\n",
    "                assert all(bK == 0)\n",
    "                fp.in_proj_bias[_start:_end] = bK\n",
    "\n",
    "            _start = _end\n",
    "            fp.in_proj_weight[_start:, :] = wV\n",
    "            if fp.in_proj_bias is not None:\n",
    "                assert all(bV == 0)\n",
    "                fp.in_proj_bias[_start:] = bV\n",
    "        else:\n",
    "            fp.q_proj_weight = nn.Parameter(wQ)\n",
    "            fp.k_proj_weight = nn.Parameter(wK)\n",
    "            fp.v_proj_weight = nn.Parameter(wV)\n",
    "            if fp.in_proj_bias is None:\n",
    "                self.linear_Q.bias = None\n",
    "                self.linear_K.bias = None\n",
    "                self.linear_V.bias = None\n",
    "            else:\n",
    "                fp.in_proj_bias[0:fp.embed_dim] = bQ\n",
    "                fp.in_proj_bias[fp.embed_dim:(fp.embed_dim * 2)] = bK\n",
    "                fp.in_proj_bias[(fp.embed_dim * 2):] = bV\n",
    "\n",
    "        return fp\n",
    "\n",
    "\n",
    "    @classmethod\n",
    "    def from_observed(cls, other):\n",
    "        # The whole flow is float -> observed -> quantized\n",
    "        # This class does float -> observed only\n",
    "        # See nn.quantized.MultiheadAttention\n",
    "        raise NotImplementedError(\"It looks like you are trying to prepare an \"\n",
    "                                  \"MHA module. Please, see \"\n",
    "                                  \"the examples on quantizable MHAs.\")\n",
    "\n",
    "    def forward(self,\n",
    "                query: Tensor,\n",
    "                key: Tensor,\n",
    "                value: Tensor,\n",
    "                key_padding_mask: Optional[Tensor] = None,\n",
    "                need_weights: bool = True,\n",
    "                attn_mask: Optional[Tensor] = None,\n",
    "                average_attn_weights: bool = True,\n",
    "                is_causal: bool = False) -> Tuple[Tensor, Optional[Tensor]]:\n",
    "        r\"\"\"\n",
    "    Note::\n",
    "        Please, refer to :func:`~torch.nn.MultiheadAttention.forward` for more\n",
    "        information\n",
    "\n",
    "    Args:\n",
    "        query, key, value: map a query and a set of key-value pairs to an output.\n",
    "            See \"Attention Is All You Need\" for more details.\n",
    "        key_padding_mask: if provided, specified padding elements in the key will\n",
    "            be ignored by the attention. When given a binary mask and a value is True,\n",
    "            the corresponding value on the attention layer will be ignored.\n",
    "        need_weights: output attn_output_weights.\n",
    "        attn_mask: 2D or 3D mask that prevents attention to certain positions. A 2D mask will be broadcasted for all\n",
    "            the batches while a 3D mask allows to specify a different mask for the entries of each batch.\n",
    "\n",
    "    Shape:\n",
    "        - Inputs:\n",
    "        - query: :math:`(L, N, E)` where L is the target sequence length, N is the batch size, E is\n",
    "          the embedding dimension. :math:`(N, L, E)` if ``batch_first`` is ``True``.\n",
    "        - key: :math:`(S, N, E)`, where S is the source sequence length, N is the batch size, E is\n",
    "          the embedding dimension. :math:`(N, S, E)` if ``batch_first`` is ``True``.\n",
    "        - value: :math:`(S, N, E)` where S is the source sequence length, N is the batch size, E is\n",
    "          the embedding dimension. :math:`(N, S, E)` if ``batch_first`` is ``True``.\n",
    "        - key_padding_mask: :math:`(N, S)` where N is the batch size, S is the source sequence length.\n",
    "          If a BoolTensor is provided, the positions with the\n",
    "          value of ``True`` will be ignored while the position with the value of ``False`` will be unchanged.\n",
    "        - attn_mask: 2D mask :math:`(L, S)` where L is the target sequence length, S is the source sequence length.\n",
    "          3D mask :math:`(N*num_heads, L, S)` where N is the batch size, L is the target sequence length,\n",
    "          S is the source sequence length. attn_mask ensure that position i is allowed to attend the unmasked\n",
    "          positions. If a BoolTensor is provided, positions with ``True``\n",
    "          is not allowed to attend while ``False`` values will be unchanged. If a FloatTensor\n",
    "          is provided, it will be added to the attention weight.\n",
    "        - is_causal: If specified, applies a causal mask as attention mask. Mutually exclusive with providing attn_mask.\n",
    "          Default: ``False``.\n",
    "        - average_attn_weights: If true, indicates that the returned ``attn_weights`` should be averaged across\n",
    "          heads. Otherwise, ``attn_weights`` are provided separately per head. Note that this flag only has an\n",
    "          effect when ``need_weights=True.``. Default: True (i.e. average weights across heads)\n",
    "\n",
    "        - Outputs:\n",
    "        - attn_output: :math:`(L, N, E)` where L is the target sequence length, N is the batch size,\n",
    "          E is the embedding dimension. :math:`(N, L, E)` if ``batch_first`` is ``True``.\n",
    "        - attn_output_weights: If ``average_attn_weights=True``, returns attention weights averaged\n",
    "          across heads of shape :math:`(N, L, S)`, where N is the batch size, L is the target sequence length,\n",
    "          S is the source sequence length. If ``average_attn_weights=False``, returns attention weights per\n",
    "          head of shape :math:`(N, num_heads, L, S)`.\n",
    "        \"\"\"\n",
    "        return self._forward_impl(query, key, value, key_padding_mask,\n",
    "                                  need_weights, attn_mask, average_attn_weights,\n",
    "                                  is_causal)\n",
    "\n",
    "    def _forward_impl(self,\n",
    "                      query: Tensor,\n",
    "                      key: Tensor,\n",
    "                      value: Tensor,\n",
    "                      key_padding_mask: Optional[Tensor] = None,\n",
    "                      need_weights: bool = True,\n",
    "                      attn_mask: Optional[Tensor] = None,\n",
    "                      average_attn_weights: bool = True,\n",
    "                      is_causal: bool = False) -> Tuple[Tensor, Optional[Tensor]]:\n",
    "        # This version will not deal with the static key/value pairs.\n",
    "        # Keeping it here for future changes.\n",
    "        #\n",
    "        # TODO: This method has some duplicate lines with the\n",
    "        # `torch.nn.functional.multi_head_attention`. Will need to refactor.\n",
    "        static_k = None\n",
    "        static_v = None\n",
    "\n",
    "        if attn_mask is not None and is_causal:\n",
    "            raise AssertionError(\"Only allow causal mask or attn_mask\")\n",
    "\n",
    "        if is_causal:\n",
    "            raise AssertionError(\"causal mask not supported by AO MHA module\")\n",
    "\n",
    "        if self.batch_first:\n",
    "            query, key, value = (x.transpose(0, 1) for x in (query, key, value))\n",
    "\n",
    "        tgt_len, bsz, embed_dim_to_check = query.size()\n",
    "        assert self.embed_dim == embed_dim_to_check\n",
    "        # allow MHA to have different sizes for the feature dimension\n",
    "        assert key.size(0) == value.size(0) and key.size(1) == value.size(1)\n",
    "\n",
    "        head_dim = self.embed_dim // self.num_heads\n",
    "        assert head_dim * self.num_heads == self.embed_dim, \"embed_dim must be divisible by num_heads\"\n",
    "        scaling = float(head_dim) ** -0.5\n",
    "\n",
    "        q = self.linear_Q(query)\n",
    "        k = self.linear_K(key)\n",
    "        v = self.linear_V(value)\n",
    "\n",
    "        #JP fix here: disabled this\n",
    "        # q = self.q_scaling_product.mul_scalar(q, scaling)\n",
    "\n",
    "        if attn_mask is not None:\n",
    "            if attn_mask.dtype == torch.uint8:\n",
    "                warnings.warn(\"Byte tensor for attn_mask in nn.MultiheadAttention is deprecated. Use bool tensor instead.\")\n",
    "                attn_mask = attn_mask.to(torch.bool)\n",
    "            assert attn_mask.is_floating_point() or attn_mask.dtype == torch.bool, \\\n",
    "                f'Only float and bool types are supported for attn_mask, not {attn_mask.dtype}'\n",
    "\n",
    "            if attn_mask.dim() == 2:\n",
    "                attn_mask = attn_mask.unsqueeze(0)\n",
    "                if list(attn_mask.size()) != [1, query.size(0), key.size(0)]:\n",
    "                    raise RuntimeError('The size of the 2D attn_mask is not correct.')\n",
    "            elif attn_mask.dim() == 3:\n",
    "                if list(attn_mask.size()) != [bsz * self.num_heads, query.size(0), key.size(0)]:\n",
    "                    raise RuntimeError('The size of the 3D attn_mask is not correct.')\n",
    "            else:\n",
    "                raise RuntimeError(f\"attn_mask's dimension {attn_mask.dim()} is not supported\")\n",
    "            # attn_mask's dim is 3 now.\n",
    "\n",
    "        # convert ByteTensor key_padding_mask to bool\n",
    "        if key_padding_mask is not None and key_padding_mask.dtype == torch.uint8:\n",
    "            warnings.warn(\"Byte tensor for key_padding_mask in nn.MultiheadAttention is deprecated. Use bool tensor instead.\")\n",
    "            key_padding_mask = key_padding_mask.to(torch.bool)\n",
    "        if self.bias_k is not None and self.bias_v is not None:\n",
    "            if static_k is None and static_v is None:\n",
    "\n",
    "                # Explicitly assert that bias_k and bias_v are not None\n",
    "                # in a way that TorchScript can understand.\n",
    "                bias_k = self.bias_k\n",
    "                assert bias_k is not None\n",
    "                bias_v = self.bias_v\n",
    "                assert bias_v is not None\n",
    "\n",
    "                k = torch.cat([k, bias_k.repeat(1, bsz, 1)])\n",
    "                v = torch.cat([v, bias_v.repeat(1, bsz, 1)])\n",
    "                if attn_mask is not None:\n",
    "                    attn_mask = nnF.pad(attn_mask, (0, 1))\n",
    "                if key_padding_mask is not None:\n",
    "                    key_padding_mask = nnF.pad(key_padding_mask, (0, 1))\n",
    "            else:\n",
    "                assert static_k is None, \"bias cannot be added to static key.\"\n",
    "                assert static_v is None, \"bias cannot be added to static value.\"\n",
    "        else:\n",
    "            assert self.bias_k is None\n",
    "            assert self.bias_v is None\n",
    "\n",
    "        q = q.contiguous().view(tgt_len, bsz * self.num_heads, head_dim).transpose(0, 1)\n",
    "        if k is not None:\n",
    "            k = k.contiguous().view(-1, bsz * self.num_heads, head_dim).transpose(0, 1)\n",
    "        if v is not None:\n",
    "            v = v.contiguous().view(-1, bsz * self.num_heads, head_dim).transpose(0, 1)\n",
    "\n",
    "        if static_k is not None:\n",
    "            assert static_k.size(0) == bsz * self.num_heads\n",
    "            assert static_k.size(2) == head_dim\n",
    "            k = static_k\n",
    "\n",
    "        if static_v is not None:\n",
    "            assert static_v.size(0) == bsz * self.num_heads\n",
    "            assert static_v.size(2) == head_dim\n",
    "            v = static_v\n",
    "\n",
    "        src_len = k.size(1)\n",
    "\n",
    "        if key_padding_mask is not None:\n",
    "            assert key_padding_mask.size(0) == bsz\n",
    "            assert key_padding_mask.size(1) == src_len\n",
    "\n",
    "        if self.add_zero_attn:\n",
    "            src_len += 1\n",
    "            k_zeros = torch.zeros((k.size(0), 1) + k.size()[2:])\n",
    "            if k.is_quantized:\n",
    "                k_zeros = torch.quantize_per_tensor(k_zeros, k.q_scale(), k.q_zero_point(), k.dtype)\n",
    "            k = torch.cat([k, k_zeros], dim=1)\n",
    "            v_zeros = torch.zeros((v.size(0), 1) + k.size()[2:])\n",
    "            if v.is_quantized:\n",
    "                v_zeros = torch.quantize_per_tensor(v_zeros, v.q_scale(), v.q_zero_point(), v.dtype)\n",
    "            v = torch.cat([v, v_zeros], dim=1)\n",
    "\n",
    "            if attn_mask is not None:\n",
    "                attn_mask = nnF.pad(attn_mask, (0, 1))\n",
    "            if key_padding_mask is not None:\n",
    "                key_padding_mask = nnF.pad(key_padding_mask, (0, 1))\n",
    "\n",
    "        # Leaving the quantized zone here\n",
    "        q = self.dequant_q(q)\n",
    "        k = self.dequant_k(k)\n",
    "        v = self.dequant_v(v)\n",
    "        attn_output_weights = torch.bmm(q, k.transpose(1, 2))\n",
    "        assert list(attn_output_weights.size()) == [bsz * self.num_heads, tgt_len, src_len]\n",
    "\n",
    "        if attn_mask is not None:\n",
    "            if attn_mask.dtype == torch.bool:\n",
    "                attn_output_weights.masked_fill_(attn_mask, float('-inf'))\n",
    "            else:\n",
    "                attn_output_weights += attn_mask\n",
    "\n",
    "        if key_padding_mask is not None:\n",
    "            attn_output_weights = attn_output_weights.view(bsz, self.num_heads, tgt_len, src_len)\n",
    "            attn_output_weights = attn_output_weights.masked_fill(\n",
    "                key_padding_mask.unsqueeze(1).unsqueeze(2),\n",
    "                float('-inf'),\n",
    "            )\n",
    "            attn_output_weights = attn_output_weights.view(bsz * self.num_heads, tgt_len, src_len)\n",
    "\n",
    "        attn_output_weights = nnF.softmax(\n",
    "            attn_output_weights, dim=-1)\n",
    "        attn_output_weights = nnF.dropout(attn_output_weights, p=self.dropout, training=self.training)\n",
    "\n",
    "        attn_output = torch.bmm(attn_output_weights, v)\n",
    "        assert list(attn_output.size()) == [bsz * self.num_heads, tgt_len, head_dim]\n",
    "        if self.batch_first:\n",
    "            attn_output = attn_output.view(bsz, tgt_len, self.embed_dim)\n",
    "        else:\n",
    "            attn_output = attn_output.transpose(0, 1).contiguous().view(tgt_len, bsz, self.embed_dim)\n",
    "\n",
    "        # Reentering the quantized zone\n",
    "        attn_output = self.quant_attn_output(attn_output)\n",
    "        # for the type: ignore[has-type], see https://github.com/pytorch/pytorch/issues/58969\n",
    "        attn_output = self.out_proj(attn_output)  # type: ignore[has-type]\n",
    "\n",
    "        #JP fix: removed need_weights part from here, return attn_output instead of tuple\n",
    "        return attn_output\n",
    "\n",
    "class QuantizedMultiheadAttention(QuantizeableMultiheadAttention):\n",
    "    _FLOAT_MODULE = torch.ao.nn.quantizable.MultiheadAttention\n",
    "\n",
    "    def _get_name(self):\n",
    "        return \"QuantizedMultiheadAttention\"\n",
    "\n",
    "    @classmethod\n",
    "    def from_float(cls, other):\n",
    "        # The whole flow is float -> observed -> quantized\n",
    "        # This class does observed -> quantized only\n",
    "        raise NotImplementedError(\"It looks like you are trying to convert a \"\n",
    "                                  \"non-observed MHA module. Please, see \"\n",
    "                                  \"the examples on quantizable MHAs.\")\n",
    "\n",
    "    @classmethod\n",
    "    def from_observed(cls, other):\n",
    "        converted = torch.ao.quantization.convert(other, mapping=None,\n",
    "                                                  inplace=False,\n",
    "                                                  remove_qconfig=True,\n",
    "                                                  convert_custom_config_dict=None)\n",
    "        converted.__class__ = cls\n",
    "        # Remove the parameters for the bias_k and bias_v to quantize them\n",
    "        # TODO: This is a potential source of accuracy drop.\n",
    "        #       quantized cat takes the scale and zp of the first\n",
    "        #       element, which might lose the precision in the bias_k\n",
    "        #       and the bias_v (which are cat'ed with k/v being first).\n",
    "        if converted.bias_k is not None:\n",
    "            bias_k = converted._parameters.pop('bias_k')\n",
    "            sc, zp = torch._choose_qparams_per_tensor(bias_k,\n",
    "                                                      reduce_range=False)\n",
    "            bias_k = torch.quantize_per_tensor(bias_k, sc, zp, torch.quint8)\n",
    "            setattr(converted, 'bias_k', bias_k)  # noqa: B010\n",
    "\n",
    "        if converted.bias_v is not None:\n",
    "            bias_v = converted._parameters.pop('bias_v')\n",
    "            sc, zp = torch._choose_qparams_per_tensor(bias_k,  # type: ignore[possibly-undefined]\n",
    "                                                      reduce_range=False)\n",
    "            bias_v = torch.quantize_per_tensor(bias_v, sc, zp, torch.quint8)\n",
    "            setattr(converted, 'bias_v', bias_v)  # noqa: B010\n",
    "\n",
    "        del converted.in_proj_weight\n",
    "        del converted.in_proj_bias\n",
    "\n",
    "        return converted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e697d50c-8b91-42b5-ade2-9e9e23041001",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    \"\"\"Focal Loss, as described in https://arxiv.org/abs/1708.02002.\n",
    "    It is essentially an enhancement to cross entropy loss and is\n",
    "    useful for classification tasks when there is a large class imbalance.\n",
    "    x is expected to contain raw, unnormalized scores for each class.\n",
    "    y is expected to contain class labels.\n",
    "    Shape:\n",
    "        - x: (batch_size, C) or (batch_size, C, d1, d2, ..., dK), K > 0.\n",
    "        - y: (batch_size,) or (batch_size, d1, d2, ..., dK), K > 0.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, alpha = None, gamma = 0.0, reduction = \"mean\", ignore_index = -100\n",
    "    ):\n",
    "        \"\"\"Constructor.\n",
    "        Args:\n",
    "            alpha (Tensor, optional): Weights for each class. Defaults to None.\n",
    "            gamma (float, optional): A constant, as described in the paper.\n",
    "                Defaults to 0.\n",
    "            reduction (str, optional): 'mean', 'sum' or 'none'.\n",
    "                Defaults to 'mean'.\n",
    "            ignore_index (int, optional): class label to ignore.\n",
    "                Defaults to -100.\n",
    "        \"\"\"\n",
    "        if reduction not in (\"mean\", \"sum\", \"none\"):\n",
    "            raise ValueError('Reduction must be one of: \"mean\", \"sum\", \"none\".')\n",
    "\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "        self.nll_loss = nn.NLLLoss(weight=alpha, reduction=\"none\")\n",
    "\n",
    "    def __repr__(self):\n",
    "        arg_keys = [\"alpha\", \"gamma\", \"reduction\"]\n",
    "        arg_vals = [self.__dict__[k] for k in arg_keys]\n",
    "        arg_strs = [f\"{k}={v!r}\" for k, v in zip(arg_keys, arg_vals)]\n",
    "        arg_str = \", \".join(arg_strs)\n",
    "        return f\"{type(self).__name__}({arg_str})\"\n",
    "\n",
    "    def forward(self, x: Tensor, y: Tensor) -> Tensor:\n",
    "        if x.ndim > 2:\n",
    "            # (N, C, d1, d2, ..., dK) --> (N * d1 * ... * dK, C)\n",
    "            c = x.shape[1]\n",
    "            x = x.permute(0, *range(2, x.ndim), 1).reshape(-1, c)\n",
    "            # (N, d1, d2, ..., dK) --> (N * d1 * ... * dK,)\n",
    "            y = y.view(-1)\n",
    "\n",
    "        # compute weighted cross entropy term: -alpha * log(pt)\n",
    "        # (alpha is already part of self.nll_loss)\n",
    "        log_p = F.log_softmax(x, dim=-1)\n",
    "        ce = self.nll_loss(log_p, y)\n",
    "\n",
    "        # get true class column from each row\n",
    "        # this is slow due to indexing\n",
    "        # all_rows = torch.arange(len(x))\n",
    "        # log_pt = log_p[all_rows, y]\n",
    "        log_pt = torch.gather(log_p, 1, y.unsqueeze(axis=-1)).squeeze(axis=-1)\n",
    "\n",
    "        # compute focal term: (1 - pt)^gamma\n",
    "        pt = log_pt.exp()\n",
    "        focal_term = (1 - pt) ** self.gamma\n",
    "\n",
    "        # the full loss: -alpha * ((1 - pt)^gamma) * log(pt)\n",
    "        loss = focal_term * ce\n",
    "\n",
    "        if self.reduction == \"mean\":\n",
    "            loss = loss.mean()\n",
    "        elif self.reduction == \"sum\":\n",
    "            loss = loss.sum()\n",
    "\n",
    "        return loss\n",
    "\n",
    "class QuantizeFeaturesStub(torch.ao.quantization.QuantStub):\n",
    "    def __init__(self, num_feats):\n",
    "        super().__init__()\n",
    "        self.num_feats = num_feats\n",
    "        self.quants = torch.nn.ModuleList()\n",
    "        for ifeat in range(self.num_feats):\n",
    "            self.quants.append(torch.ao.quantization.QuantStub())\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.cat([self.quants[ifeat](x[..., ifeat:ifeat+1]) for ifeat in range(self.num_feats)], axis=-1)\n",
    "        \n",
    "def mlpf_loss(y, ypred, mask):\n",
    "    loss = {}\n",
    "    loss_obj_id = FocalLoss(gamma=2.0, reduction=\"none\")\n",
    "\n",
    "    msk_true_particle = torch.unsqueeze((y[\"cls_id\"] != 0).to(dtype=torch.float32), axis=-1)\n",
    "    nelem = torch.sum(mask)\n",
    "    npart = torch.sum(y[\"cls_id\"] != 0)\n",
    "    \n",
    "    ypred[\"momentum\"] = ypred[\"momentum\"] * msk_true_particle\n",
    "    y[\"momentum\"] = y[\"momentum\"] * msk_true_particle\n",
    "\n",
    "    ypred[\"cls_id_onehot\"] = ypred[\"cls_id_onehot\"].permute((0, 2, 1))\n",
    "\n",
    "    loss_classification = loss_obj_id(ypred[\"cls_id_onehot\"], y[\"cls_id\"]).reshape(y[\"cls_id\"].shape)\n",
    "    loss_regression = torch.nn.functional.huber_loss(ypred[\"momentum\"], y[\"momentum\"], reduction=\"none\")\n",
    "    \n",
    "    # average over all elements that were not padded\n",
    "    loss[\"Classification\"] = loss_classification.sum() / npart\n",
    "    \n",
    "    mom_normalizer = y[\"momentum\"][y[\"cls_id\"] != 0].std(axis=0)\n",
    "    reg_losses = loss_regression[y[\"cls_id\"] != 0]\n",
    "    # average over all true particles\n",
    "    loss[\"Regression\"] = (reg_losses / mom_normalizer).sum() / npart\n",
    "\n",
    "    px = ypred[\"momentum\"][..., 0:1] * ypred[\"momentum\"][..., 3:4] * msk_true_particle\n",
    "    py = ypred[\"momentum\"][..., 0:1] * ypred[\"momentum\"][..., 2:3] * msk_true_particle\n",
    "    pred_met = torch.sqrt(torch.sum(px, axis=-2) ** 2 + torch.sum(py, axis=-2) ** 2)\n",
    "\n",
    "    px = y[\"momentum\"][..., 0:1] * y[\"momentum\"][..., 3:4] * msk_true_particle\n",
    "    py = y[\"momentum\"][..., 0:1] * y[\"momentum\"][..., 2:3] * msk_true_particle\n",
    "    true_met = torch.sqrt(torch.sum(px, axis=-2) ** 2 + torch.sum(py, axis=-2) ** 2)\n",
    "    loss[\"MET\"] = torch.nn.functional.huber_loss(pred_met, true_met).mean()\n",
    "\n",
    "    loss[\"Total\"] = loss[\"Classification\"] + loss[\"Regression\"]\n",
    "    # loss[\"Total\"] += 0.1*loss[\"MET\"]\n",
    "    return loss\n",
    "    \n",
    "class SelfAttentionLayer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        embedding_dim=128,\n",
    "        num_heads=2,\n",
    "        width=128,\n",
    "        dropout_mha=0.1,\n",
    "        dropout_ff=0.1,\n",
    "        attention_type=\"efficient\",\n",
    "    ):\n",
    "        super(SelfAttentionLayer, self).__init__()\n",
    "\n",
    "        self.attention_type = attention_type\n",
    "        self.act = nn.ReLU\n",
    "        self.mha = torch.nn.MultiheadAttention(embedding_dim, num_heads, dropout=dropout_mha, batch_first=True)\n",
    "        self.norm0 = torch.nn.LayerNorm(embedding_dim)\n",
    "        self.norm1 = torch.nn.LayerNorm(embedding_dim)\n",
    "        self.seq = torch.nn.Sequential(\n",
    "            nn.Linear(embedding_dim, width), self.act(), nn.Linear(width, embedding_dim), self.act()\n",
    "        )\n",
    "        self.dropout = torch.nn.Dropout(dropout_ff)\n",
    "\n",
    "        self.add0 = torch.ao.nn.quantized.FloatFunctional()\n",
    "        self.add1 = torch.ao.nn.quantized.FloatFunctional()\n",
    "        self.mul = torch.ao.nn.quantized.FloatFunctional()\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        mha_out = self.mha(x, x, x, need_weights=False)[0]\n",
    "        x = self.add0.add(x, mha_out)\n",
    "        x = self.norm0(x)\n",
    "        x = self.add1.add(x, self.seq(x))\n",
    "        x = self.norm1(x)\n",
    "        x = self.dropout(x)\n",
    "        # x = self.mul.mul(x, mask.unsqueeze(-1))\n",
    "        return x\n",
    "\n",
    "class RegressionOutput(nn.Module):\n",
    "    def __init__(self, embed_dim, width, act, dropout):\n",
    "        super(RegressionOutput, self).__init__()\n",
    "        self.dequant = torch.ao.quantization.DeQuantStub()\n",
    "        self.nn = ffn(embed_dim, 1, width, act, dropout)\n",
    "\n",
    "    def forward(self, elems, x, orig_value):\n",
    "        nn_out = self.nn(x)\n",
    "        nn_out = self.dequant(nn_out)\n",
    "        return orig_value + nn_out\n",
    "\n",
    "def ffn(input_dim, output_dim, width, act, dropout):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(input_dim, width),\n",
    "        act(),\n",
    "        torch.nn.LayerNorm(width),\n",
    "        nn.Dropout(dropout),\n",
    "        nn.Linear(width, output_dim),\n",
    "    )\n",
    "\n",
    "def transform_batch(Xbatch):\n",
    "    Xbatch = Xbatch.clone()\n",
    "    Xbatch[..., 1] = torch.log(Xbatch[..., 1])\n",
    "    Xbatch[..., 5] = torch.log(Xbatch[..., 5])\n",
    "    Xbatch[torch.isnan(Xbatch)] = 0.0\n",
    "    Xbatch[torch.isinf(Xbatch)] = 0.0\n",
    "    return Xbatch\n",
    "    \n",
    "def unpack_target(y):\n",
    "    ret = {}\n",
    "    ret[\"cls_id\"] = y[..., 0].long()\n",
    "\n",
    "    for i, feat in enumerate(Y_FEATURES):\n",
    "        if i >= 2:  # skip the cls and charge as they are defined above\n",
    "            ret[feat] = y[..., i].to(dtype=torch.float32)\n",
    "    ret[\"phi\"] = torch.atan2(ret[\"sin_phi\"], ret[\"cos_phi\"])\n",
    "    \n",
    "    # note ~ momentum = [\"pt\", \"eta\", \"sin_phi\", \"cos_phi\", \"energy\"]\n",
    "    ret[\"momentum\"] = y[..., 2:7].to(dtype=torch.float32)\n",
    "    ret[\"p4\"] = torch.cat(\n",
    "        [ret[\"pt\"].unsqueeze(1), ret[\"eta\"].unsqueeze(1), ret[\"phi\"].unsqueeze(1), ret[\"energy\"].unsqueeze(1)], axis=1\n",
    "    )\n",
    "\n",
    "    return ret\n",
    "\n",
    "\n",
    "def unpack_predictions(preds):\n",
    "    ret = {}\n",
    "    ret[\"cls_id_onehot\"], ret[\"momentum\"] = preds\n",
    "\n",
    "    ret[\"pt\"] = ret[\"momentum\"][..., 0]\n",
    "    ret[\"eta\"] = ret[\"momentum\"][..., 1]\n",
    "    ret[\"sin_phi\"] = ret[\"momentum\"][..., 2]\n",
    "    ret[\"cos_phi\"] = ret[\"momentum\"][..., 3]\n",
    "    ret[\"energy\"] = ret[\"momentum\"][..., 4]\n",
    "\n",
    "    ret[\"cls_id\"] = torch.argmax(ret[\"cls_id_onehot\"], axis=-1)\n",
    "    ret[\"phi\"] = torch.atan2(ret[\"sin_phi\"], ret[\"cos_phi\"])\n",
    "    ret[\"p4\"] = torch.cat(\n",
    "        [\n",
    "            ret[\"pt\"].unsqueeze(axis=-1),\n",
    "            ret[\"eta\"].unsqueeze(axis=-1),\n",
    "            ret[\"phi\"].unsqueeze(axis=-1),\n",
    "            ret[\"energy\"].unsqueeze(axis=-1),\n",
    "        ],\n",
    "        axis=-1,\n",
    "    )\n",
    "\n",
    "    return ret\n",
    "\n",
    "class MLPF(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim=16,\n",
    "        num_classes=6,\n",
    "        num_convs=2,\n",
    "        dropout_ff=0.0,\n",
    "        dropout_conv_reg_mha=0.0,\n",
    "        dropout_conv_reg_ff=0.0,\n",
    "        dropout_conv_id_mha=0.0,\n",
    "        dropout_conv_id_ff=0.0,\n",
    "        num_heads=16,\n",
    "        head_dim=16,\n",
    "        elemtypes=[0,1,2],\n",
    "    ):\n",
    "        super(MLPF, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.act = nn.ReLU\n",
    "        self.elemtypes = elemtypes\n",
    "        self.num_elemtypes = len(self.elemtypes)\n",
    "\n",
    "        embedding_dim = num_heads * head_dim\n",
    "        width = num_heads * head_dim\n",
    "        \n",
    "        self.nn0_id = ffn(self.input_dim, embedding_dim, width, self.act, dropout_ff)\n",
    "        self.nn0_reg = ffn(self.input_dim, embedding_dim, width, self.act, dropout_ff)\n",
    "        \n",
    "        self.conv_id = nn.ModuleList()\n",
    "        self.conv_reg = nn.ModuleList()\n",
    "\n",
    "        for i in range(num_convs):\n",
    "            self.conv_id.append(\n",
    "                SelfAttentionLayer(\n",
    "                    embedding_dim=embedding_dim,\n",
    "                    num_heads=num_heads,\n",
    "                    width=width,\n",
    "                    dropout_mha=dropout_conv_id_mha,\n",
    "                    dropout_ff=dropout_conv_id_ff,\n",
    "                )\n",
    "            )\n",
    "            self.conv_reg.append(\n",
    "                SelfAttentionLayer(\n",
    "                    embedding_dim=embedding_dim,\n",
    "                    num_heads=num_heads,\n",
    "                    width=width,\n",
    "                    dropout_mha=dropout_conv_reg_mha,\n",
    "                    dropout_ff=dropout_conv_reg_ff,\n",
    "                )\n",
    "            )\n",
    "\n",
    "        decoding_dim = self.input_dim + embedding_dim\n",
    "\n",
    "        # DNN that acts on the node level to predict the PID\n",
    "        self.nn_id = ffn(decoding_dim, num_classes, width, self.act, dropout_ff)\n",
    "\n",
    "        # elementwise DNN for node momentum regression\n",
    "        embed_dim = decoding_dim + num_classes\n",
    "        self.nn_pt = RegressionOutput(embed_dim, width, self.act, dropout_ff)\n",
    "        self.nn_eta = RegressionOutput(embed_dim, width, self.act, dropout_ff)\n",
    "        self.nn_sin_phi = RegressionOutput(embed_dim, width, self.act, dropout_ff)\n",
    "        self.nn_cos_phi = RegressionOutput(embed_dim, width, self.act, dropout_ff)\n",
    "        self.nn_energy = RegressionOutput(embed_dim, width, self.act, dropout_ff)\n",
    "        \n",
    "        self.quant = QuantizeFeaturesStub(self.input_dim + len(self.elemtypes))\n",
    "        self.dequant_id = torch.ao.quantization.DeQuantStub()\n",
    "\n",
    "    def forward(self, X_features, mask):\n",
    "        Xfeat_transformed = transform_batch(X_features)\n",
    "        Xfeat_normed = self.quant(Xfeat_transformed)\n",
    "\n",
    "        embeddings_id, embeddings_reg = [], []\n",
    "        embedding_id = self.nn0_id(Xfeat_normed)\n",
    "        embedding_reg = self.nn0_reg(Xfeat_normed)\n",
    "        for num, conv in enumerate(self.conv_id):\n",
    "            conv_input = embedding_id if num == 0 else embeddings_id[-1]\n",
    "            out_padded = conv(conv_input, mask)\n",
    "            embeddings_id.append(out_padded)\n",
    "        for num, conv in enumerate(self.conv_reg):\n",
    "            conv_input = embedding_reg if num == 0 else embeddings_reg[-1]\n",
    "            out_padded = conv(conv_input, mask)\n",
    "            embeddings_reg.append(out_padded)\n",
    "\n",
    "        final_embedding_id = torch.cat([Xfeat_normed] + [embeddings_id[-1]], axis=-1)\n",
    "        preds_id = self.nn_id(final_embedding_id)\n",
    "\n",
    "        final_embedding_reg = torch.cat([Xfeat_normed] + [embeddings_reg[-1]] + [preds_id], axis=-1)\n",
    "        preds_pt = self.nn_pt(X_features, final_embedding_reg, X_features[..., 1:2])\n",
    "        preds_eta = self.nn_eta(X_features, final_embedding_reg, X_features[..., 2:3])\n",
    "        preds_sin_phi = self.nn_sin_phi(X_features, final_embedding_reg, X_features[..., 3:4])\n",
    "        preds_cos_phi = self.nn_cos_phi(X_features, final_embedding_reg, X_features[..., 4:5])\n",
    "        preds_energy = self.nn_energy(X_features, final_embedding_reg, X_features[..., 5:6])\n",
    "        preds_momentum = torch.cat([preds_pt, preds_eta, preds_sin_phi, preds_cos_phi, preds_energy], axis=-1)\n",
    "        \n",
    "        preds_id = self.dequant_id(preds_id)\n",
    "        return preds_id, preds_momentum\n",
    "\n",
    "model = MLPF(input_dim=INPUT_DIM, num_classes=NUM_CLASSES)\n",
    "optimizer = torch.optim.Adam(lr=1e-4, params=model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4721f1c7-b501-4757-982b-fa2194cf6176",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "28fc87e0-5b18-4c44-a67e-ce2792b567de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 10/10 [00:01<00:00,  6.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, loss=2.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 10/10 [00:00<00:00, 26.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, loss=1.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 10/10 [00:00<00:00, 25.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, loss=1.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 10/10 [00:00<00:00, 26.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, loss=1.46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 10/10 [00:00<00:00, 25.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, loss=1.33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 10/10 [00:00<00:00, 26.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, loss=1.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 10/10 [00:00<00:00, 26.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, loss=1.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 10/10 [00:00<00:00, 26.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, loss=1.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 10/10 [00:00<00:00, 26.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, loss=1.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 10/10 [00:00<00:00, 26.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, loss=0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "max_events_train = 100\n",
    "max_events_eval = 100\n",
    "events_per_batch = 10\n",
    "nepochs = 10\n",
    "\n",
    "model = MLPF(input_dim=INPUT_DIM, num_classes=NUM_CLASSES).to(device=device)\n",
    "optimizer = torch.optim.Adam(lr=1e-4, params=model.parameters())\n",
    "\n",
    "#Training loop\n",
    "loss_vals_epochs = []\n",
    "for epoch in range(nepochs):\n",
    "    loss_vals_steps = []\n",
    "    inds_train = range(0,max_events_train,events_per_batch)\n",
    "    for ind in tqdm.tqdm(inds_train):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        #load the data for one batch\n",
    "        ds_elems = [ds_train[i] for i in range(ind,ind+events_per_batch)]\n",
    "        X_features = [torch.tensor(elem[\"X\"]).to(torch.float32) for elem in ds_elems]\n",
    "        y_targets = [torch.tensor(elem[\"ygen\"]).to(torch.float32) for elem in ds_elems]\n",
    "\n",
    "        #batch the data into [batch_size, num_elems, num_features]\n",
    "        X_features_padded = pad_sequence(X_features, batch_first=True).to(device=device)\n",
    "        y_targets_padded = pad_sequence(y_targets, batch_first=True).to(device=device)\n",
    "        mask = X_features_padded[:, :, 0]!=0\n",
    "\n",
    "        #run the model\n",
    "        preds = model(X_features_padded, mask)\n",
    "        preds_unpacked = unpack_predictions(preds)\n",
    "        targets_unpacked = unpack_target(y_targets_padded)\n",
    "\n",
    "        #compute loss, update model weights\n",
    "        loss = mlpf_loss(targets_unpacked, preds_unpacked, mask)\n",
    "        loss[\"Total\"].backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        loss_vals_steps.append(loss[\"Total\"].detach().cpu().item())\n",
    "\n",
    "    loss_vals_epochs.append(np.mean(loss_vals_steps))\n",
    "    print(\"Epoch {}, loss={:.2f}\".format(epoch, loss_vals_epochs[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd8787e9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'losses' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/sraj/ipykernel_1419920/948663204.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Iteration'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Training Loss Curve'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'losses' is not defined"
     ]
    }
   ],
   "source": [
    "plt.plot(losses)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b437405-87f1-409e-9ab9-ff79af3e1cd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f565365e2e0>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_vals_epochs, label=\"training loss\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d11c05-a019-46b1-aff6-07d9e6565c5c",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4149d6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Evaluation and prediction\n",
    "#put the model back on CPU\n",
    "model = model.to(device=\"cpu\")\n",
    "\n",
    "# Divide the evaluation and prediction in batches and try to make predictions as witout it we are using whole CPU and RAM on the lxplus.\n",
    "ds_elems = [ds_train[i] for i in range(max_events_train, max_events_train + max_events_eval)]\n",
    "\n",
    "# Define batch size\n",
    "batch_size = 32  # You can adjust this value based on your available memory\n",
    "\n",
    "# Iterate over the dataset elements in chunks\n",
    "for i in range(0, len(ds_elems), batch_size):\n",
    "    # Get a batch of dataset elements\n",
    "    batch_elems = ds_elems[i:i + batch_size]\n",
    "\n",
    "    # Process input features\n",
    "    X_features = [torch.tensor(elem[\"X\"]).to(torch.float32) for elem in batch_elems]\n",
    "    X_features_padded = pad_sequence(X_features, batch_first=True)\n",
    "\n",
    "    # Process target labels\n",
    "    y_targets = [torch.tensor(elem[\"ygen\"]).to(torch.float32) for elem in batch_elems]\n",
    "    y_targets_padded = pad_sequence(y_targets, batch_first=True)\n",
    "\n",
    "    # Create mask for the batch\n",
    "    mask = X_features_padded[:, :, 0] != 0\n",
    "\n",
    "    # Continue with your further processing (e.g., model prediction, loss computation)\n",
    "    preds = model(X_features_padded, mask)\n",
    "    preds = preds[0].detach(), preds[1].detach()\n",
    "\n",
    "    # Update mask for the batch\n",
    "    mask = X_features_padded[:, :, 0] != 0\n",
    "\n",
    "    # Unpack predictions and targets for the batch\n",
    "    preds_unpacked = unpack_predictions(preds)\n",
    "    targets_unpacked = unpack_target(y_targets_padded)\n",
    "\n",
    "    # Compute loss for the batch\n",
    "    loss = mlpf_loss(targets_unpacked, preds_unpacked, mask)\n",
    "\n",
    "    # Perform backpropagation and optimization (if applicable)\n",
    "    # optimizer.zero_grad()\n",
    "    # loss.backward()\n",
    "    # optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7ab70010",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Classification': tensor(0.6487),\n",
       " 'Regression': tensor(0.2485),\n",
       " 'MET': tensor(21.0352),\n",
       " 'Total': tensor(0.8972)}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "508ad615-a40e-49b5-a159-34fb564053dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds_elems = [ds_train[i] for i in range(max_events_train,max_events_train+max_events_eval)]\n",
    "# X_features = [torch.tensor(elem[\"X\"]).to(torch.float32) for elem in ds_elems]\n",
    "# X_features_padded = pad_sequence(X_features, batch_first=True)\n",
    "# y_targets = [torch.tensor(elem[\"ygen\"]).to(torch.float32) for elem in ds_elems]\n",
    "# y_targets_padded = pad_sequence(y_targets, batch_first=True)\n",
    "# mask = X_features_padded[:, :, 0]!=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f61b28d5-29d0-4b5d-9468-9a385b814faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preds = model(X_features_padded, mask)\n",
    "# preds = preds[0].detach(), preds[1].detach()\n",
    "# mask = X_features_padded[:, :, 0:1] != 0\n",
    "# preds_unpacked = unpack_predictions(preds)\n",
    "# targets_unpacked = unpack_target(y_targets_padded)\n",
    "\n",
    "# loss = mlpf_loss(targets_unpacked, preds_unpacked, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4e93a0dd-77cb-4325-9fc1-b9da22b2b508",
   "metadata": {},
   "outputs": [],
   "source": [
    "msk_true_particles = targets_unpacked[\"cls_id\"]!=0\n",
    "\n",
    "pt_target = targets_unpacked[\"pt\"][msk_true_particles].numpy()\n",
    "pt_pred = preds_unpacked[\"pt\"][msk_true_particles].numpy()\n",
    "\n",
    "eta_target = targets_unpacked[\"eta\"][msk_true_particles].numpy()\n",
    "eta_pred = preds_unpacked[\"eta\"][msk_true_particles].numpy()\n",
    "\n",
    "sphi_target = targets_unpacked[\"sin_phi\"][msk_true_particles].numpy()\n",
    "sphi_pred = preds_unpacked[\"sin_phi\"][msk_true_particles].numpy()\n",
    "\n",
    "cphi_target = targets_unpacked[\"cos_phi\"][msk_true_particles].numpy()\n",
    "cphi_pred = preds_unpacked[\"cos_phi\"][msk_true_particles].numpy()\n",
    "\n",
    "energy_target = targets_unpacked[\"energy\"][msk_true_particles].numpy()\n",
    "energy_pred = preds_unpacked[\"energy\"][msk_true_particles].numpy()\n",
    "\n",
    "px = preds_unpacked[\"pt\"] * preds_unpacked[\"cos_phi\"] * msk_true_particles\n",
    "py = preds_unpacked[\"pt\"] * preds_unpacked[\"sin_phi\"] * msk_true_particles\n",
    "pred_met = torch.sqrt(torch.sum(px, axis=-2) ** 2 + torch.sum(py, axis=-2) ** 2)\n",
    "\n",
    "px = targets_unpacked[\"pt\"] * targets_unpacked[\"cos_phi\"] * msk_true_particles\n",
    "py = targets_unpacked[\"pt\"] * targets_unpacked[\"sin_phi\"] * msk_true_particles\n",
    "true_met = torch.sqrt(torch.sum(px, axis=-2) ** 2 + torch.sum(py, axis=-2) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "864ee0fb-257d-48fc-8c52-d07cb6895395",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'pred MET')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(true_met, pred_met, marker=\".\")\n",
    "plt.xlabel(\"true MET\")\n",
    "plt.ylabel(\"pred MET\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "00ca5eaa-86b6-410a-bd72-3a69134d9e1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAAsTAAALEwEAmpwYAAAPAklEQVR4nO3dfYxld13H8ffHbhuUB9u1s+tKiSNmU60mfcikFqsEXUpKS9jVWAJRnGjNhoQaSDS6SkLwv6KR+BCDWaEyakUqUHfDk2xGCDGByrRsS+sWl5Kl1C47QxEKmoiFr3/cs3W4e2fnzsO5Mz95v5LJOed3fmfPN79z9rNnzj3nbqoKSVJ7vmurC5AkrY8BLkmNMsAlqVEGuCQ1ygCXpEbtmOTOLr300pqenp7kLiWpeffee++XqmpquH2iAT49Pc3CwsIkdylJzUvy+VHt3kKRpEYZ4JLUqLECPMnFSd6d5OEkJ5K8IMnOJMeSnOyml/RdrCTp/4x7Bf7HwIeq6keAK4ETwCFgvqr2AvPdsiRpQlYN8CTPAV4IvB2gqr5RVV8B9gNzXbc54EA/JUqSRhnnCvz5wBLwl0k+leRtSZ4J7K6q0wDddNeojZMcTLKQZGFpaWnTCpek73TjBPgO4BrgrVV1NfCfrOF2SVUdrqqZqpqZmjrnMUZJ0jqNE+CPAY9V1T3d8rsZBPqZJHsAuuliPyVKkkZZNcCr6ovAF5Jc3jXtA/4VOArMdm2zwJFeKpQkjTTum5i/DtyZ5CLgc8CvMAj/u5LcCjwK3NJPieszfej937Z86vabt6gSSerHWAFeVceBmRGr9m1qNZKksfkmpiQ1ygCXpEYZ4JLUKANckhplgEtSowxwSWqUAS5JjTLAJalRBrgkNcoAl6RGGeCS1CgDXJIaZYBLUqMMcElqlAEuSY0ywCWpUQa4JDXKAJekRhngktQoA1ySGmWAS1KjDHBJapQBLkmNMsAlqVEGuCQ1ygCXpEbtGKdTklPA14BvAk9V1UySncC7gGngFPCKqvqPfsqUJA1byxX4z1TVVVU10y0fAuarai8w3y1LkiZkI7dQ9gNz3fwccGDD1UiSxjZugBfw4ST3JjnYte2uqtMA3XTXqA2THEyykGRhaWlp4xVLkoAx74ED11fV40l2AceSPDzuDqrqMHAYYGZmptZRoyRphLGuwKvq8W66CNwNXAucSbIHoJsu9lWkJOlcqwZ4kmcmefbZeeAlwIPAUWC26zYLHOmrSEnSuca5hbIbuDvJ2f5/W1UfSvJJ4K4ktwKPArf0V6YkadiqAV5VnwOuHNH+BLCvj6IkSavzTUxJapQBLkmNMsAlqVEGuCQ1ygCXpEYZ4JLUKANckhplgEtSowxwSWqUAS5JjTLAJalRBrgkNcoAl6RGGeCS1CgDXJIaZYBLUqMMcElqlAEuSY0ywCWpUeP8p8b/L0wfev/T86duv3kLK5GkzeEVuCQ1ygCXpEYZ4JLUKANckhplgEtSowxwSWrU2AGe5IIkn0ryvm55Z5JjSU5200v6K1OSNGwtV+CvA04sWz4EzFfVXmC+W5YkTchYAZ7kMuBm4G3LmvcDc938HHBgUyuTJJ3XuFfgfwT8FvCtZW27q+o0QDfdNWrDJAeTLCRZWFpa2kitkqRlVg3wJC8DFqvq3vXsoKoOV9VMVc1MTU2t54+QJI0wznehXA+8PMlNwDOA5yT5G+BMkj1VdTrJHmCxz0IlSd9u1SvwqvqdqrqsqqaBVwL/VFW/BBwFZrtus8CR3qqUJJ1jI8+B3w7ckOQkcEO3LEmakDV9nWxVfRT4aDf/BLBv80uSJI3DNzElqVEGuCQ1ygCXpEYZ4JLUKANckhplgEtSowxwSWqUAS5JjTLAJalRBrgkNcoAl6RGGeCS1CgDXJIaZYBLUqMMcElqlAEuSY0ywCWpUQa4JDXKAJekRhngktQoA1ySGmWAS1KjDHBJapQBLkmNMsAlqVEGuCQ1atUAT/KMJP+S5P4kDyX5va59Z5JjSU5200v6L1eSdNY4V+D/DfxsVV0JXAXcmOQ64BAwX1V7gfluWZI0IasGeA18vVu8sPspYD8w17XPAQf6KFCSNNpY98CTXJDkOLAIHKuqe4DdVXUaoJvu6q1KSdI5xgrwqvpmVV0FXAZcm+THx91BkoNJFpIsLC0trbNMSdKwNT2FUlVfAT4K3AicSbIHoJsurrDN4aqaqaqZqampjVUrSXraOE+hTCW5uJv/buDFwMPAUWC26zYLHOmpRknSCDvG6LMHmEtyAYPAv6uq3pfk48BdSW4FHgVu6bFOSdKQVQO8qh4Arh7R/gSwr4+iJEmr801MSWqUAS5JjTLAJalRBrgkNcoAl6RGGeCS1CgDXJIaZYBLUqMMcElqlAEuSY0ywCWpUQa4JDXKAJekRhngktQoA1ySGmWAS1KjDHBJapQBLkmNMsAlqVEGuCQ1ygCXpEYZ4JLUKANckhplgEtSowxwSWqUAS5JjVo1wJM8L8lHkpxI8lCS13XtO5McS3Kym17Sf7mSpLPGuQJ/CviNqvpR4DrgtUmuAA4B81W1F5jvliVJE7JqgFfV6aq6r5v/GnACeC6wH5jrus0BB3qqUZI0wprugSeZBq4G7gF2V9VpGIQ8sGvTq5MkrWjsAE/yLOA9wOur6sk1bHcwyUKShaWlpfXUKEkaYawAT3Ihg/C+s6re2zWfSbKnW78HWBy1bVUdrqqZqpqZmprajJolSYz3FEqAtwMnquoty1YdBWa7+VngyOaXJ0layY4x+lwPvBr4dJLjXdvvArcDdyW5FXgUuKWXCiVJI60a4FX1z0BWWL1vc8uRJI3LNzElqVEGuCQ1ygCXpEYZ4JLUKANckhplgEtSowxwSWqUAS5JjTLAJalRBrgkNcoAl6RGGeCS1CgDXJIaZYBLUqMMcElqlAEuSY0ywCWpUQa4JDXKAJekRhngktQoA1ySGmWAS1KjDHBJapQBLkmNMsAlqVEGuCQ1ygCXpEatGuBJ7kiymOTBZW07kxxLcrKbXtJvmZKkYeNcgb8DuHGo7RAwX1V7gfluWZI0QasGeFV9DPjyUPN+YK6bnwMObG5ZkqTVrPce+O6qOg3QTXet1DHJwSQLSRaWlpbWuTtJ0rDeP8SsqsNVNVNVM1NTU33vTpK+Y6w3wM8k2QPQTRc3ryRJ0jh2rHO7o8AscHs3PbJpFU3A9KH3Pz1/6vabt7ASSVq/cR4jfCfwceDyJI8luZVBcN+Q5CRwQ7csSZqgVa/Aq+pVK6zat8m1SJLWwDcxJalRBrgkNcoAl6RGGeCS1CgDXJIaZYBLUqMMcElqlAEuSY1a76v029LyV+TXs42v1UtqiVfgktQoA1ySGmWAS1KjDHBJapQBLkmNMsAlqVFNPka4nscF1/rn+kihpO3OK3BJapQBLkmNavIWynbk7RdJk+YVuCQ1ygCXpEYZ4JLUKANckhplgEtSowxwSWpUM48R9vX25Vr3t5FHBCfxqKGPM0rfOTZ0BZ7kxiSfSfLZJIc2qyhJ0urWHeBJLgD+DHgpcAXwqiRXbFZhkqTz28gV+LXAZ6vqc1X1DeDvgP2bU5YkaTWpqvVtmPwCcGNV/Vq3/GrgJ6rqtqF+B4GD3eLlwGfWWeulwJfWuW2frGttrGttrGtttmtdsLHafrCqpoYbN/IhZka0nfOvQVUdBg5vYD+DnSULVTWz0T9ns1nX2ljX2ljX2mzXuqCf2jZyC+Ux4HnLli8DHt9YOZKkcW0kwD8J7E3yQ0kuAl4JHN2csiRJq1n3LZSqeirJbcA/AhcAd1TVQ5tW2bk2fBumJ9a1Nta1Nta1Ntu1LuihtnV/iClJ2lq+Si9JjTLAJalR2y7AV3s9PwN/0q1/IMk1E6jpeUk+kuREkoeSvG5Enxcl+WqS493PG/uuq9vvqSSf7va5MGL9VozX5cvG4XiSJ5O8fqjPRMYryR1JFpM8uKxtZ5JjSU5200tW2La3r4pYoa4/SPJwd5zuTnLxCtue95j3UNebkvz7smN10wrbTnq83rWsplNJjq+wbZ/jNTIbJnaOVdW2+WHwYegjwPOBi4D7gSuG+twEfJDBc+jXAfdMoK49wDXd/LOBfxtR14uA923BmJ0CLj3P+omP14hj+kUGLyJMfLyAFwLXAA8ua/t94FA3fwh483rOxR7qegmwo5t/86i6xjnmPdT1JuA3xzjOEx2vofV/CLxxC8ZrZDZM6hzbblfg47yevx/4qxr4BHBxkj19FlVVp6vqvm7+a8AJ4Ll97nMTTXy8huwDHqmqz09wn0+rqo8BXx5q3g/MdfNzwIERm/b6VRGj6qqqD1fVU93iJxi8WzFRK4zXOCY+XmclCfAK4J2btb9xnScbJnKObbcAfy7whWXLj3FuUI7TpzdJpoGrgXtGrH5BkvuTfDDJj02opAI+nOTeDL62YNiWjheD9wNW+ou1FeMFsLuqTsPgLyCwa0SfrR63X2Xwm9Moqx3zPtzW3dq5Y4XbAVs5Xj8NnKmqkyusn8h4DWXDRM6x7Rbg47yeP9Yr/H1I8izgPcDrq+rJodX3MbhNcCXwp8A/TKIm4PqquobBt0K+NskLh9Zv5XhdBLwc+PsRq7dqvMa1leP2BuAp4M4Vuqx2zDfbW4EfBq4CTjO4XTFsy8YLeBXnv/rufbxWyYYVNxvRtqYx224BPs7r+VvyCn+SCxkcoDur6r3D66vqyar6ejf/AeDCJJf2XVdVPd5NF4G7GfxattxWfuXBS4H7qurM8IqtGq/OmbO3kbrp4og+W3WezQIvA36xuhulw8Y45puqqs5U1Ter6lvAX6ywv60arx3AzwPvWqlP3+O1QjZM5BzbbgE+zuv5R4Ff7p6uuA746tlfVfrS3WN7O3Ciqt6yQp/v7/qR5FoGY/tEz3U9M8mzz84z+BDswaFuEx+vZVa8MtqK8VrmKDDbzc8CR0b0mfhXRSS5Efht4OVV9V8r9BnnmG92Xcs/M/m5Ffa3VV+t8WLg4ap6bNTKvsfrPNkwmXOsj09mN/ip7k0MPsl9BHhD1/Ya4DXdfBj8RxKPAJ8GZiZQ008x+NXmAeB493PTUF23AQ8x+CT5E8BPTqCu53f7u7/b97YYr26/38MgkL93WdvEx4vBPyCngf9hcMVzK/B9wDxwspvu7Pr+APCB852LPdf1WQb3RM+eY38+XNdKx7znuv66O3ceYBAwe7bDeHXt7zh7Ti3rO8nxWikbJnKO+Sq9JDVqu91CkSSNyQCXpEYZ4JLUKANckhplgEtSowxwSWqUAS5JjfpfTKO4lIsgcGgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(pred_met/true_met, bins=np.linspace(0,20,100));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5b100969-4eb0-4eff-ae28-4d4f17a559f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'pred pt')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "b = np.logspace(-1,2,100)\n",
    "plt.hist2d(\n",
    "    pt_target,\n",
    "    pt_pred,\n",
    "    bins=(b,b)\n",
    ")\n",
    "plt.xscale(\"log\")\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"true pt\")\n",
    "plt.ylabel(\"pred pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8d5ef494-527e-447b-9023-79b1a1245909",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'pred eta')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "b = np.linspace(-4,4,100)\n",
    "plt.hist2d(\n",
    "    eta_target,\n",
    "    eta_pred,\n",
    "    bins=(b,b)\n",
    ")\n",
    "plt.xlabel(\"true eta\")\n",
    "plt.ylabel(\"pred eta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "460019b7-9971-4556-a644-342cc29a94a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'pred sphi')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "b = np.linspace(-1,1,100)\n",
    "plt.hist2d(\n",
    "    sphi_target,\n",
    "    sphi_pred,\n",
    "    bins=(b,b)\n",
    ")\n",
    "plt.xlabel(\"true sphi\")\n",
    "plt.ylabel(\"pred sphi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f4be3453-73ad-49ea-b50f-d1e8286c067e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'pred cphi')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "b = np.linspace(-1,1,100)\n",
    "plt.hist2d(\n",
    "    cphi_target,\n",
    "    cphi_pred,\n",
    "    bins=(b,b)\n",
    ")\n",
    "plt.xlabel(\"true cphi\")\n",
    "plt.ylabel(\"pred cphi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "04008e59-081c-41e7-93db-79ac0bd9da7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'pred energy')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "b = np.logspace(-1,2,100)\n",
    "plt.hist2d(\n",
    "    energy_target,\n",
    "    energy_pred,\n",
    "    bins=(b,b)\n",
    ")\n",
    "plt.xscale(\"log\")\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"true energy\")\n",
    "plt.ylabel(\"pred energy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb59b32-9925-419f-bd15-09923b6d1073",
   "metadata": {},
   "source": [
    "## Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "90148326-4b8c-4d2d-b192-b479b1516633",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cvmfs/sft.cern.ch/lcg/views/LCG_105_cuda/x86_64-el9-gcc11-opt/lib/python3.9/site-packages/torch/ao/quantization/observer.py:214: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
      "  warnings.warn(\n",
      "/cvmfs/sft.cern.ch/lcg/views/LCG_105_cuda/x86_64-el9-gcc11-opt/lib/python3.9/site-packages/torch/ao/quantization/observer.py:1207: UserWarning: must run observer before calling calculate_qparams.                                    Returning default scale and zero point \n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "model.qconfig = torch.ao.quantization.get_default_qconfig('x86')\n",
    "custom_module_config = {\n",
    "        \"float_to_observed_custom_module_class\": {torch.nn.MultiheadAttention: QuantizeableMultiheadAttention},\n",
    "        \"observed_to_quantized_custom_module_class\": {QuantizeableMultiheadAttention: QuantizedMultiheadAttention},\n",
    "}\n",
    "\n",
    "model_prepared = torch.ao.quantization.prepare(model, prepare_custom_config_dict=custom_module_config)\n",
    "\n",
    "#calibrate on data\n",
    "num_events_to_calibrate = 100\n",
    "for ind in range(max_events_train,max_events_train+num_events_to_calibrate):\n",
    "    _X = torch.unsqueeze(torch.tensor(ds_train[ind][\"X\"]).to(torch.float32), 0)\n",
    "    _mask = _X[:, :, 0]!=0\n",
    "    model_prepared(_X, _mask)\n",
    "\n",
    "model_int8 = torch.ao.quantization.convert(model_prepared,convert_custom_config_dict=custom_module_config,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9248b521-f166-4944-95cb-af96b5e66adc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QuantizeFeaturesStub(\n",
       "  (quants): ModuleList(\n",
       "    (0): Quantize(scale=tensor([0.0157]), zero_point=tensor([0]), dtype=torch.quint8)\n",
       "    (1): Quantize(scale=tensor([0.0771]), zero_point=tensor([67]), dtype=torch.quint8)\n",
       "    (2): Quantize(scale=tensor([0.0763]), zero_point=tensor([64]), dtype=torch.quint8)\n",
       "    (3-4): 2 x Quantize(scale=tensor([0.0158]), zero_point=tensor([63]), dtype=torch.quint8)\n",
       "    (5): Quantize(scale=tensor([0.0709]), zero_point=tensor([49]), dtype=torch.quint8)\n",
       "    (6): Quantize(scale=tensor([584.8150]), zero_point=tensor([4]), dtype=torch.quint8)\n",
       "    (7): Quantize(scale=tensor([44.0685]), zero_point=tensor([68]), dtype=torch.quint8)\n",
       "    (8): Quantize(scale=tensor([63.4346]), zero_point=tensor([64]), dtype=torch.quint8)\n",
       "    (9): Quantize(scale=tensor([0.0243]), zero_point=tensor([0]), dtype=torch.quint8)\n",
       "    (10): Quantize(scale=tensor([6.4775]), zero_point=tensor([0]), dtype=torch.quint8)\n",
       "    (11): Quantize(scale=tensor([0.5430]), zero_point=tensor([13]), dtype=torch.quint8)\n",
       "    (12): Quantize(scale=tensor([1.2229]), zero_point=tensor([39]), dtype=torch.quint8)\n",
       "    (13): Quantize(scale=tensor([11.7960]), zero_point=tensor([0]), dtype=torch.quint8)\n",
       "    (14): Quantize(scale=tensor([11.3899]), zero_point=tensor([38]), dtype=torch.quint8)\n",
       "    (15): Quantize(scale=tensor([7.8096]), zero_point=tensor([0]), dtype=torch.quint8)\n",
       "    (16): Quantize(scale=tensor([6.7856]), zero_point=tensor([0]), dtype=torch.quint8)\n",
       "    (17-19): 3 x Quantize(scale=tensor([1.]), zero_point=tensor([0]), dtype=torch.quint8)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_int8.quant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2e8f0258-3225-4c0f-8529-7a3bcbc83659",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_quantized = torch.quantize_per_tensor((X_features_padded[:, :, 0]!=0).to(torch.float32), 1, 0, torch.quint8)\n",
    "preds = model_int8(X_features_padded, mask_quantized)\n",
    "preds = preds[0].detach(), preds[1].detach()\n",
    "preds_unpacked_int8 = unpack_predictions(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f1344cde-97f6-4a1c-8526-3586a139efff",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_int8 = mlpf_loss(targets_unpacked, preds_unpacked_int8, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "90b2a37d-8aa2-4ae0-be3b-c1d3fe56a2e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Final total loss')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(range(2), [loss[\"Total\"].detach().numpy(), loss_int8[\"Total\"].detach().numpy()])\n",
    "plt.xticks(range(2), [\"fp32\", \"int8\"])\n",
    "plt.ylabel(\"Final total loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "57979d38-46a9-48bd-a9a2-748cb29d519d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_pred_int8 = preds_unpacked_int8[\"pt\"][msk_true_particles].numpy()\n",
    "eta_pred_int8 = preds_unpacked_int8[\"eta\"][msk_true_particles].numpy()\n",
    "sphi_pred_int8 = preds_unpacked_int8[\"sin_phi\"][msk_true_particles].numpy()\n",
    "cphi_pred_int8 = preds_unpacked_int8[\"cos_phi\"][msk_true_particles].numpy()\n",
    "energy_pred_int8 = preds_unpacked_int8[\"energy\"][msk_true_particles].numpy()\n",
    "\n",
    "px = preds_unpacked_int8[\"pt\"] * preds_unpacked_int8[\"cos_phi\"] * msk_true_particles\n",
    "py = preds_unpacked_int8[\"pt\"] * preds_unpacked_int8[\"sin_phi\"] * msk_true_particles\n",
    "pred_met_int8 = torch.sqrt(torch.sum(px, axis=-2) ** 2 + torch.sum(py, axis=-2) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e7c02b0e-3e92-4aec-8741-6a4a58c1deca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f562e252e50>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(pred_met/true_met, bins=np.linspace(0,5,61), histtype=\"step\", lw=2, label=\"fp32\");\n",
    "plt.hist(pred_met_int8/true_met, bins=np.linspace(0,5,61), histtype=\"step\", lw=2, label=\"int8\");\n",
    "plt.xlabel(\"reco_met / gen_met\")\n",
    "plt.ylabel(\"number of events / bin\")\n",
    "plt.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688b47f6-c922-4520-8ba4-5f783a7f4130",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(3):\n",
    "#     t0 = time.time()\n",
    "#     for j in range(1):\n",
    "#         model(X_features_padded, X_features_padded[:, :, 0]!=0)\n",
    "#     t1 = time.time()\n",
    "#     print(t1 - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f845b93f-decc-4d8f-be11-d54b7486e24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask_quantized = torch.quantize_per_tensor((X_features_padded[:, :, 0]!=0).to(torch.float32), 1, 0, torch.quint8)\n",
    "# for i in range(3):\n",
    "#     t0 = time.time()\n",
    "#     for j in range(1):\n",
    "#         model_int8(X_features_padded, mask_quantized)\n",
    "#     t1 = time.time()\n",
    "#     print(t1 - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c59978-a1ae-44f5-ba0e-ecce9d0d1e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_options = torch.onnx.ExportOptions(dynamic_shapes=True)\n",
    "mask = X_features_padded[:, :, 0]!=0\n",
    "\n",
    "onnx_program = torch.onnx.dynamo_export(model, X_features_padded, mask, export_options=export_options)\n",
    "onnx_program.save(\"mlpf_fp32_dynamo.onnx\")\n",
    "\n",
    "torch.onnx.export(model,                                            # model\n",
    "                  (X_features_padded, mask),                        # model input\n",
    "                  \"mlpf_fp32.onnx\",                                 # path\n",
    "                  export_params=True,                               # store the trained parameter weights inside the model file\n",
    "                  opset_version=17,                                 # the ONNX version to export the model to\n",
    "                  do_constant_folding=True,                         # constant folding for optimization\n",
    "                  input_names = ['input'],                          # input names\n",
    "                  output_names = ['output'],                        # output names\n",
    "                  dynamic_axes={'input' : {0 : 'batch_size', 1: 'num_elems'},\n",
    "                                'output' : {0 : 'batch_size', 1: 'num_elems'}},\n",
    "                  verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a3cb52-1120-4293-b07c-decaf6c0013d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This does not work\n",
    "# onnx_program = torch.onnx.dynamo_export(model_int8, X_features_padded, mask_quantized, export_options=export_options)\n",
    "# onnx_program.save(\"mlpf_int8_dynamo.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfcff62-763d-48b0-99de-4485c160382d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.onnx.export(model_int8,                                       # model\n",
    "                  (X_features_padded, mask_quantized),              # model input\n",
    "                  \"mlpf_int8.onnx\",                                 # path\n",
    "                  export_params=True,                               # store the trained parameter weights inside the model file\n",
    "                  opset_version=17,                                 # the ONNX version to export the model to\n",
    "                  do_constant_folding=True,                         # constant folding for optimization\n",
    "                  input_names = ['input'],                          # input names\n",
    "                  output_names = ['output'],                        # output names\n",
    "                  dynamic_axes={'input' : {0 : 'batch_size', 1: 'num_elems'},\n",
    "                                'output' : {0 : 'batch_size', 1: 'num_elems'}},\n",
    "                  verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a36aea-6c1c-4070-a9c1-fa418fe70587",
   "metadata": {},
   "outputs": [],
   "source": [
    "!du -csh *.onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36df9966-0a7a-471a-ab2f-f050581164da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime as ort\n",
    "\n",
    "ort_fp32 = ort.InferenceSession('mlpf_fp32.onnx')\n",
    "outputs = ort_fp32.run(None, {'input': X_features_padded.numpy()})\n",
    "preds_unpacked_ort_fp32 = unpack_predictions((torch.tensor(outputs[0]), torch.tensor(outputs[1])))\n",
    "\n",
    "px = preds_unpacked_ort_fp32[\"pt\"] * preds_unpacked_ort_fp32[\"cos_phi\"] * msk_true_particles\n",
    "py = preds_unpacked_ort_fp32[\"pt\"] * preds_unpacked_ort_fp32[\"sin_phi\"] * msk_true_particles\n",
    "pred_met_ort_fp32 = torch.sqrt(torch.sum(px, axis=-2) ** 2 + torch.sum(py, axis=-2) ** 2)\n",
    "\n",
    "ort_int8 = ort.InferenceSession('mlpf_int8.onnx')\n",
    "outputs = ort_int8.run(None, {'input': X_features_padded.numpy()})\n",
    "preds_unpacked_ort_int8 = unpack_predictions((torch.tensor(outputs[0]), torch.tensor(outputs[1])))\n",
    "\n",
    "px = preds_unpacked_ort_int8[\"pt\"] * preds_unpacked_ort_int8[\"cos_phi\"] * msk_true_particles\n",
    "py = preds_unpacked_ort_int8[\"pt\"] * preds_unpacked_ort_int8[\"sin_phi\"] * msk_true_particles\n",
    "pred_met_ort_int8 = torch.sqrt(torch.sum(px, axis=-2) ** 2 + torch.sum(py, axis=-2) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a8dcba-ade3-4135-a23b-9d9eed6830c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(\n",
    "    preds_unpacked[\"pt\"][targets_unpacked[\"cls_id\"]!=0],\n",
    "    preds_unpacked_ort_fp32[\"pt\"][targets_unpacked[\"cls_id\"]!=0],\n",
    "    marker=\".\", label=\"fp32\"\n",
    ")\n",
    "\n",
    "plt.scatter(\n",
    "    preds_unpacked_int8[\"pt\"][targets_unpacked[\"cls_id\"]!=0],\n",
    "    preds_unpacked_ort_int8[\"pt\"][targets_unpacked[\"cls_id\"]!=0],\n",
    "    marker=\".\", label=\"int8\"\n",
    ")\n",
    "plt.xlabel(\"pt, pytorch\")\n",
    "plt.ylabel(\"pt, ONNX\")\n",
    "plt.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6919306-9c6e-43ad-9f3a-fa32af4ee102",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(\n",
    "    pred_met,\n",
    "    pred_met_ort_fp32,\n",
    "    marker=\".\", label=\"fp32\"\n",
    ")\n",
    "\n",
    "plt.scatter(\n",
    "    pred_met_int8,\n",
    "    pred_met_ort_int8,\n",
    "    marker=\".\", label=\"int8\"\n",
    ")\n",
    "plt.xlabel(\"MET, pytorch\")\n",
    "plt.ylabel(\"MET, ONNX\")\n",
    "plt.legend(loc=\"best\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
