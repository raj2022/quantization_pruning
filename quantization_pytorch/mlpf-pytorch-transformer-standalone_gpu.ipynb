{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b53ad0ae",
   "metadata": {},
   "source": [
    "## TO DO:\n",
    "\n",
    "* Working on the CPU with a reseaonable numbr of statistics try to plot the figure 9.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c0a1754",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import time\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39607f7d-cab2-469b-874e-c835e0c78865",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, Tensor\n",
    "import tensorflow_datasets as tfds\n",
    "import torch_geometric\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f57959f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of available GPUs: 1\n",
      "Current GPU: Tesla T4\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    gpu_count = torch.cuda.device_count()\n",
    "    print(f\"Number of available GPUs: {gpu_count}\")\n",
    "\n",
    "    # Get the name of the current GPU\n",
    "    current_gpu = torch.cuda.get_device_name(0)\n",
    "    print(f\"Current GPU: {current_gpu}\")\n",
    "else:\n",
    "    print(\"CUDA is not available. PyTorch is running on CPU.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb7fa6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2460cf92-75be-4622-bfb2-8392978e2ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../../mlpf/tensorflow_datasets/\"\n",
    "dataset = \"clic_edm_ttbar_pf\"\n",
    "\n",
    "#Load dataset\n",
    "builder = tfds.builder(dataset, data_dir=data_dir)\n",
    "ds_train = builder.as_data_source(split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86bd3286-c7a9-4bcb-a945-162cad36eec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_FEATURES_TRK = [\n",
    "    \"elemtype\",\n",
    "    \"pt\",\n",
    "    \"eta\",\n",
    "    \"sin_phi\",\n",
    "    \"cos_phi\",\n",
    "    \"p\",\n",
    "    \"chi2\",\n",
    "    \"ndf\",\n",
    "    \"dEdx\",\n",
    "    \"dEdxError\",\n",
    "    \"radiusOfInnermostHit\",\n",
    "    \"tanLambda\",\n",
    "    \"D0\",\n",
    "    \"omega\",\n",
    "    \"Z0\",\n",
    "    \"time\",\n",
    "]\n",
    "X_FEATURES_CL = [\n",
    "    \"elemtype\",\n",
    "    \"et\",\n",
    "    \"eta\",\n",
    "    \"sin_phi\",\n",
    "    \"cos_phi\",\n",
    "    \"energy\",\n",
    "    \"position.x\",\n",
    "    \"position.y\",\n",
    "    \"position.z\",\n",
    "    \"iTheta\",\n",
    "    \"energy_ecal\",\n",
    "    \"energy_hcal\",\n",
    "    \"energy_other\",\n",
    "    \"num_hits\",\n",
    "    \"sigma_x\",\n",
    "    \"sigma_y\",\n",
    "    \"sigma_z\",\n",
    "]\n",
    "Y_FEATURES = [\"cls_id\", \"charge\", \"pt\", \"eta\", \"sin_phi\", \"cos_phi\", \"energy\"]\n",
    "Y_CLASSES = [0, 211, 130, 22, 11, 13]\n",
    "\n",
    "INPUT_DIM = max(len(X_FEATURES_TRK), len(X_FEATURES_CL))\n",
    "NUM_CLASSES = len(Y_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0fc5f7e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_CLASSES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409952b1-db7a-47f6-b57c-8d0ce37e0872",
   "metadata": {},
   "source": [
    "## Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d581d65-1794-4ac5-b65f-96461a4b9c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as nnF\n",
    "\n",
    "from torch import Tensor\n",
    "from typing import Optional, Tuple\n",
    "\n",
    "class QuantizeableMultiheadAttention(nn.MultiheadAttention):\n",
    "    _FLOAT_MODULE = nn.MultiheadAttention\n",
    "\n",
    "    r\"\"\"Quantizable implementation of the MultiheadAttention.\n",
    "\n",
    "    Note::\n",
    "        Please, refer to :class:`~torch.nn.MultiheadAttention` for more\n",
    "        information\n",
    "\n",
    "    Allows the model to jointly attend to information from different\n",
    "    representation subspaces.\n",
    "    See reference: Attention Is All You Need\n",
    "\n",
    "    The original MHA module is not quantizable.\n",
    "    This reimplements it by explicitly instantiating the linear layers.\n",
    "\n",
    "    .. math::\n",
    "        \\text{MultiHead}(Q, K, V) = \\text{Concat}(head_1,\\dots,head_h)W^O\n",
    "        \\text{where} head_i = \\text{Attention}(QW_i^Q, KW_i^K, VW_i^V)\n",
    "\n",
    "    Args:\n",
    "        embed_dim: total dimension of the model.\n",
    "        num_heads: parallel attention heads.\n",
    "        dropout: a Dropout layer on attn_output_weights. Default: 0.0.\n",
    "        bias: add bias as module parameter. Default: True.\n",
    "        add_bias_kv: add bias to the key and value sequences at dim=0.\n",
    "        add_zero_attn: add a new batch of zeros to the key and\n",
    "                       value sequences at dim=1.\n",
    "        kdim: total number of features in key. Default: None.\n",
    "        vdim: total number of features in value. Default: None.\n",
    "        batch_first: If ``True``, then the input and output tensors are provided\n",
    "            as (batch, seq, feature). Default: ``False`` (seq, batch, feature).\n",
    "\n",
    "    Note that if :attr:`kdim` and :attr:`vdim` are None, they will be set\n",
    "    to :attr:`embed_dim` such that query, key, and value have the same\n",
    "    number of features.\n",
    "\n",
    "    Examples::\n",
    "\n",
    "        >>> import torch.ao.nn.quantizable as nnqa\n",
    "        >>> multihead_attn = nnqa.MultiheadAttention(embed_dim, num_heads)\n",
    "        >>> attn_output, attn_output_weights = multihead_attn(query, key, value)\n",
    "\n",
    "    Note::\n",
    "        Please, follow the quantization flow to convert the quantizable MHA.\n",
    "    \"\"\"\n",
    "    __constants__ = ['batch_first']\n",
    "\n",
    "    def __init__(self, embed_dim: int, num_heads: int,\n",
    "                 dropout: float = 0., bias: bool = True,\n",
    "                 add_bias_kv: bool = False, add_zero_attn: bool = False,\n",
    "                 kdim: Optional[int] = None, vdim: Optional[int] = None, batch_first: bool = False,\n",
    "                 device=None, dtype=None) -> None:\n",
    "        factory_kwargs = {'device': device, 'dtype': dtype}\n",
    "        super().__init__(embed_dim, num_heads, dropout,\n",
    "                         bias, add_bias_kv,\n",
    "                         add_zero_attn, kdim, vdim, batch_first,\n",
    "                         **factory_kwargs)\n",
    "        self.linear_Q = nn.Linear(self.embed_dim, self.embed_dim, bias=bias, **factory_kwargs)\n",
    "        self.linear_K = nn.Linear(self.kdim, self.embed_dim, bias=bias, **factory_kwargs)\n",
    "        self.linear_V = nn.Linear(self.vdim, self.embed_dim, bias=bias, **factory_kwargs)\n",
    "        # for the type: ignore, see https://github.com/pytorch/pytorch/issues/58969\n",
    "        self.out_proj = nn.Linear(self.embed_dim, self.embed_dim, bias=bias, **factory_kwargs)  # type: ignore[assignment]\n",
    "\n",
    "        # Functionals\n",
    "        # self.q_scaling_product = torch.ao.nn.quantized.FloatFunctional()\n",
    "        # note: importing torch.ao.nn.quantized at top creates a circular import\n",
    "\n",
    "        # Quant/Dequant\n",
    "        self.quant_attn_output = torch.ao.quantization.QuantStub()\n",
    "        self.quant_attn_output_weights = torch.ao.quantization.QuantStub()\n",
    "        self.dequant_q = torch.ao.quantization.DeQuantStub()\n",
    "        self.dequant_k = torch.ao.quantization.DeQuantStub()\n",
    "        self.dequant_v = torch.ao.quantization.DeQuantStub()\n",
    "\n",
    "    def _get_name(self):\n",
    "        return 'QuantizableMultiheadAttention'\n",
    "\n",
    "    @classmethod\n",
    "    def from_float(cls, other):\n",
    "        assert type(other) == cls._FLOAT_MODULE\n",
    "        assert hasattr(other, 'qconfig'), \"The float module must have 'qconfig'\"\n",
    "        # Setting the dropout to 0.0!\n",
    "        observed = cls(other.embed_dim, other.num_heads, other.dropout,\n",
    "                       (other.in_proj_bias is not None),\n",
    "                       (other.bias_k is not None),\n",
    "                       other.add_zero_attn, other.kdim, other.vdim,\n",
    "                       other.batch_first)\n",
    "        observed.bias_k = other.bias_k\n",
    "        observed.bias_v = other.bias_v\n",
    "        observed.qconfig = other.qconfig\n",
    "\n",
    "        # Set the linear weights\n",
    "        # for the type: ignores, see https://github.com/pytorch/pytorch/issues/58969\n",
    "        observed.out_proj.weight = other.out_proj.weight  # type: ignore[has-type]\n",
    "        observed.out_proj.bias = other.out_proj.bias  # type: ignore[has-type]\n",
    "        if other._qkv_same_embed_dim:\n",
    "            # Use separate params\n",
    "            bias = other.in_proj_bias\n",
    "            _start = 0\n",
    "            _end = _start + other.embed_dim\n",
    "            weight = other.in_proj_weight[_start:_end, :]\n",
    "            if bias is not None:\n",
    "                bias = torch.nn.Parameter(bias[_start:_end], bias.requires_grad)\n",
    "            observed.linear_Q.weight = torch.nn.Parameter(weight,\n",
    "                                                          weight.requires_grad)\n",
    "            observed.linear_Q.bias = bias\n",
    "\n",
    "            bias = other.in_proj_bias\n",
    "            _start = _end\n",
    "            _end = _start + other.embed_dim\n",
    "            weight = other.in_proj_weight[_start:_end, :]\n",
    "            if bias is not None:\n",
    "                bias = torch.nn.Parameter(bias[_start:_end], bias.requires_grad)\n",
    "            observed.linear_K.weight = torch.nn.Parameter(weight,\n",
    "                                                          weight.requires_grad)\n",
    "            observed.linear_K.bias = bias\n",
    "\n",
    "            bias = other.in_proj_bias\n",
    "            _start = _end\n",
    "            weight = other.in_proj_weight[_start:, :]\n",
    "            if bias is not None:\n",
    "                bias = torch.nn.Parameter(bias[_start:], bias.requires_grad)\n",
    "            observed.linear_V.weight = torch.nn.Parameter(weight,\n",
    "                                                          weight.requires_grad)\n",
    "            observed.linear_V.bias = bias\n",
    "        else:\n",
    "            observed.linear_Q.weight = nn.Parameter(other.q_proj_weight)\n",
    "            observed.linear_K.weight = nn.Parameter(other.k_proj_weight)\n",
    "            observed.linear_V.weight = nn.Parameter(other.v_proj_weight)\n",
    "            if other.in_proj_bias is None:\n",
    "                observed.linear_Q.bias = None  # type: ignore[assignment]\n",
    "                observed.linear_K.bias = None  # type: ignore[assignment]\n",
    "                observed.linear_V.bias = None  # type: ignore[assignment]\n",
    "            else:\n",
    "                observed.linear_Q.bias = nn.Parameter(other.in_proj_bias[0:other.embed_dim])\n",
    "                observed.linear_K.bias = nn.Parameter(other.in_proj_bias[other.embed_dim:(other.embed_dim * 2)])\n",
    "                observed.linear_V.bias = nn.Parameter(other.in_proj_bias[(other.embed_dim * 2):])\n",
    "        observed.eval()\n",
    "        # Explicit prepare\n",
    "        observed = torch.ao.quantization.prepare(observed, inplace=True)\n",
    "        return observed\n",
    "\n",
    "    @torch.jit.unused\n",
    "    def dequantize(self):\n",
    "        r\"\"\"Utility to convert the quantized MHA back to float.\n",
    "\n",
    "        The motivation for this is that it is not trivial to conver the weights\n",
    "        from the format that is used in the quantized version back to the\n",
    "        float.\n",
    "        \"\"\"\n",
    "        fp = self._FLOAT_MODULE(self.embed_dim, self.num_heads, self.dropout,\n",
    "                                (self.linear_Q._weight_bias()[1] is not None),\n",
    "                                (self.bias_k is not None),\n",
    "                                self.add_zero_attn, self.kdim, self.vdim, self.batch_first)\n",
    "        assert fp._qkv_same_embed_dim == self._qkv_same_embed_dim\n",
    "        if self.bias_k is not None:\n",
    "            fp.bias_k = nn.Parameter(self.bias_k.dequantize())\n",
    "        if self.bias_v is not None:\n",
    "            fp.bias_v = nn.Parameter(self.bias_v.dequantize())\n",
    "\n",
    "        # Set the linear weights\n",
    "        # Note: Because the linear layers are quantized, mypy does not nkow how\n",
    "        # to deal with them -- might need to ignore the typing checks.\n",
    "        # for the type: ignore[has-type], see https://github.com/pytorch/pytorch/issues/58969\n",
    "        w, b = self.out_proj._weight_bias()  # type: ignore[operator, has-type]\n",
    "        fp.out_proj.weight = nn.Parameter(w.dequantize())\n",
    "        if b is not None:\n",
    "            fp.out_proj.bias = nn.Parameter(b)\n",
    "\n",
    "        wQ, bQ = self.linear_Q._weight_bias()  # type: ignore[operator]\n",
    "        wQ = wQ.dequantize()\n",
    "        wK, bK = self.linear_K._weight_bias()  # type: ignore[operator]\n",
    "        wK = wK.dequantize()\n",
    "        wV, bV = self.linear_V._weight_bias()  # type: ignore[operator]\n",
    "        wV = wV.dequantize()\n",
    "        if fp._qkv_same_embed_dim:\n",
    "            # Use separate params\n",
    "            _start = 0\n",
    "            _end = _start + fp.embed_dim\n",
    "            fp.in_proj_weight[_start:_end, :] = wQ\n",
    "            if fp.in_proj_bias is not None:\n",
    "                assert all(bQ == 0)\n",
    "                fp.in_proj_bias[_start:_end] = bQ\n",
    "\n",
    "            _start = _end\n",
    "            _end = _start + fp.embed_dim\n",
    "            fp.in_proj_weight[_start:_end, :] = wK\n",
    "            if fp.in_proj_bias is not None:\n",
    "                assert all(bK == 0)\n",
    "                fp.in_proj_bias[_start:_end] = bK\n",
    "\n",
    "            _start = _end\n",
    "            fp.in_proj_weight[_start:, :] = wV\n",
    "            if fp.in_proj_bias is not None:\n",
    "                assert all(bV == 0)\n",
    "                fp.in_proj_bias[_start:] = bV\n",
    "        else:\n",
    "            fp.q_proj_weight = nn.Parameter(wQ)\n",
    "            fp.k_proj_weight = nn.Parameter(wK)\n",
    "            fp.v_proj_weight = nn.Parameter(wV)\n",
    "            if fp.in_proj_bias is None:\n",
    "                self.linear_Q.bias = None\n",
    "                self.linear_K.bias = None\n",
    "                self.linear_V.bias = None\n",
    "            else:\n",
    "                fp.in_proj_bias[0:fp.embed_dim] = bQ\n",
    "                fp.in_proj_bias[fp.embed_dim:(fp.embed_dim * 2)] = bK\n",
    "                fp.in_proj_bias[(fp.embed_dim * 2):] = bV\n",
    "\n",
    "        return fp\n",
    "\n",
    "\n",
    "    @classmethod\n",
    "    def from_observed(cls, other):\n",
    "        # The whole flow is float -> observed -> quantized\n",
    "        # This class does float -> observed only\n",
    "        # See nn.quantized.MultiheadAttention\n",
    "        raise NotImplementedError(\"It looks like you are trying to prepare an \"\n",
    "                                  \"MHA module. Please, see \"\n",
    "                                  \"the examples on quantizable MHAs.\")\n",
    "\n",
    "    def forward(self,\n",
    "                query: Tensor,\n",
    "                key: Tensor,\n",
    "                value: Tensor,\n",
    "                key_padding_mask: Optional[Tensor] = None,\n",
    "                need_weights: bool = True,\n",
    "                attn_mask: Optional[Tensor] = None,\n",
    "                average_attn_weights: bool = True,\n",
    "                is_causal: bool = False) -> Tuple[Tensor, Optional[Tensor]]:\n",
    "        r\"\"\"\n",
    "    Note::\n",
    "        Please, refer to :func:`~torch.nn.MultiheadAttention.forward` for more\n",
    "        information\n",
    "\n",
    "    Args:\n",
    "        query, key, value: map a query and a set of key-value pairs to an output.\n",
    "            See \"Attention Is All You Need\" for more details.\n",
    "        key_padding_mask: if provided, specified padding elements in the key will\n",
    "            be ignored by the attention. When given a binary mask and a value is True,\n",
    "            the corresponding value on the attention layer will be ignored.\n",
    "        need_weights: output attn_output_weights.\n",
    "        attn_mask: 2D or 3D mask that prevents attention to certain positions. A 2D mask will be broadcasted for all\n",
    "            the batches while a 3D mask allows to specify a different mask for the entries of each batch.\n",
    "\n",
    "    Shape:\n",
    "        - Inputs:\n",
    "        - query: :math:`(L, N, E)` where L is the target sequence length, N is the batch size, E is\n",
    "          the embedding dimension. :math:`(N, L, E)` if ``batch_first`` is ``True``.\n",
    "        - key: :math:`(S, N, E)`, where S is the source sequence length, N is the batch size, E is\n",
    "          the embedding dimension. :math:`(N, S, E)` if ``batch_first`` is ``True``.\n",
    "        - value: :math:`(S, N, E)` where S is the source sequence length, N is the batch size, E is\n",
    "          the embedding dimension. :math:`(N, S, E)` if ``batch_first`` is ``True``.\n",
    "        - key_padding_mask: :math:`(N, S)` where N is the batch size, S is the source sequence length.\n",
    "          If a BoolTensor is provided, the positions with the\n",
    "          value of ``True`` will be ignored while the position with the value of ``False`` will be unchanged.\n",
    "        - attn_mask: 2D mask :math:`(L, S)` where L is the target sequence length, S is the source sequence length.\n",
    "          3D mask :math:`(N*num_heads, L, S)` where N is the batch size, L is the target sequence length,\n",
    "          S is the source sequence length. attn_mask ensure that position i is allowed to attend the unmasked\n",
    "          positions. If a BoolTensor is provided, positions with ``True``\n",
    "          is not allowed to attend while ``False`` values will be unchanged. If a FloatTensor\n",
    "          is provided, it will be added to the attention weight.\n",
    "        - is_causal: If specified, applies a causal mask as attention mask. Mutually exclusive with providing attn_mask.\n",
    "          Default: ``False``.\n",
    "        - average_attn_weights: If true, indicates that the returned ``attn_weights`` should be averaged across\n",
    "          heads. Otherwise, ``attn_weights`` are provided separately per head. Note that this flag only has an\n",
    "          effect when ``need_weights=True.``. Default: True (i.e. average weights across heads)\n",
    "\n",
    "        - Outputs:\n",
    "        - attn_output: :math:`(L, N, E)` where L is the target sequence length, N is the batch size,\n",
    "          E is the embedding dimension. :math:`(N, L, E)` if ``batch_first`` is ``True``.\n",
    "        - attn_output_weights: If ``average_attn_weights=True``, returns attention weights averaged\n",
    "          across heads of shape :math:`(N, L, S)`, where N is the batch size, L is the target sequence length,\n",
    "          S is the source sequence length. If ``average_attn_weights=False``, returns attention weights per\n",
    "          head of shape :math:`(N, num_heads, L, S)`.\n",
    "        \"\"\"\n",
    "        return self._forward_impl(query, key, value, key_padding_mask,\n",
    "                                  need_weights, attn_mask, average_attn_weights,\n",
    "                                  is_causal)\n",
    "\n",
    "    def _forward_impl(self,\n",
    "                      query: Tensor,\n",
    "                      key: Tensor,\n",
    "                      value: Tensor,\n",
    "                      key_padding_mask: Optional[Tensor] = None,\n",
    "                      need_weights: bool = True,\n",
    "                      attn_mask: Optional[Tensor] = None,\n",
    "                      average_attn_weights: bool = True,\n",
    "                      is_causal: bool = False) -> Tuple[Tensor, Optional[Tensor]]:\n",
    "        # This version will not deal with the static key/value pairs.\n",
    "        # Keeping it here for future changes.\n",
    "        #\n",
    "        # TODO: This method has some duplicate lines with the\n",
    "        # `torch.nn.functional.multi_head_attention`. Will need to refactor.\n",
    "        static_k = None\n",
    "        static_v = None\n",
    "\n",
    "        if attn_mask is not None and is_causal:\n",
    "            raise AssertionError(\"Only allow causal mask or attn_mask\")\n",
    "\n",
    "        if is_causal:\n",
    "            raise AssertionError(\"causal mask not supported by AO MHA module\")\n",
    "\n",
    "        if self.batch_first:\n",
    "            query, key, value = (x.transpose(0, 1) for x in (query, key, value))\n",
    "\n",
    "        tgt_len, bsz, embed_dim_to_check = query.size()\n",
    "        assert self.embed_dim == embed_dim_to_check\n",
    "        # allow MHA to have different sizes for the feature dimension\n",
    "        assert key.size(0) == value.size(0) and key.size(1) == value.size(1)\n",
    "\n",
    "        head_dim = self.embed_dim // self.num_heads\n",
    "        assert head_dim * self.num_heads == self.embed_dim, \"embed_dim must be divisible by num_heads\"\n",
    "        scaling = float(head_dim) ** -0.5\n",
    "\n",
    "        q = self.linear_Q(query)\n",
    "        k = self.linear_K(key)\n",
    "        v = self.linear_V(value)\n",
    "\n",
    "        #JP fix here: disabled this\n",
    "        # q = self.q_scaling_product.mul_scalar(q, scaling)\n",
    "\n",
    "        if attn_mask is not None:\n",
    "            if attn_mask.dtype == torch.uint8:\n",
    "                warnings.warn(\"Byte tensor for attn_mask in nn.MultiheadAttention is deprecated. Use bool tensor instead.\")\n",
    "                attn_mask = attn_mask.to(torch.bool)\n",
    "            assert attn_mask.is_floating_point() or attn_mask.dtype == torch.bool, \\\n",
    "                f'Only float and bool types are supported for attn_mask, not {attn_mask.dtype}'\n",
    "\n",
    "            if attn_mask.dim() == 2:\n",
    "                attn_mask = attn_mask.unsqueeze(0)\n",
    "                if list(attn_mask.size()) != [1, query.size(0), key.size(0)]:\n",
    "                    raise RuntimeError('The size of the 2D attn_mask is not correct.')\n",
    "            elif attn_mask.dim() == 3:\n",
    "                if list(attn_mask.size()) != [bsz * self.num_heads, query.size(0), key.size(0)]:\n",
    "                    raise RuntimeError('The size of the 3D attn_mask is not correct.')\n",
    "            else:\n",
    "                raise RuntimeError(f\"attn_mask's dimension {attn_mask.dim()} is not supported\")\n",
    "            # attn_mask's dim is 3 now.\n",
    "\n",
    "        # convert ByteTensor key_padding_mask to bool\n",
    "        if key_padding_mask is not None and key_padding_mask.dtype == torch.uint8:\n",
    "            warnings.warn(\"Byte tensor for key_padding_mask in nn.MultiheadAttention is deprecated. Use bool tensor instead.\")\n",
    "            key_padding_mask = key_padding_mask.to(torch.bool)\n",
    "        if self.bias_k is not None and self.bias_v is not None:\n",
    "            if static_k is None and static_v is None:\n",
    "\n",
    "                # Explicitly assert that bias_k and bias_v are not None\n",
    "                # in a way that TorchScript can understand.\n",
    "                bias_k = self.bias_k\n",
    "                assert bias_k is not None\n",
    "                bias_v = self.bias_v\n",
    "                assert bias_v is not None\n",
    "\n",
    "                k = torch.cat([k, bias_k.repeat(1, bsz, 1)])\n",
    "                v = torch.cat([v, bias_v.repeat(1, bsz, 1)])\n",
    "                if attn_mask is not None:\n",
    "                    attn_mask = nnF.pad(attn_mask, (0, 1))\n",
    "                if key_padding_mask is not None:\n",
    "                    key_padding_mask = nnF.pad(key_padding_mask, (0, 1))\n",
    "            else:\n",
    "                assert static_k is None, \"bias cannot be added to static key.\"\n",
    "                assert static_v is None, \"bias cannot be added to static value.\"\n",
    "        else:\n",
    "            assert self.bias_k is None\n",
    "            assert self.bias_v is None\n",
    "\n",
    "        q = q.contiguous().view(tgt_len, bsz * self.num_heads, head_dim).transpose(0, 1)\n",
    "        if k is not None:\n",
    "            k = k.contiguous().view(-1, bsz * self.num_heads, head_dim).transpose(0, 1)\n",
    "        if v is not None:\n",
    "            v = v.contiguous().view(-1, bsz * self.num_heads, head_dim).transpose(0, 1)\n",
    "\n",
    "        if static_k is not None:\n",
    "            assert static_k.size(0) == bsz * self.num_heads\n",
    "            assert static_k.size(2) == head_dim\n",
    "            k = static_k\n",
    "\n",
    "        if static_v is not None:\n",
    "            assert static_v.size(0) == bsz * self.num_heads\n",
    "            assert static_v.size(2) == head_dim\n",
    "            v = static_v\n",
    "\n",
    "        src_len = k.size(1)\n",
    "\n",
    "        if key_padding_mask is not None:\n",
    "            assert key_padding_mask.size(0) == bsz\n",
    "            assert key_padding_mask.size(1) == src_len\n",
    "\n",
    "        if self.add_zero_attn:\n",
    "            src_len += 1\n",
    "            k_zeros = torch.zeros((k.size(0), 1) + k.size()[2:])\n",
    "            if k.is_quantized:\n",
    "                k_zeros = torch.quantize_per_tensor(k_zeros, k.q_scale(), k.q_zero_point(), k.dtype)\n",
    "            k = torch.cat([k, k_zeros], dim=1)\n",
    "            v_zeros = torch.zeros((v.size(0), 1) + k.size()[2:])\n",
    "            if v.is_quantized:\n",
    "                v_zeros = torch.quantize_per_tensor(v_zeros, v.q_scale(), v.q_zero_point(), v.dtype)\n",
    "            v = torch.cat([v, v_zeros], dim=1)\n",
    "\n",
    "            if attn_mask is not None:\n",
    "                attn_mask = nnF.pad(attn_mask, (0, 1))\n",
    "            if key_padding_mask is not None:\n",
    "                key_padding_mask = nnF.pad(key_padding_mask, (0, 1))\n",
    "\n",
    "        # Leaving the quantized zone here\n",
    "        q = self.dequant_q(q)\n",
    "        k = self.dequant_k(k)\n",
    "        v = self.dequant_v(v)\n",
    "        attn_output_weights = torch.bmm(q, k.transpose(1, 2))\n",
    "        assert list(attn_output_weights.size()) == [bsz * self.num_heads, tgt_len, src_len]\n",
    "\n",
    "        if attn_mask is not None:\n",
    "            if attn_mask.dtype == torch.bool:\n",
    "                attn_output_weights.masked_fill_(attn_mask, float('-inf'))\n",
    "            else:\n",
    "                attn_output_weights += attn_mask\n",
    "\n",
    "        if key_padding_mask is not None:\n",
    "            attn_output_weights = attn_output_weights.view(bsz, self.num_heads, tgt_len, src_len)\n",
    "            attn_output_weights = attn_output_weights.masked_fill(\n",
    "                key_padding_mask.unsqueeze(1).unsqueeze(2),\n",
    "                float('-inf'),\n",
    "            )\n",
    "            attn_output_weights = attn_output_weights.view(bsz * self.num_heads, tgt_len, src_len)\n",
    "\n",
    "        attn_output_weights = nnF.softmax(\n",
    "            attn_output_weights, dim=-1)\n",
    "        attn_output_weights = nnF.dropout(attn_output_weights, p=self.dropout, training=self.training)\n",
    "\n",
    "        attn_output = torch.bmm(attn_output_weights, v)\n",
    "        assert list(attn_output.size()) == [bsz * self.num_heads, tgt_len, head_dim]\n",
    "        if self.batch_first:\n",
    "            attn_output = attn_output.view(bsz, tgt_len, self.embed_dim)\n",
    "        else:\n",
    "            attn_output = attn_output.transpose(0, 1).contiguous().view(tgt_len, bsz, self.embed_dim)\n",
    "\n",
    "        # Reentering the quantized zone\n",
    "        attn_output = self.quant_attn_output(attn_output)\n",
    "        # for the type: ignore[has-type], see https://github.com/pytorch/pytorch/issues/58969\n",
    "        attn_output = self.out_proj(attn_output)  # type: ignore[has-type]\n",
    "\n",
    "        #JP fix: removed need_weights part from here, return attn_output instead of tuple\n",
    "        return attn_output\n",
    "\n",
    "class QuantizedMultiheadAttention(QuantizeableMultiheadAttention):\n",
    "    _FLOAT_MODULE = torch.ao.nn.quantizable.MultiheadAttention\n",
    "\n",
    "    def _get_name(self):\n",
    "        return \"QuantizedMultiheadAttention\"\n",
    "\n",
    "    @classmethod\n",
    "    def from_float(cls, other):\n",
    "        # The whole flow is float -> observed -> quantized\n",
    "        # This class does observed -> quantized only\n",
    "        raise NotImplementedError(\"It looks like you are trying to convert a \"\n",
    "                                  \"non-observed MHA module. Please, see \"\n",
    "                                  \"the examples on quantizable MHAs.\")\n",
    "\n",
    "    @classmethod\n",
    "    def from_observed(cls, other):\n",
    "        converted = torch.ao.quantization.convert(other, mapping=None,\n",
    "                                                  inplace=False,\n",
    "                                                  remove_qconfig=True,\n",
    "                                                  convert_custom_config_dict=None)\n",
    "        converted.__class__ = cls\n",
    "        # Remove the parameters for the bias_k and bias_v to quantize them\n",
    "        # TODO: This is a potential source of accuracy drop.\n",
    "        #       quantized cat takes the scale and zp of the first\n",
    "        #       element, which might lose the precision in the bias_k\n",
    "        #       and the bias_v (which are cat'ed with k/v being first).\n",
    "        if converted.bias_k is not None:\n",
    "            bias_k = converted._parameters.pop('bias_k')\n",
    "            sc, zp = torch._choose_qparams_per_tensor(bias_k,\n",
    "                                                      reduce_range=False)\n",
    "            bias_k = torch.quantize_per_tensor(bias_k, sc, zp, torch.quint8)\n",
    "            setattr(converted, 'bias_k', bias_k)  # noqa: B010\n",
    "\n",
    "        if converted.bias_v is not None:\n",
    "            bias_v = converted._parameters.pop('bias_v')\n",
    "            sc, zp = torch._choose_qparams_per_tensor(bias_k,  # type: ignore[possibly-undefined]\n",
    "                                                      reduce_range=False)\n",
    "            bias_v = torch.quantize_per_tensor(bias_v, sc, zp, torch.quint8)\n",
    "            setattr(converted, 'bias_v', bias_v)  # noqa: B010\n",
    "\n",
    "        del converted.in_proj_weight\n",
    "        del converted.in_proj_bias\n",
    "\n",
    "        return converted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e697d50c-8b91-42b5-ade2-9e9e23041001",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    \"\"\"Focal Loss, as described in https://arxiv.org/abs/1708.02002.\n",
    "    It is essentially an enhancement to cross entropy loss and is\n",
    "    useful for classification tasks when there is a large class imbalance.\n",
    "    x is expected to contain raw, unnormalized scores for each class.\n",
    "    y is expected to contain class labels.\n",
    "    Shape:\n",
    "        - x: (batch_size, C) or (batch_size, C, d1, d2, ..., dK), K > 0.\n",
    "        - y: (batch_size,) or (batch_size, d1, d2, ..., dK), K > 0.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, alpha = None, gamma = 0.0, reduction = \"mean\", ignore_index = -100\n",
    "    ):\n",
    "        \"\"\"Constructor.\n",
    "        Args:\n",
    "            alpha (Tensor, optional): Weights for each class. Defaults to None.\n",
    "            gamma (float, optional): A constant, as described in the paper.\n",
    "                Defaults to 0.\n",
    "            reduction (str, optional): 'mean', 'sum' or 'none'.\n",
    "                Defaults to 'mean'.\n",
    "            ignore_index (int, optional): class label to ignore.\n",
    "                Defaults to -100.\n",
    "        \"\"\"\n",
    "        if reduction not in (\"mean\", \"sum\", \"none\"):\n",
    "            raise ValueError('Reduction must be one of: \"mean\", \"sum\", \"none\".')\n",
    "\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "        self.nll_loss = nn.NLLLoss(weight=alpha, reduction=\"none\")\n",
    "\n",
    "    def __repr__(self):\n",
    "        arg_keys = [\"alpha\", \"gamma\", \"reduction\"]\n",
    "        arg_vals = [self.__dict__[k] for k in arg_keys]\n",
    "        arg_strs = [f\"{k}={v!r}\" for k, v in zip(arg_keys, arg_vals)]\n",
    "        arg_str = \", \".join(arg_strs)\n",
    "        return f\"{type(self).__name__}({arg_str})\"\n",
    "\n",
    "    def forward(self, x: Tensor, y: Tensor) -> Tensor:\n",
    "        if x.ndim > 2:\n",
    "            # (N, C, d1, d2, ..., dK) --> (N * d1 * ... * dK, C)\n",
    "            c = x.shape[1]\n",
    "            x = x.permute(0, *range(2, x.ndim), 1).reshape(-1, c)\n",
    "            # (N, d1, d2, ..., dK) --> (N * d1 * ... * dK,)\n",
    "            y = y.view(-1)\n",
    "\n",
    "        # compute weighted cross entropy term: -alpha * log(pt)\n",
    "        # (alpha is already part of self.nll_loss)\n",
    "        log_p = F.log_softmax(x, dim=-1)\n",
    "        ce = self.nll_loss(log_p, y)\n",
    "\n",
    "        # get true class column from each row\n",
    "        # this is slow due to indexing\n",
    "        # all_rows = torch.arange(len(x))\n",
    "        # log_pt = log_p[all_rows, y]\n",
    "        log_pt = torch.gather(log_p, 1, y.unsqueeze(axis=-1)).squeeze(axis=-1)\n",
    "\n",
    "        # compute focal term: (1 - pt)^gamma\n",
    "        pt = log_pt.exp()\n",
    "        focal_term = (1 - pt) ** self.gamma\n",
    "\n",
    "        # the full loss: -alpha * ((1 - pt)^gamma) * log(pt)\n",
    "        loss = focal_term * ce\n",
    "\n",
    "        if self.reduction == \"mean\":\n",
    "            loss = loss.mean()\n",
    "        elif self.reduction == \"sum\":\n",
    "            loss = loss.sum()\n",
    "\n",
    "        return loss\n",
    "\n",
    "class QuantizeFeaturesStub(torch.ao.quantization.QuantStub):\n",
    "    def __init__(self, num_feats):\n",
    "        super().__init__()\n",
    "        self.num_feats = num_feats\n",
    "        self.quants = torch.nn.ModuleList()\n",
    "        for ifeat in range(self.num_feats):\n",
    "            self.quants.append(torch.ao.quantization.QuantStub())\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.cat([self.quants[ifeat](x[..., ifeat:ifeat+1]) for ifeat in range(self.num_feats)], axis=-1)\n",
    "        \n",
    "def mlpf_loss(y, ypred, mask):\n",
    "    loss = {}\n",
    "    loss_obj_id = FocalLoss(gamma=2.0, reduction=\"none\")\n",
    "\n",
    "    msk_true_particle = torch.unsqueeze((y[\"cls_id\"] != 0).to(dtype=torch.float32), axis=-1)\n",
    "    nelem = torch.sum(mask)\n",
    "    npart = torch.sum(y[\"cls_id\"] != 0)\n",
    "    \n",
    "    ypred[\"momentum\"] = ypred[\"momentum\"] * msk_true_particle\n",
    "    y[\"momentum\"] = y[\"momentum\"] * msk_true_particle\n",
    "\n",
    "    ypred[\"cls_id_onehot\"] = ypred[\"cls_id_onehot\"].permute((0, 2, 1))\n",
    "\n",
    "    loss_classification = loss_obj_id(ypred[\"cls_id_onehot\"], y[\"cls_id\"]).reshape(y[\"cls_id\"].shape)\n",
    "    loss_regression = torch.nn.functional.huber_loss(ypred[\"momentum\"], y[\"momentum\"], reduction=\"none\")\n",
    "    \n",
    "    # average over all elements that were not padded\n",
    "    loss[\"Classification\"] = loss_classification.sum() / npart\n",
    "    \n",
    "    mom_normalizer = y[\"momentum\"][y[\"cls_id\"] != 0].std(axis=0)\n",
    "    reg_losses = loss_regression[y[\"cls_id\"] != 0]\n",
    "    # average over all true particles\n",
    "    loss[\"Regression\"] = (reg_losses / mom_normalizer).sum() / npart\n",
    "\n",
    "    px = ypred[\"momentum\"][..., 0:1] * ypred[\"momentum\"][..., 3:4] * msk_true_particle\n",
    "    py = ypred[\"momentum\"][..., 0:1] * ypred[\"momentum\"][..., 2:3] * msk_true_particle\n",
    "    pred_met = torch.sqrt(torch.sum(px, axis=-2) ** 2 + torch.sum(py, axis=-2) ** 2)\n",
    "\n",
    "    px = y[\"momentum\"][..., 0:1] * y[\"momentum\"][..., 3:4] * msk_true_particle\n",
    "    py = y[\"momentum\"][..., 0:1] * y[\"momentum\"][..., 2:3] * msk_true_particle\n",
    "    true_met = torch.sqrt(torch.sum(px, axis=-2) ** 2 + torch.sum(py, axis=-2) ** 2)\n",
    "    loss[\"MET\"] = torch.nn.functional.huber_loss(pred_met, true_met).mean()\n",
    "\n",
    "    loss[\"Total\"] = loss[\"Classification\"] + loss[\"Regression\"]\n",
    "    # loss[\"Total\"] += 0.1*loss[\"MET\"]\n",
    "    return loss\n",
    "    \n",
    "class SelfAttentionLayer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        embedding_dim=128,\n",
    "        num_heads=2,\n",
    "        width=128,\n",
    "        dropout_mha=0.1,\n",
    "        dropout_ff=0.1,\n",
    "        attention_type=\"efficient\",\n",
    "    ):\n",
    "        super(SelfAttentionLayer, self).__init__()\n",
    "\n",
    "        self.attention_type = attention_type\n",
    "        self.act = nn.ReLU\n",
    "        self.mha = torch.nn.MultiheadAttention(embedding_dim, num_heads, dropout=dropout_mha, batch_first=True)\n",
    "        self.norm0 = torch.nn.LayerNorm(embedding_dim)\n",
    "        self.norm1 = torch.nn.LayerNorm(embedding_dim)\n",
    "        self.seq = torch.nn.Sequential(\n",
    "            nn.Linear(embedding_dim, width), self.act(), nn.Linear(width, embedding_dim), self.act()\n",
    "        )\n",
    "        self.dropout = torch.nn.Dropout(dropout_ff)\n",
    "\n",
    "        self.add0 = torch.ao.nn.quantized.FloatFunctional()\n",
    "        self.add1 = torch.ao.nn.quantized.FloatFunctional()\n",
    "        self.mul = torch.ao.nn.quantized.FloatFunctional()\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        mha_out = self.mha(x, x, x, need_weights=False)[0]\n",
    "        x = self.add0.add(x, mha_out)\n",
    "        x = self.norm0(x)\n",
    "        x = self.add1.add(x, self.seq(x))\n",
    "        x = self.norm1(x)\n",
    "        x = self.dropout(x)\n",
    "        # x = self.mul.mul(x, mask.unsqueeze(-1))\n",
    "        return x\n",
    "\n",
    "class RegressionOutput(nn.Module):\n",
    "    def __init__(self, embed_dim, width, act, dropout):\n",
    "        super(RegressionOutput, self).__init__()\n",
    "        self.dequant = torch.ao.quantization.DeQuantStub()\n",
    "        self.nn = ffn(embed_dim, 1, width, act, dropout)\n",
    "\n",
    "    def forward(self, elems, x, orig_value):\n",
    "        nn_out = self.nn(x)\n",
    "        nn_out = self.dequant(nn_out)\n",
    "        return orig_value + nn_out\n",
    "\n",
    "def ffn(input_dim, output_dim, width, act, dropout):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(input_dim, width),\n",
    "        act(),\n",
    "        torch.nn.LayerNorm(width),\n",
    "        nn.Dropout(dropout),\n",
    "        nn.Linear(width, output_dim),\n",
    "    )\n",
    "\n",
    "def transform_batch(Xbatch):\n",
    "    Xbatch = Xbatch.clone()\n",
    "    Xbatch[..., 1] = torch.log(Xbatch[..., 1])\n",
    "    Xbatch[..., 5] = torch.log(Xbatch[..., 5])\n",
    "    Xbatch[torch.isnan(Xbatch)] = 0.0\n",
    "    Xbatch[torch.isinf(Xbatch)] = 0.0\n",
    "    return Xbatch\n",
    "    \n",
    "def unpack_target(y):\n",
    "    ret = {}\n",
    "    ret[\"cls_id\"] = y[..., 0].long()\n",
    "\n",
    "    for i, feat in enumerate(Y_FEATURES):\n",
    "        if i >= 2:  # skip the cls and charge as they are defined above\n",
    "            ret[feat] = y[..., i].to(dtype=torch.float32)\n",
    "    ret[\"phi\"] = torch.atan2(ret[\"sin_phi\"], ret[\"cos_phi\"])\n",
    "    \n",
    "    # note ~ momentum = [\"pt\", \"eta\", \"sin_phi\", \"cos_phi\", \"energy\"]\n",
    "    ret[\"momentum\"] = y[..., 2:7].to(dtype=torch.float32)\n",
    "    ret[\"p4\"] = torch.cat(\n",
    "        [ret[\"pt\"].unsqueeze(1), ret[\"eta\"].unsqueeze(1), ret[\"phi\"].unsqueeze(1), ret[\"energy\"].unsqueeze(1)], axis=1\n",
    "    )\n",
    "\n",
    "    return ret\n",
    "\n",
    "\n",
    "def unpack_predictions(preds):\n",
    "    ret = {}\n",
    "    ret[\"cls_id_onehot\"], ret[\"momentum\"] = preds\n",
    "\n",
    "    ret[\"pt\"] = ret[\"momentum\"][..., 0]\n",
    "    ret[\"eta\"] = ret[\"momentum\"][..., 1]\n",
    "    ret[\"sin_phi\"] = ret[\"momentum\"][..., 2]\n",
    "    ret[\"cos_phi\"] = ret[\"momentum\"][..., 3]\n",
    "    ret[\"energy\"] = ret[\"momentum\"][..., 4]\n",
    "\n",
    "    ret[\"cls_id\"] = torch.argmax(ret[\"cls_id_onehot\"], axis=-1)\n",
    "    ret[\"phi\"] = torch.atan2(ret[\"sin_phi\"], ret[\"cos_phi\"])\n",
    "    ret[\"p4\"] = torch.cat(\n",
    "        [\n",
    "            ret[\"pt\"].unsqueeze(axis=-1),\n",
    "            ret[\"eta\"].unsqueeze(axis=-1),\n",
    "            ret[\"phi\"].unsqueeze(axis=-1),\n",
    "            ret[\"energy\"].unsqueeze(axis=-1),\n",
    "        ],\n",
    "        axis=-1,\n",
    "    )\n",
    "\n",
    "    return ret\n",
    "\n",
    "class MLPF(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim=16,\n",
    "        num_classes=6,\n",
    "        num_convs=2,\n",
    "        dropout_ff=0.0,\n",
    "        dropout_conv_reg_mha=0.0,\n",
    "        dropout_conv_reg_ff=0.0,\n",
    "        dropout_conv_id_mha=0.0,\n",
    "        dropout_conv_id_ff=0.0,\n",
    "        num_heads=16,\n",
    "        head_dim=16,\n",
    "        elemtypes=[0,1,2],\n",
    "    ):\n",
    "        super(MLPF, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.act = nn.ReLU\n",
    "        self.elemtypes = elemtypes\n",
    "        self.num_elemtypes = len(self.elemtypes)\n",
    "\n",
    "        embedding_dim = num_heads * head_dim\n",
    "        width = num_heads * head_dim\n",
    "        \n",
    "        self.nn0_id = ffn(self.input_dim, embedding_dim, width, self.act, dropout_ff)\n",
    "        self.nn0_reg = ffn(self.input_dim, embedding_dim, width, self.act, dropout_ff)\n",
    "        \n",
    "        self.conv_id = nn.ModuleList()\n",
    "        self.conv_reg = nn.ModuleList()\n",
    "\n",
    "        for i in range(num_convs):\n",
    "            self.conv_id.append(\n",
    "                SelfAttentionLayer(\n",
    "                    embedding_dim=embedding_dim,\n",
    "                    num_heads=num_heads,\n",
    "                    width=width,\n",
    "                    dropout_mha=dropout_conv_id_mha,\n",
    "                    dropout_ff=dropout_conv_id_ff,\n",
    "                )\n",
    "            )\n",
    "            self.conv_reg.append(\n",
    "                SelfAttentionLayer(\n",
    "                    embedding_dim=embedding_dim,\n",
    "                    num_heads=num_heads,\n",
    "                    width=width,\n",
    "                    dropout_mha=dropout_conv_reg_mha,\n",
    "                    dropout_ff=dropout_conv_reg_ff,\n",
    "                )\n",
    "            )\n",
    "\n",
    "        decoding_dim = self.input_dim + embedding_dim\n",
    "\n",
    "        # DNN that acts on the node level to predict the PID\n",
    "        self.nn_id = ffn(decoding_dim, num_classes, width, self.act, dropout_ff)\n",
    "\n",
    "        # elementwise DNN for node momentum regression\n",
    "        embed_dim = decoding_dim + num_classes\n",
    "        self.nn_pt = RegressionOutput(embed_dim, width, self.act, dropout_ff)\n",
    "        self.nn_eta = RegressionOutput(embed_dim, width, self.act, dropout_ff)\n",
    "        self.nn_sin_phi = RegressionOutput(embed_dim, width, self.act, dropout_ff)\n",
    "        self.nn_cos_phi = RegressionOutput(embed_dim, width, self.act, dropout_ff)\n",
    "        self.nn_energy = RegressionOutput(embed_dim, width, self.act, dropout_ff)\n",
    "        \n",
    "        self.quant = QuantizeFeaturesStub(self.input_dim + len(self.elemtypes))\n",
    "        self.dequant_id = torch.ao.quantization.DeQuantStub()\n",
    "\n",
    "    def forward(self, X_features, mask):\n",
    "        Xfeat_transformed = transform_batch(X_features)\n",
    "        Xfeat_normed = self.quant(Xfeat_transformed)\n",
    "\n",
    "        embeddings_id, embeddings_reg = [], []\n",
    "        embedding_id = self.nn0_id(Xfeat_normed)\n",
    "        embedding_reg = self.nn0_reg(Xfeat_normed)\n",
    "        for num, conv in enumerate(self.conv_id):\n",
    "            conv_input = embedding_id if num == 0 else embeddings_id[-1]\n",
    "            out_padded = conv(conv_input, mask)\n",
    "            embeddings_id.append(out_padded)\n",
    "        for num, conv in enumerate(self.conv_reg):\n",
    "            conv_input = embedding_reg if num == 0 else embeddings_reg[-1]\n",
    "            out_padded = conv(conv_input, mask)\n",
    "            embeddings_reg.append(out_padded)\n",
    "\n",
    "        final_embedding_id = torch.cat([Xfeat_normed] + [embeddings_id[-1]], axis=-1)\n",
    "        preds_id = self.nn_id(final_embedding_id)\n",
    "\n",
    "        final_embedding_reg = torch.cat([Xfeat_normed] + [embeddings_reg[-1]] + [preds_id], axis=-1)\n",
    "        preds_pt = self.nn_pt(X_features, final_embedding_reg, X_features[..., 1:2])\n",
    "        preds_eta = self.nn_eta(X_features, final_embedding_reg, X_features[..., 2:3])\n",
    "        preds_sin_phi = self.nn_sin_phi(X_features, final_embedding_reg, X_features[..., 3:4])\n",
    "        preds_cos_phi = self.nn_cos_phi(X_features, final_embedding_reg, X_features[..., 4:5])\n",
    "        preds_energy = self.nn_energy(X_features, final_embedding_reg, X_features[..., 5:6])\n",
    "        preds_momentum = torch.cat([preds_pt, preds_eta, preds_sin_phi, preds_cos_phi, preds_energy], axis=-1)\n",
    "        \n",
    "        preds_id = self.dequant_id(preds_id)\n",
    "        return preds_id, preds_momentum\n",
    "\n",
    "model = MLPF(input_dim=INPUT_DIM, num_classes=NUM_CLASSES)\n",
    "optimizer = torch.optim.Adam(lr=1e-4, params=model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4721f1c7-b501-4757-982b-fa2194cf6176",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28fc87e0-5b18-4c44-a67e-ce2792b567de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [00:21<00:00,  1.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, loss=1.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [00:03<00:00,  6.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, loss=1.42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [00:03<00:00,  6.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, loss=1.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [00:03<00:00,  6.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, loss=1.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [00:03<00:00,  6.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, loss=0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [00:03<00:00,  6.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, loss=0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [00:03<00:00,  6.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, loss=0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [00:03<00:00,  5.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, loss=0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [00:03<00:00,  5.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, loss=0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [00:03<00:00,  6.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, loss=0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "max_events_train = 1000\n",
    "max_events_eval = 1000\n",
    "events_per_batch = 50\n",
    "nepochs = 10\n",
    "\n",
    "model = MLPF(input_dim=INPUT_DIM, num_classes=NUM_CLASSES).to(device=device)\n",
    "optimizer = torch.optim.Adam(lr=1e-4, params=model.parameters())\n",
    "\n",
    "#Training loop\n",
    "loss_vals_epochs = []\n",
    "for epoch in range(nepochs):\n",
    "    loss_vals_steps = []\n",
    "    inds_train = range(0,max_events_train,events_per_batch)\n",
    "    for ind in tqdm.tqdm(inds_train):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        #load the data for one batch\n",
    "        ds_elems = [ds_train[i] for i in range(ind,ind+events_per_batch)]\n",
    "        X_features = [torch.tensor(elem[\"X\"]).to(torch.float32) for elem in ds_elems]\n",
    "        y_targets = [torch.tensor(elem[\"ygen\"]).to(torch.float32) for elem in ds_elems]\n",
    "\n",
    "        #batch the data into [batch_size, num_elems, num_features]\n",
    "        X_features_padded = pad_sequence(X_features, batch_first=True).to(device=device)\n",
    "        y_targets_padded = pad_sequence(y_targets, batch_first=True).to(device=device)\n",
    "        mask = X_features_padded[:, :, 0]!=0\n",
    "\n",
    "        #run the model\n",
    "        preds = model(X_features_padded, mask)\n",
    "        preds_unpacked = unpack_predictions(preds)\n",
    "        targets_unpacked = unpack_target(y_targets_padded)\n",
    "\n",
    "        #compute loss, update model weights\n",
    "        loss = mlpf_loss(targets_unpacked, preds_unpacked, mask)\n",
    "        loss[\"Total\"].backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        loss_vals_steps.append(loss[\"Total\"].detach().cpu().item())\n",
    "\n",
    "    loss_vals_epochs.append(np.mean(loss_vals_steps))\n",
    "    print(\"Epoch {}, loss={:.2f}\".format(epoch, loss_vals_epochs[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fd8787e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(losses)\n",
    "# plt.xlabel('Iteration')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.title('Training Loss Curve')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b437405-87f1-409e-9ab9-ff79af3e1cd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f1dd1a47640>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_vals_epochs, label=\"training loss\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d11c05-a019-46b1-aff6-07d9e6565c5c",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4149d6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#put the model back on CPU\n",
    "model = model.to(device=\"cpu\")\n",
    "\n",
    "all_preds = []\n",
    "all_targets = []\n",
    "\n",
    "ds_elems = [ds_train[i] for i in range(max_events_train, max_events_train + max_events_eval)]\n",
    "\n",
    "# Define batch size\n",
    "batch_size = 32  \n",
    "for i in range(0, len(ds_elems), batch_size):\n",
    "    batch_elems = ds_elems[i:i + batch_size]\n",
    "\n",
    "    # input features\n",
    "    X_features = [torch.tensor(elem[\"X\"]).to(torch.float32) for elem in batch_elems]\n",
    "    X_features_padded = pad_sequence(X_features, batch_first=True)\n",
    "\n",
    "    #  target labels\n",
    "    y_targets = [torch.tensor(elem[\"ygen\"]).to(torch.float32) for elem in batch_elems]\n",
    "    y_targets_padded = pad_sequence(y_targets, batch_first=True)\n",
    "\n",
    "    #  mask for the batch\n",
    "    mask = X_features_padded[:, :, 0] != 0\n",
    "\n",
    "    #  model prediction, loss computation\n",
    "    preds = model(X_features_padded, mask)\n",
    "    preds = preds[0].detach(), preds[1].detach()\n",
    "\n",
    "    # Update mask for the batch\n",
    "    mask = X_features_padded[:, :, 0] != 0\n",
    "\n",
    "    # Unpack predictions and targets for the batch\n",
    "    preds_unpacked = unpack_predictions(preds)\n",
    "    targets_unpacked = unpack_target(y_targets_padded)\n",
    "    \n",
    "    # append to a list \n",
    "    all_preds.append(preds_unpacked)\n",
    "    all_targets.append(targets_unpacked)\n",
    "    \n",
    "    \n",
    "\n",
    "    # Compute loss for the batch\n",
    "    loss = mlpf_loss(targets_unpacked, preds_unpacked, mask)\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03029dbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ab70010",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Classification': tensor(0.5378),\n",
       " 'Regression': tensor(0.2856),\n",
       " 'MET': tensor(11.9503),\n",
       " 'Total': tensor(0.8234)}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb31372b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt = [data['pt'] for data in all_preds]\n",
    "# pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "508ad615-a40e-49b5-a159-34fb564053dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds_elems = [ds_train[i] for i in range(max_events_train,max_events_train+max_events_eval)]\n",
    "# X_features = [torch.tensor(elem[\"X\"]).to(torch.float32) for elem in ds_elems]\n",
    "# X_features_padded = pad_sequence(X_features, batch_first=True)\n",
    "# y_targets = [torch.tensor(elem[\"ygen\"]).to(torch.float32) for elem in ds_elems]\n",
    "# y_targets_padded = pad_sequence(y_targets, batch_first=True)\n",
    "# mask = X_features_padded[:, :, 0]!=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f61b28d5-29d0-4b5d-9468-9a385b814faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preds = model(X_features_padded, mask)\n",
    "# preds = preds[0].detach(), preds[1].detach()\n",
    "# mask = X_features_padded[:, :, 0:1] != 0\n",
    "# preds_unpacked = unpack_predictions(preds)\n",
    "# targets_unpacked = unpack_target(y_targets_padded)\n",
    "\n",
    "# loss = mlpf_loss(targets_unpacked, preds_unpacked, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4e93a0dd-77cb-4325-9fc1-b9da22b2b508",
   "metadata": {},
   "outputs": [],
   "source": [
    "msk_true_particles = targets_unpacked[\"cls_id\"]!=0\n",
    "\n",
    "pt_target = targets_unpacked[\"pt\"][msk_true_particles].numpy()\n",
    "pt_pred = preds_unpacked[\"pt\"][msk_true_particles].numpy()\n",
    "\n",
    "eta_target = targets_unpacked[\"eta\"][msk_true_particles].numpy()\n",
    "eta_pred = preds_unpacked[\"eta\"][msk_true_particles].numpy()\n",
    "\n",
    "sphi_target = targets_unpacked[\"sin_phi\"][msk_true_particles].numpy()\n",
    "sphi_pred = preds_unpacked[\"sin_phi\"][msk_true_particles].numpy()\n",
    "\n",
    "cphi_target = targets_unpacked[\"cos_phi\"][msk_true_particles].numpy()\n",
    "cphi_pred = preds_unpacked[\"cos_phi\"][msk_true_particles].numpy()\n",
    "\n",
    "energy_target = targets_unpacked[\"energy\"][msk_true_particles].numpy()\n",
    "energy_pred = preds_unpacked[\"energy\"][msk_true_particles].numpy()\n",
    "\n",
    "px = preds_unpacked[\"pt\"] * preds_unpacked[\"cos_phi\"] * msk_true_particles\n",
    "py = preds_unpacked[\"pt\"] * preds_unpacked[\"sin_phi\"] * msk_true_particles\n",
    "pred_met = torch.sqrt(torch.sum(px, axis=-2) ** 2 + torch.sum(py, axis=-2) ** 2)\n",
    "\n",
    "px = targets_unpacked[\"pt\"] * targets_unpacked[\"cos_phi\"] * msk_true_particles\n",
    "py = targets_unpacked[\"pt\"] * targets_unpacked[\"sin_phi\"] * msk_true_particles\n",
    "true_met = torch.sqrt(torch.sum(px, axis=-2) ** 2 + torch.sum(py, axis=-2) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "864ee0fb-257d-48fc-8c52-d07cb6895395",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'pred MET')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(true_met, pred_met, marker=\".\")\n",
    "plt.xlabel(\"true MET\")\n",
    "plt.ylabel(\"pred MET\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "00ca5eaa-86b6-410a-bd72-3a69134d9e1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(pred_met/true_met, bins=np.linspace(0,20,100));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5b100969-4eb0-4eff-ae28-4d4f17a559f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'pred pt')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "b = np.logspace(-1,2,100)\n",
    "plt.hist2d(\n",
    "    pt_target,\n",
    "    pt_pred,\n",
    "    bins=(b,b)\n",
    ")\n",
    "plt.xscale(\"log\")\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"true pt\")\n",
    "plt.ylabel(\"pred pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8d5ef494-527e-447b-9023-79b1a1245909",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'pred eta')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "b = np.linspace(-4,4,100)\n",
    "plt.hist2d(\n",
    "    eta_target,\n",
    "    eta_pred,\n",
    "    bins=(b,b)\n",
    ")\n",
    "plt.xlabel(\"true eta\")\n",
    "plt.ylabel(\"pred eta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "460019b7-9971-4556-a644-342cc29a94a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'pred sphi')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "b = np.linspace(-1,1,100)\n",
    "plt.hist2d(\n",
    "    sphi_target,\n",
    "    sphi_pred,\n",
    "    bins=(b,b)\n",
    ")\n",
    "plt.xlabel(\"true sphi\")\n",
    "plt.ylabel(\"pred sphi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f4be3453-73ad-49ea-b50f-d1e8286c067e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'pred cphi')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "b = np.linspace(-1,1,100)\n",
    "plt.hist2d(\n",
    "    cphi_target,\n",
    "    cphi_pred,\n",
    "    bins=(b,b)\n",
    ")\n",
    "plt.xlabel(\"true cphi\")\n",
    "plt.ylabel(\"pred cphi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "04008e59-081c-41e7-93db-79ac0bd9da7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'pred energy')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZMAAAEQCAYAAAB1OJkXAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAAsTAAALEwEAmpwYAAAZOUlEQVR4nO3dfZBddX3H8c+HhBUS5Bl05EFCjGgGn6oSBR/wcSIacVRGoq2DMARH0RbHVqy2WK1VsTNYBItRkfqEIjrKagwjrYoiLVFEQSBCg0hKJYqKFJAY/PaPe3f33Mves+fec849D/f9msnsed7v7mH53u/5PRxHhAAAyGOnqgMAADQfyQQAkBvJBACQG8kEAJAbyQQAkBvJBACQG8kEAJAbyQQAkFvtk4ntl9n+mO2v2n5h1fEAAB6skmRi+3zb22xf17d9te3Ntm+2fbokRcRXIuJkSSdIelUF4QIAFlBVZXKBpNXJDbYXSTpX0oskrZS01vbKxCHv7O4HANRMJckkIi6X9Ju+zUdIujkitkTEdkmfl3SsOz4g6RsRcfW4YwUALGxx1QEkHCDptsT6VkmrJL1J0vMl7WH7URFx3nwn214naZ0kLdKiJy/R7iWHCwDtcbd+++uI2G/U8+uUTDzPtoiIsyWdvdDJEbFe0npJ2t17xyo/r+DwAKC9LouLb81zfp16c22VdFBi/UBJt1cUCwBgCHVKJpskrbC9zPaUpOMlXTLMBWyvsb1+h7aXEiAAYH5VdQ2+UNKVkg6zvdX2SRGxQ9Kpki6VdIOkiyLip8NcNyKmI2LdYk0VHzTQcosPe9TsP2BYlbSZRMTaAds3SNow5nAAADnVqQEeQIV2bL656hDQYK1KJrbXSFqzq5ZWHQoATJQ6NcDnRpsJAFSjVckEAFANkgkAIDfaTAAAubWqMqHNBACq0apkAgCoBskEAJAbyQQAkBsN8ACA3FqVTCJiWtL07t775KpjAYC8+ifdrPOUNzzmAgDk1qrKBACaKFmBJKuPOlci/ahMAAC5taoyoQEeAKrRqsqEEfAAUI1WJRMAQDVa9ZgLAJqoSQ3tg1CZAAByI5kAAHIjmQAAcmtVmwldgwGgGq2qTOgaDADVaFUyAQBUg2QCAMiNZAIAyK1VDfAAUIb+94oktWHAYRGoTAAAuVGZAMAQqETmR2UCAMitVZUJgxYBoBqtqkwYtAgA1WhVZQIAo9q++qk961MbN80u006ysFZVJgCAalCZAGi8/nEggyqJtPEiSlQiGB6VCQAgNyoTAI1XRptGsoqhzWRhVCYAgNxIJgCA3HjMBaDVRp2kkUdbw6EyAQDkRmUCoHWyNp7TyF4cKhMAQG6tqkyY6BGYTHeecmTP+j4f/X6m86hGitOqyoSJHgGgGq2qTAA0X1o7xqB9WSsRlKdVlQkAoBpUJgByKbpHFGM/monKBACQG8kEAJAbj7mAhqrLgLsyv3fa2w9RL1QmAIDcqEyAhmprY3SyGkmrREadwBHloDIBAORGZQKgUg+qMDK2i1B91AuVCQAgNyoTAGORrEDuXbbX7PL2vuOmNo8pIBSKygQAkBuVCYCx2PLq/WeXD/3cttll2j7agcoEAJAbyQQAkFvtH3PZPlTSOyTtERGvrDoeoK2Knp6lv8svj7barZLKxPb5trfZvq5v+2rbm23fbPt0SYqILRFxUhVxAgCyqaoyuUDSOZI+NbPB9iJJ50p6gaStkjbZviQirq8kQmAEdZl8cRRFxNszMSOTMk6USiqTiLhc0m/6Nh8h6eZuJbJd0uclHTv24AAAQ6tTm8kBkm5LrG+VtMr2PpLeK+lJtt8eEe+b72Tb6yStk6RdtKTsWIF51b0a6W/HGCXe/mnh73vz72aX9ziGamRS1SmZeJ5tERF3Snr9QidHxHpJ6yVpd+8dBccGAEhRp2SyVdJBifUDJd1eUSylKuLTITCKMv5b2+e0xGe3BrcZIZ86jTPZJGmF7WW2pyQdL+mSYS5ge43t9TseNNsPAKBMlVQmti+UdLSkfW1vlXRGRHzC9qmSLpW0SNL5EfHTYa4bEdOSpnf33icXHXOR+MSWXZN7R7XJXRtWzC73t4vsGHcwqKVKkklErB2wfYOkDWMOBwCQU50ecwEAGmrBysT24RFx3ULH1YHtNZLW7KqlVYeCgozz0VaTH6kVEXvyGskZfiXp0NMSU6GMdPXqNPm+NkmWyuQ821fZfoPtPcsOKI+ImI6IdYs1VXUoADBRFqxMIuIZtldIOlHSD2xfJemTEfHN0qMDxqjJn1qLiP3Os+aGeh18zPd7r5/xGlmrgHFWC02+r02Sqc0kIm6S9E5Jb5P0bEln277R9svLDA4A0AxZ2kweL+l1kl4s6ZuS1kTE1bYfIelKSV8uN8TsaDPBpBqlIpB620b6q5FRZK0CqBbaJ0tlco6kH0l6QkS8MSKulqSIuF2daqU2aDMBgGpkaTN5Vsq+TxcbDoBRZK1Gku0iUjHVCCBle8x1raT+iRPvkvQDSf/YnYgRADDBsoyA/4akByR9rrt+fPfr79V5ydWa4sMCUJR7l+01u9w/FQpjMFCULMnkqIg4KrF+re0rIuIo239eVmCjoAEeAKqRpQF+N9urZlZsHyFpt+5qrQbD0gAPANXIUpmcJOmTtmcSyN2STrK9VNK8bz0EMF7Jtx/+8uk79+w7+IzBjezJR1s88kIeqcnE9iJJz4yIx9neQ5Ij4neJQy4qMzgAQDOkJpOIeMD2sZLOioi7xhQTMNGyVgiDqpG0SiQN1QjyyPKY6wrb50j6gqR7ZjbODF4EACBLMjmy+/XdiW0h6bnFh5MPvbnQBlkrhCW3/HZ2+eCNc+ckKxZJmtrY2x0YKEOWEfDPGUcgRWjKa3sBoG2yjIB/mKR/kvSIiHiR7ZWSnh4Rnyg9OqBE/ZMe1rHNIO2FVYPaRqhEUIUs40wukHSppEd0138m6a9KigcA0EBZ2kz2jYiLbL9dkiJih+0HSo4LKMyg3lF1rET63fA3c1OhPPbMbT37ajViGBMvS2Vyj+191J3s0fbT1JnoEQAASdkqk7dIukTScttXSNpP0itLjQoA0ChZenNdbfvZkg6TZEmbI+KPpUc2AroGYz51fJyVNjDxtP++YW75M0cOPC7LtYc5D8gjS2UiSUdIOqR7/J/ZVkR8qrSoRkTXYACoRpauwZ+WtFzSNeq810TqtJ/ULpkAdZVWLdx5ypE9+85aPrd8sLJNjcIkjahalsrkKZJWRkT/2xYBAJCULZlcJ+nhkv635FiAzJrWLpDWLvLhY/p+lgKuD4xbpnEmkq63fZWk+2c2RsRLS4sKANAoWZLJu8oOAhhWXT+J91dMM960Ybpn/QNvfO3cyrLeY6c2Z7t2XX8HmExZugZ/x/YjJa2IiMtsL5G0qPzQAABNkaU318mS1knaW51eXQdIOk/S88oNDainrD2nklOhnLX8sT37pjT8ZIxUIqizLNOpvFHSUZJ+L0kRcZOk/VPPqIjtNbbX79D2qkMBgImSJZncHxGz/3e2vVjdebrqJiKmI2LdYk1VHQoATJQsDfDfsf23kna1/QJJb5A0vcA5wFiNc9Be2vUf/bmfzx335MHHMcgQbZOlMjld0q8kXSvpFEkbJL2zzKAAAM2SpTfXnyR9rPsPqKWiP90P6uLbL1mJSNLPXn1IYm0uJrr1ou2yVCYAAKTKOmswMLHuXbZXz/ovn77z7PId63s7Nu6zeW5ixja1i7TpZ0E5qEwAALkNrExsTyulCzBzc6HNtrx6ruJ4+JW974I7+Iy56mP76qcOvEabPsG36WdBOdIec/1z9+vL1Zk1+DPd9bWSfl5iTACAhhmYTCLiO5Jk+z0R8azErmnbl5ceGVCy/h5Wdxw9V43s8dRfze24cs+B11hyy2971keZPp6eXmiDLG0m+9k+dGbF9jJJ+5UXEgCgabL05jpN0rdtb+muH6LO4EUAACRlG7S40fYKSY/pbroxIu5PO6cqttdIWrOrllYdSukm/dFIET9/8rGWJN3ziLnlQ09L9j3J/ygrTdbYJ/2eo94WfMzVfX/JX0s6NSJ+LOlg2y8pPbIRMNEjAFQjy2OuT0r6oaSnd9e3SvqipK+VFRQWNumfSkf9+e885cjZ5d8c0dvl9yFb5wYjJq+fNrXKOO/DpN9z1FuWBvjlEXGmpD9KUkTcJ8mlRgUAaJQslcl227uqO4DR9nJJtWwzweToHyw4tXHwmwuTlUWyGnnkF3uPW3LLttnlZLvIMBUB045gUmVJJmdI2ijpINufVeetiyeUGRQAoFlSk4ntnSTtpc4o+Kep83jrLyPi12OIDRiof7CgUiqCr3/rS7PLL37OKwZes4hKYpRr0EsLbZCaTCLiT7ZPjYiLJH19TDEBABrGEemvc7f9d5Luk/QFSffMbI+I35Qb2uh2996xys+rOgwkjPrpO2sbRLIN5dbjevf1t43MSGtnASbNZXHxDyPiKaOen6XN5MTu1zcmtoWkQ+c5FgAwgbKMgF82jkAAAM21YDKxvYukN0h6hjoVyXclnRcRfyg5NrRI1sdaD3o/yIBHUb/4hyN71pPvHFlxUu85gx6V0fANFCfLY65PSbpb0oe762slfVrScQPPAABMlCzJ5LCIeEJi/Vu2f1xWQJNu0ge9pTWKJ6uWpbf37kt2Fe6fiHHQ73ESf79AWbJMp/Ij20+bWbG9StIV5YUEAGiaLJXJKkmvtf2L7vrBkm6wfa2kiIjHlxbdBJr0T8v9bSZ3P3Ju8sXkVCiPPXObspr0ag8YhyzJZHXpUQAAGi1L1+BbxxEIID14mpT73jw3QfXeXx38tui0ioNqBChflsqkUraXSvqIpO2Svh0Rn604JABAn0qSie3zJb1E0raIODyxfbWkf5G0SNLHI+L96kwyeXFETNv+giSSSUMk2z/Semn1jxlJevjZc+0kUxu/P7ejb4wI7SJAtbL05irDBepri7G9SNK5kl4kaaWktbZXSjpQ0m3dwx4YY4wAgIwqSSYRcbmk/okij5B0c0RsiYjtkj4v6Vh1XhN8YPeYqpIfACBFndpMDtBcBSJ1ksgqSWdLOsf2iyVNDzrZ9jpJ6yRpFy0pMczJM+q0I8lHW/3XuOPo/WeXV7/kqtnl65/cO+Sw5/FVSgxp72kHUL46JZP53isfEXGPpNctdHJErJe0XupMQV9wbACAFHVKJlslHZRYP1DS7QOOLcQkNNoWMZlh2b+bZDXSH++9y/aaXZ7aPPgabb1/QFPUqQ1ik6QVtpfZnpJ0vKRLhrmA7TW21+/Q9lICBADMb8E3LZbyTe0LJR0taV9Jd0g6IyI+YfsYSR9Sp2vw+RHx3lGuz5sW6yFZZSQrDKl3mpSH3jrX/bd/0OKgKeP7r8dbE4F8xvGmxcJFxNoB2zdI2jDmcAAAOdWpzaQw3uUhWnxI51Msz9LHp3+SxjsT1cc+H/1+z76HDagysk6LktZ+AmD8WpVMbK+RtGbJzntWHQoATJRK2kzK1tY2kzr2PktWI7f2vXsz+frctF5a/e0kSYPaTOry8wNtkbfNpE69uQAADUUyAQDk1so2k121tOpQSjHORztpM/7eecrcLL/Jbr3Jx1r9+mNPNqD3v7M9adCjrSIGYwIoTqsqk4iYjoh1izVVdSgAMFFaVZmMQ5s+Eac1aCerkZU/7P3P5Jp3/HHe45IVi9RbtYw6qHDQ77fJv3egjVpVmQAAqkHX4JqpS/fXUaZ0T4u3TRUd0EaNnE6lLG1vgAeAumpVMomIaUnTu3vvk6uOZVRlf2IfVPn0t3ckpz8p4sVTVCJAu9FmAgDIrVWVCTrS2l2S68mxJMmeVwtdY9Bxw8QBoF2oTAAAubWqMpnkBvi8VUD/OJC0Uek9x2WcMr4fVQvQLq2qTBgBDwDVaFUyAQBUo1WPuSbZoEdFaV1+R53iJG0SyKx4tAW0C5UJACA3KpMKlD21SPL6D/v2tt7vlVgetcIYtRoB0F5UJgCA3FpVmRTZNbjMrqtFXC9tsOAdR+8/u5xsI+k3aoVBt14A/VpVmdA1GACq0arKpEh1+MSdVn30x5c8Nq0ayfq9Rh2MCGAytaoyAQBUg8qkxoapAEapFmj7AFAUKhMAQG4kEwBAbjzmGpMiHikVfQ0AKAqVCQAgt1ZVJjODFpfsvKcWL+98Ai+7Csh6XHLfMF1+s+4bBY3uAIrSqspkdtDiol2qDgUAJkqrKpMZ8Yf7c3/qznr+KBXHvcv2Gnjc1OZM33Zkg36usiefBNBurapMAADVaGVlUpWsn+aX3PLbwddILI/atjIKKhEAeVCZAAByozKpwKhVQFr7DJUFgCpRmQAAciOZAABya/1jrlEGH6Ydm3Zc8p3qUm9De9GPqIoYSAkARaEyAQDk1vrKZJTBh6Me1/9O9R0Djhv1e1FxAKgrKhMAQG6tqkxmJnrcVUurDqUURVdZAFCUVlUmsxM9aqrqUABgorSqMikS7RMAkF2rKhMAQDUmujJJqz6qqkaKHhcDAONAZQIAyI1kAgDIbaIfc43TKO+KT8NjLQB1QmUCAMhtoiuTcX66z/q90ioYuisDqCsqEwBAbhNdmdRREe0pADBuVCYAgNxIJgCA3EgmAIDcSCYAgNxIJgCA3EgmAIDcap9MbB9q+xO2L646FgDA/EpNJrbPt73N9nV921fb3mz7Ztunp10jIrZExEllxgkAyKfsQYsXSDpH0qdmNtheJOlcSS+QtFXSJtuXSFok6X19558YEdtKjnFBTGMCAOlKTSYRcbntQ/o2HyHp5ojYIkm2Py/p2Ih4n6SXlBkPAKAcVUyncoCk2xLrWyWtGnSw7X0kvVfSk2y/vZt05jtunaR13dX7L4uLr5vvuJHcONJZe0i6q7AYRr/eMOdlOTbtmEH7htm+r6RfLxDDONTh/o3z3qXtb9r9q8O9G/a8sv72Bu2bb9thC3z/dBFR6j9Jh0i6LrF+nKSPJ9b/QtKHC/6ePyj758oQw/o6XG+Y87Icm3bMoH3DbK/DvavL/RvnvWvT/avDvRv3/Rt2Xxn3roreXFslHZRYP1DS7RXEUbbpmlxvmPOyHJt2zKB9w26vgzrcv3Heu7T9Tbt/dbh3w55X1t/eoH2F3zt3M1Jpum0mX4uIw7vriyX9TNLzJP2PpE2SXh0RPy3we/4gIp5S1PUwPty7ZuP+NVfee1d21+ALJV0p6TDbW22fFBE7JJ0q6VJJN0i6qMhE0rW+4OthfLh3zcb9a65c9670ygQA0H61HwEPAKg/kgkAIDeSCQAgt4lKJkwa2Ty2l9r+N9sfs/2aquPBcPibay7bL+v+3X3V9gsXOr4xyYRJI9tjyHv5ckkXR8TJkl469mDxIMPcP/7m6mXIe/eV7t/dCZJetdC1G5NM1Jk0cnVyQ2LSyBdJWilpre2Vth9n+2t9//Yff8gY4AJlvJfqDGqdmX7ngTHGiMEuUPb7h3q5QMPfu3d296eqYm6ukQSTRrbGMPdSnRkTDpR0jZr14ae1hrx/1485PKQY5t7ZvkHS+yV9IyKuXujaTf/jnG/SyAMGHWx7H9vnqTtpZNnBYSiD7uWXJb3C9r+qvtN3YMD942+uEQb97b1J0vMlvdL26xe6SGMqkwE8z7aBozAj4k5JC/5SUIl572VE3CPpdeMOBkMbdP/4m6u/QffubElnZ71I0yuTSZk0chJwL5uN+9dchdy7pieTTZJW2F5me0rS8ZIuqTgmjIZ72Wzcv+Yq5N41JplUOGkkCsa9bDbuX3OVee+Y6BEAkFtjKhMAQH2RTAAAuZFMAAC5kUwAALmRTAAAuZFMAAC5kUwwsWzvafsNVccBtAHJBJNsT0nzJpPutNy1VOfYMLlIJphk75e03PY1tj9o+2jb37L9OUnX2j4k+RIh22+1/a7u8nLbG23/0PZ3bT+m/+Ldt0Seb3uT7R/ZPra7/QTbX+6ef5PtMxPnvND2lbavtv1F27t1t//c9t/b/p6k42wfY/tG29+zfXb3nT07da+3X/ecnbovO9q3zF8iIDV/1mAgj9MlHR4RT5Qk20er826HwyPilnne+5C0XtLrI+Im26skfUTSc/uOeYek/4iIE23vKekq25d19z1R0pMk3S9ps+0PS7pPnRcRPT8i7rH9NklvkfTu7jl/iIhn2N5F0k2SntWN80JJiog/2f6MpNdI+pA604f/OCJ+PfRvBhgSyQTodVVE3JJ2QLdaOFLSF+3Z2bsfMs+hL5T0Uttv7a7vIung7vK/R8Rd3etdL+mR6jx2Wynpiu51p9SZR2nGF7pfHyNpSyLOCyWt6y6fL+mr6iSTEyV9Mu1nAYpCMgF63ZNY3qHeR8G7dL/uJOl3MxVNCkt6RURs7tnYqWTuT2x6QJ2/RUv6ZkSsXSC2+d4/IUmKiNts32H7uZJWqVOlAKWjzQST7G5JD03Zf4ek/btvC3yIuq+CjojfS7rF9nGS5I4nzHP+pZLe5G6ZYftJC8Tzn5KOsv2o7vFLbD96nuNulHRo4jHcq/r2f1zSZ9SZ/fWBBb4nUAiSCSZW9y2AV9i+zvYH59n/R3XaK/5L0tfU+Z/4jNdIOsn2jyX9VJ33nfd7j6SdJf2k25D/ngXi+ZWkEyRdaPsn6iSXBzXsR8R96vRC29htkL9D0l2JQy6RtJt4xIUxYgp6oIFs7xYR/9etes6VdFNEnNXd9xRJZ0XEMysNEhOFygRoppNtX6NOVbSHpI9Kku3TJX1J0turCw2TiMoEAJAblQkAIDeSCQAgN5IJACA3kgkAIDeSCQAgN5IJACC3/wfn+hmP/H382AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "b = np.logspace(-1,2,100)\n",
    "plt.hist2d(\n",
    "    energy_target,\n",
    "    energy_pred,\n",
    "    bins=(b,b)\n",
    ")\n",
    "plt.xscale(\"log\")\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"true energy\")\n",
    "plt.ylabel(\"pred energy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc9df3b",
   "metadata": {},
   "source": [
    "# Jets\n",
    "\n",
    "https://fastjet.readthedocs.io/en/latest/Awkward.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8fe4e107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jet 1: pt = 707.9314059897632, eta = -0.22688206060131969, phi = 5.113068680217441, mass = 1231.952231367644\n",
      "Jet 2: pt = 662.287664562741, eta = 0.4998694601530169, phi = 3.6214088127106288, mass = 1084.4891176510894\n",
      "Jet 3: pt = 650.3448414209281, eta = 0.10290552518367481, phi = 2.277502731560636, mass = 1159.7186725080428\n",
      "Jet 4: pt = 436.91384128100793, eta = -0.314101078731973, phi = 0.6295511003407852, mass = 679.6301558707829#--------------------------------------------------------------------------\n",
      "#                         FastJet release 3.4.1\n",
      "#                 M. Cacciari, G.P. Salam and G. Soyez                  \n",
      "#     A software package for jet finding and analysis at colliders      \n",
      "#                           http://fastjet.fr                           \n",
      "#\t                                                                      \n",
      "# Please cite EPJC72(2012)1896 [arXiv:1111.6097] if you use this package\n",
      "# for scientific work and optionally PLB641(2006)57 [hep-ph/0512210].   \n",
      "#                                                                       \n",
      "# FastJet is provided without warranty under the GNU GPL v2 or higher.  \n",
      "# It uses T. Chan's closest pair algorithm, S. Fortune's Voronoi code,\n",
      "# CGAL and 3rd party plugin jet algorithms. See COPYING file for details.\n",
      "#--------------------------------------------------------------------------\n",
      "\n",
      "Jet 5: pt = 20.431037123170483, eta = -1.5281795249223202, phi = 3.1714146761939266, mass = 50.91318464745024\n",
      "Jet 6: pt = 18.36701076200816, eta = 1.8982476314816084, phi = 1.3860006492110384, mass = 63.23286547925353\n",
      "Jet 7: pt = 10.891554670557678, eta = 1.330897110672144, phi = 6.081913919884816, mass = 23.044334555258\n",
      "Jet 8: pt = 8.397956325751851, eta = -1.7336791656422397, phi = 1.5667411118268408, mass = 25.132817896197114\n",
      "Jet 9: pt = 2.5134254834723624, eta = 1.902665506352057, phi = 4.588935013533528, mass = 8.618036917282703\n",
      "Jet 10: pt = 2.477832749018865, eta = -1.722527575753209, phi = 5.953033692199199, mass = 7.380609592342717\n"
     ]
    }
   ],
   "source": [
    "import fastjet as fj\n",
    "import numpy as np\n",
    "\n",
    "def create_particles(X_features):\n",
    "    particles = []\n",
    "    for x_feat in X_features:\n",
    "        pt, eta, phi, mass = x_feat[:, 1], x_feat[:, 2], torch.atan2(x_feat[:, 4], x_feat[:, 3]), x_feat[:, 5]\n",
    "        for pt_, eta_, phi_, mass_ in zip(pt, eta, phi, mass):\n",
    "            px = pt_ * torch.cos(phi_)\n",
    "            py = pt_ * torch.sin(phi_)\n",
    "            pz = pt_ * torch.sinh(eta_)\n",
    "            e = torch.sqrt(px**2 + py**2 + pz**2 + mass_**2)\n",
    "            particles.append(fj.PseudoJet(px.item(), py.item(), pz.item(), e.item()))\n",
    "    return particles\n",
    "\n",
    "# Cluster jets using FastJet\n",
    "def cluster_jets(particles, R=1.0, algorithm=fj.antikt_algorithm):\n",
    "    jet_def = fj.JetDefinition(algorithm, R)\n",
    "    cs = fj.ClusterSequence(particles, jet_def)\n",
    "    jets = fj.sorted_by_pt(cs.inclusive_jets())\n",
    "    return jets\n",
    "\n",
    "\n",
    "# Convert X_features into particles\n",
    "particles = create_particles(X_features)\n",
    "\n",
    "# Cluster jets\n",
    "jets = cluster_jets(particles)\n",
    "\n",
    "# Analyze jets\n",
    "for i, jet in enumerate(jets):\n",
    "    print(f\"Jet {i+1}: pt = {jet.pt()}, eta = {jet.eta()}, phi = {jet.phi()}, mass = {jet.m()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd3df45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046655cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b45095",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b43e41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c036e48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1bb59b32-9925-419f-bd15-09923b6d1073",
   "metadata": {},
   "source": [
    "## Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "90148326-4b8c-4d2d-b192-b479b1516633",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cvmfs/sft.cern.ch/lcg/views/LCG_105_cuda/x86_64-el9-gcc11-opt/lib/python3.9/site-packages/torch/ao/quantization/observer.py:214: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
      "  warnings.warn(\n",
      "/cvmfs/sft.cern.ch/lcg/views/LCG_105_cuda/x86_64-el9-gcc11-opt/lib/python3.9/site-packages/torch/ao/quantization/observer.py:1207: UserWarning: must run observer before calling calculate_qparams.                                    Returning default scale and zero point \n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "model.qconfig = torch.ao.quantization.get_default_qconfig('x86')\n",
    "custom_module_config = {\n",
    "        \"float_to_observed_custom_module_class\": {torch.nn.MultiheadAttention: QuantizeableMultiheadAttention},\n",
    "        \"observed_to_quantized_custom_module_class\": {QuantizeableMultiheadAttention: QuantizedMultiheadAttention},\n",
    "}\n",
    "\n",
    "model_prepared = torch.ao.quantization.prepare(model, prepare_custom_config_dict=custom_module_config)\n",
    "\n",
    "#calibrate on data\n",
    "num_events_to_calibrate = 5000\n",
    "for ind in range(max_events_train,max_events_train+num_events_to_calibrate):\n",
    "    _X = torch.unsqueeze(torch.tensor(ds_train[ind][\"X\"]).to(torch.float32), 0)\n",
    "    _mask = _X[:, :, 0]!=0\n",
    "    model_prepared(_X, _mask)\n",
    "\n",
    "model_int8 = torch.ao.quantization.convert(model_prepared,convert_custom_config_dict=custom_module_config,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9248b521-f166-4944-95cb-af96b5e66adc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QuantizeFeaturesStub(\n",
       "  (quants): ModuleList(\n",
       "    (0): Quantize(scale=tensor([0.0157]), zero_point=tensor([0]), dtype=torch.quint8)\n",
       "    (1): Quantize(scale=tensor([0.0876]), zero_point=tensor([69]), dtype=torch.quint8)\n",
       "    (2): Quantize(scale=tensor([0.0797]), zero_point=tensor([63]), dtype=torch.quint8)\n",
       "    (3-4): 2 x Quantize(scale=tensor([0.0157]), zero_point=tensor([64]), dtype=torch.quint8)\n",
       "    (5): Quantize(scale=tensor([0.0679]), zero_point=tensor([49]), dtype=torch.quint8)\n",
       "    (6): Quantize(scale=tensor([41.5642]), zero_point=tensor([78]), dtype=torch.quint8)\n",
       "    (7): Quantize(scale=tensor([51.0497]), zero_point=tensor([64]), dtype=torch.quint8)\n",
       "    (8): Quantize(scale=tensor([64.1927]), zero_point=tensor([64]), dtype=torch.quint8)\n",
       "    (9): Quantize(scale=tensor([0.0245]), zero_point=tensor([0]), dtype=torch.quint8)\n",
       "    (10): Quantize(scale=tensor([6.4767]), zero_point=tensor([0]), dtype=torch.quint8)\n",
       "    (11): Quantize(scale=tensor([0.7337]), zero_point=tensor([13]), dtype=torch.quint8)\n",
       "    (12): Quantize(scale=tensor([1.4606]), zero_point=tensor([86]), dtype=torch.quint8)\n",
       "    (13): Quantize(scale=tensor([12.4617]), zero_point=tensor([0]), dtype=torch.quint8)\n",
       "    (14): Quantize(scale=tensor([43.9382]), zero_point=tensor([78]), dtype=torch.quint8)\n",
       "    (15): Quantize(scale=tensor([8.6720]), zero_point=tensor([0]), dtype=torch.quint8)\n",
       "    (16): Quantize(scale=tensor([7.6902]), zero_point=tensor([0]), dtype=torch.quint8)\n",
       "    (17-19): 3 x Quantize(scale=tensor([1.]), zero_point=tensor([0]), dtype=torch.quint8)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_int8.quant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2e8f0258-3225-4c0f-8529-7a3bcbc83659",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_quantized = torch.quantize_per_tensor((X_features_padded[:, :, 0]!=0).to(torch.float32), 1, 0, torch.quint8)\n",
    "preds = model_int8(X_features_padded, mask_quantized)\n",
    "preds = preds[0].detach(), preds[1].detach()\n",
    "preds_unpacked_int8 = unpack_predictions(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f1344cde-97f6-4a1c-8526-3586a139efff",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_int8 = mlpf_loss(targets_unpacked, preds_unpacked_int8, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "90b2a37d-8aa2-4ae0-be3b-c1d3fe56a2e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Final total loss')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(range(2), [loss[\"Total\"].detach().numpy(), loss_int8[\"Total\"].detach().numpy()])\n",
    "plt.xticks(range(2), [\"fp32\", \"int8\"])\n",
    "plt.ylabel(\"Final total loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "57979d38-46a9-48bd-a9a2-748cb29d519d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_pred_int8 = preds_unpacked_int8[\"pt\"][msk_true_particles].numpy()\n",
    "eta_pred_int8 = preds_unpacked_int8[\"eta\"][msk_true_particles].numpy()\n",
    "sphi_pred_int8 = preds_unpacked_int8[\"sin_phi\"][msk_true_particles].numpy()\n",
    "cphi_pred_int8 = preds_unpacked_int8[\"cos_phi\"][msk_true_particles].numpy()\n",
    "energy_pred_int8 = preds_unpacked_int8[\"energy\"][msk_true_particles].numpy()\n",
    "\n",
    "px = preds_unpacked_int8[\"pt\"] * preds_unpacked_int8[\"cos_phi\"] * msk_true_particles\n",
    "py = preds_unpacked_int8[\"pt\"] * preds_unpacked_int8[\"sin_phi\"] * msk_true_particles\n",
    "pred_met_int8 = torch.sqrt(torch.sum(px, axis=-2) ** 2 + torch.sum(py, axis=-2) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e7c02b0e-3e92-4aec-8741-6a4a58c1deca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f1d70077a60>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(pred_met/true_met, bins=np.linspace(0,5,61), histtype=\"step\", lw=2, label=\"fp32\");\n",
    "plt.hist(pred_met_int8/true_met, bins=np.linspace(0,5,61), histtype=\"step\", lw=2, label=\"int8\");\n",
    "plt.xlabel(\"reco_met / gen_met\")\n",
    "plt.ylabel(\"number of events / bin\")\n",
    "plt.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c83132",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a57b8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "abdb37a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pt_values [707.9314059897632, 662.287664562741, 650.3448414209281, 436.91384128100793, 20.431037123170483, 18.36701076200816, 10.891554670557678, 8.397956325751851, 2.5134254834723624, 2.477832749018865]\n"
     ]
    }
   ],
   "source": [
    "pt_values = [jet.pt() for jet in jets]\n",
    "print(f\"pt_values\",pt_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f657b5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4289b59d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ds_eval' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/sraj/ipykernel_2753893/2961230070.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# Use the trained model to predict jets on the evaluation dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mpredicted_jets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_jets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mds_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents_per_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'ds_eval' is not defined"
     ]
    }
   ],
   "source": [
    "# Define a function to predict jets using the trained model\n",
    "def predict_jets(model, dataset, events_per_batch):\n",
    "    predicted_jets = []\n",
    "    inds = range(0, len(dataset), events_per_batch)\n",
    "    for ind in tqdm.tqdm(inds):\n",
    "        # Load the data for one batch\n",
    "        ds_elems = dataset[ind:ind+events_per_batch]\n",
    "        X_features = [torch.tensor(elem[\"X\"]).to(torch.float32) for elem in ds_elems]\n",
    "\n",
    "        # Batch the data into [batch_size, num_elems, num_features]\n",
    "        X_features_padded = pad_sequence(X_features, batch_first=True).to(device=device)\n",
    "        mask = X_features_padded[:, :, 0] != 0\n",
    "\n",
    "        # Run the model to predict jets\n",
    "        with torch.no_grad():\n",
    "            preds = model(X_features_padded, mask)\n",
    "        \n",
    "        # Unpack and process the predicted jets\n",
    "        preds_unpacked = unpack_predictions(preds)\n",
    "        predicted_jets.extend(preds_unpacked)\n",
    "    \n",
    "    return predicted_jets\n",
    "\n",
    "# Use the trained model to predict jets on the evaluation dataset\n",
    "predicted_jets = predict_jets(model, ds_eval, events_per_batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "72242e94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch element 0:\n",
      "tensor([[ 1.0000,  3.6839, -0.2448,  ..., -0.5479, -1.0000,  0.0000],\n",
      "        [ 1.0000, 21.6268,  0.5386,  ...,  0.6570, -1.0000,  0.0000],\n",
      "        [ 1.0000,  3.5427, -0.3341,  ...,  1.2163, -1.0000,  0.0000],\n",
      "        ...,\n",
      "        [ 2.0000,  1.8473, -0.5751,  ..., 25.4729, 19.2184, 18.4121],\n",
      "        [ 2.0000,  0.2759, -0.0767,  ...,  5.8995,  4.7749,  2.4985],\n",
      "        [ 2.0000,  0.8693, -0.6771,  ..., 30.6583, 31.6224, 28.4398]])\n",
      "Batch element 1:\n",
      "tensor([[ 1.0000e+00,  4.7078e+01,  2.7044e-01,  ...,  2.5455e-03,\n",
      "         -1.0000e+00,  0.0000e+00],\n",
      "        [ 1.0000e+00,  2.6926e+01, -6.2637e-02,  ..., -4.3941e-03,\n",
      "         -1.0000e+00,  0.0000e+00],\n",
      "        [ 1.0000e+00,  2.2181e+01, -4.3668e-01,  ..., -4.4045e-03,\n",
      "         -1.0000e+00,  0.0000e+00],\n",
      "        ...,\n",
      "        [ 2.0000e+00,  1.4925e+00, -5.4835e-01,  ...,  1.4042e+01,\n",
      "          2.9127e+01,  2.4526e+01],\n",
      "        [ 2.0000e+00,  2.6105e+00, -9.0993e-01,  ...,  3.6439e+01,\n",
      "          4.4795e+01,  5.2597e+01],\n",
      "        [ 2.0000e+00,  4.7236e+00, -4.4167e-01,  ...,  4.3143e+02,\n",
      "          9.0859e+02,  4.6345e+02]])\n",
      "Batch element 2:\n",
      "tensor([[ 1.0000e+00,  4.7440e+01, -4.6837e-01,  ...,  9.4367e-03,\n",
      "         -1.0000e+00,  0.0000e+00],\n",
      "        [ 1.0000e+00,  5.8608e+00,  4.2135e-01,  ...,  7.2756e-01,\n",
      "         -1.0000e+00,  0.0000e+00],\n",
      "        [ 1.0000e+00,  8.0156e+00,  6.2740e-01,  ..., -4.4983e-02,\n",
      "         -1.0000e+00,  0.0000e+00],\n",
      "        ...,\n",
      "        [ 2.0000e+00,  2.5003e+00,  3.8596e-01,  ...,  2.0533e+01,\n",
      "          3.3211e+01,  1.5568e+01],\n",
      "        [ 2.0000e+00,  3.7204e+00, -1.3960e-01,  ...,  2.8571e+01,\n",
      "          3.8986e+01,  2.9147e+01],\n",
      "        [ 2.0000e+00,  5.8965e+00,  1.4763e+00,  ...,  3.4362e+01,\n",
      "          4.0347e+01,  5.7029e+01]])\n",
      "Batch element 3:\n",
      "tensor([[ 1.0000e+00,  1.6499e+01,  1.2239e+00,  ..., -3.8539e-01,\n",
      "         -1.0000e+00,  0.0000e+00],\n",
      "        [ 1.0000e+00,  1.3658e+01, -8.3923e-01,  ..., -2.0083e-02,\n",
      "         -1.0000e+00,  0.0000e+00],\n",
      "        [ 1.0000e+00,  8.6668e+00, -8.4851e-01,  ..., -5.2766e-03,\n",
      "         -1.0000e+00,  0.0000e+00],\n",
      "        ...,\n",
      "        [ 2.0000e+00,  7.0913e+00,  3.5451e-01,  ...,  1.1936e+02,\n",
      "          9.5356e+01,  7.3544e+01],\n",
      "        [ 2.0000e+00,  2.2577e+01, -1.0222e+00,  ...,  6.3504e+01,\n",
      "          1.2651e+02,  1.6315e+02],\n",
      "        [ 2.0000e+00,  3.3492e+00, -1.4719e+00,  ...,  2.3504e+01,\n",
      "          3.3259e+01,  4.3300e+01]])\n",
      "Batch element 4:\n",
      "tensor([[ 1.0000e+00,  3.0073e+01,  5.4297e-01,  ...,  3.3453e-03,\n",
      "         -1.0000e+00,  0.0000e+00],\n",
      "        [ 1.0000e+00,  7.2090e+01,  5.7680e-01,  ...,  4.1311e-03,\n",
      "         -1.0000e+00,  0.0000e+00],\n",
      "        [ 1.0000e+00,  1.9822e+01,  5.5428e-01,  ...,  1.3948e-02,\n",
      "         -1.0000e+00,  0.0000e+00],\n",
      "        ...,\n",
      "        [ 2.0000e+00,  2.3865e+00, -5.3911e-01,  ...,  3.1241e+01,\n",
      "          2.9918e+01,  3.6526e+01],\n",
      "        [ 2.0000e+00,  4.1794e-01, -7.7783e-01,  ...,  2.9175e+01,\n",
      "          1.4493e+01,  2.5227e+01],\n",
      "        [ 2.0000e+00,  3.9538e+00,  2.9744e-01,  ...,  7.8572e+02,\n",
      "          7.1760e+02,  3.1284e+02]])\n",
      "Batch element 5:\n",
      "tensor([[ 1.0000e+00,  5.0189e+00,  1.4543e-01,  ..., -7.8657e-02,\n",
      "         -1.0000e+00,  0.0000e+00],\n",
      "        [ 1.0000e+00,  1.5650e+01, -1.5809e-01,  ...,  2.0444e-03,\n",
      "         -1.0000e+00,  0.0000e+00],\n",
      "        [ 1.0000e+00,  1.4491e+01, -2.2517e-01,  ...,  1.9644e-03,\n",
      "         -1.0000e+00,  0.0000e+00],\n",
      "        ...,\n",
      "        [ 2.0000e+00,  1.0057e+01,  5.1718e-02,  ...,  1.0597e+02,\n",
      "          1.3967e+02,  4.7799e+01],\n",
      "        [ 2.0000e+00,  1.3383e+01, -8.7564e-01,  ...,  1.9178e+02,\n",
      "          2.6184e+02,  3.1303e+02],\n",
      "        [ 2.0000e+00,  1.1902e+01, -1.1764e+00,  ...,  5.4598e+01,\n",
      "          6.7547e+01,  1.1601e+02]])\n",
      "Batch element 6:\n",
      "tensor([[ 1.0000e+00,  5.9586e+00,  8.1385e-01,  ..., -4.5329e-02,\n",
      "         -1.0000e+00,  0.0000e+00],\n",
      "        [ 1.0000e+00,  9.5201e+00,  2.9853e-01,  ..., -4.3758e-03,\n",
      "         -1.0000e+00,  0.0000e+00],\n",
      "        [ 1.0000e+00,  8.3660e+00, -9.5316e-01,  ...,  1.8778e-01,\n",
      "         -1.0000e+00,  0.0000e+00],\n",
      "        ...,\n",
      "        [ 2.0000e+00,  2.1902e+00,  1.9241e+00,  ...,  7.4655e+01,\n",
      "          4.5092e+01,  2.2886e+02],\n",
      "        [ 2.0000e+00,  3.5284e+00, -9.4639e-01,  ...,  2.7055e+02,\n",
      "          7.2742e+02,  8.5310e+02],\n",
      "        [ 2.0000e+00,  2.7129e+00, -1.3027e+00,  ...,  4.3068e+02,\n",
      "          3.1670e+01,  7.3781e+02]])\n",
      "Batch element 7:\n",
      "tensor([[ 1.0000e+00,  4.3336e+01, -7.8041e-01,  ..., -6.8078e-04,\n",
      "         -1.0000e+00,  0.0000e+00],\n",
      "        [ 1.0000e+00,  2.3925e+01, -5.4545e-01,  ..., -5.0876e-03,\n",
      "         -1.0000e+00,  0.0000e+00],\n",
      "        [ 1.0000e+00,  1.9395e+00, -3.7165e-01,  ..., -1.0744e+00,\n",
      "         -1.0000e+00,  0.0000e+00],\n",
      "        ...,\n",
      "        [ 2.0000e+00,  1.1023e+00, -5.1763e-02,  ...,  1.2018e+01,\n",
      "          4.4677e+01,  1.2371e+01],\n",
      "        [ 2.0000e+00,  5.4299e+00, -1.1663e+00,  ...,  2.9026e+01,\n",
      "          3.5837e+01,  3.8506e+01],\n",
      "        [ 2.0000e+00,  4.1215e+00, -1.3018e+00,  ...,  1.2261e+01,\n",
      "          2.2377e+01,  3.5890e+01]])\n"
     ]
    }
   ],
   "source": [
    "for i, batch_elem in enumerate(X_features):\n",
    "    print(f\"Batch element {i}:\")\n",
    "    print(batch_elem)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "518d8193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch element 0 shape: torch.Size([122, 17])\n",
      "Batch element 1 shape: torch.Size([85, 17])\n",
      "Batch element 2 shape: torch.Size([93, 17])\n",
      "Batch element 3 shape: torch.Size([111, 17])\n",
      "Batch element 4 shape: torch.Size([112, 17])\n",
      "Batch element 5 shape: torch.Size([140, 17])\n",
      "Batch element 6 shape: torch.Size([124, 17])\n",
      "Batch element 7 shape: torch.Size([87, 17])\n"
     ]
    }
   ],
   "source": [
    "for i, batch_elem in enumerate(X_features):\n",
    "    print(f\"Batch element {i} shape: {batch_elem.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0faae1de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688b47f6-c922-4520-8ba4-5f783a7f4130",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(3):\n",
    "#     t0 = time.time()\n",
    "#     for j in range(1):\n",
    "#         model(X_features_padded, X_features_padded[:, :, 0]!=0)\n",
    "#     t1 = time.time()\n",
    "#     print(t1 - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f845b93f-decc-4d8f-be11-d54b7486e24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask_quantized = torch.quantize_per_tensor((X_features_padded[:, :, 0]!=0).to(torch.float32), 1, 0, torch.quint8)\n",
    "# for i in range(3):\n",
    "#     t0 = time.time()\n",
    "#     for j in range(1):\n",
    "#         model_int8(X_features_padded, mask_quantized)\n",
    "#     t1 = time.time()\n",
    "#     print(t1 - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c59978-a1ae-44f5-ba0e-ecce9d0d1e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_options = torch.onnx.ExportOptions(dynamic_shapes=True)\n",
    "mask = X_features_padded[:, :, 0]!=0\n",
    "\n",
    "onnx_program = torch.onnx.dynamo_export(model, X_features_padded, mask, export_options=export_options)\n",
    "onnx_program.save(\"mlpf_fp32_dynamo.onnx\")\n",
    "\n",
    "torch.onnx.export(model,                                            # model\n",
    "                  (X_features_padded, mask),                        # model input\n",
    "                  \"mlpf_fp32.onnx\",                                 # path\n",
    "                  export_params=True,                               # store the trained parameter weights inside the model file\n",
    "                  opset_version=17,                                 # the ONNX version to export the model to\n",
    "                  do_constant_folding=True,                         # constant folding for optimization\n",
    "                  input_names = ['input'],                          # input names\n",
    "                  output_names = ['output'],                        # output names\n",
    "                  dynamic_axes={'input' : {0 : 'batch_size', 1: 'num_elems'},\n",
    "                                'output' : {0 : 'batch_size', 1: 'num_elems'}},\n",
    "                  verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a3cb52-1120-4293-b07c-decaf6c0013d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This does not work\n",
    "# onnx_program = torch.onnx.dynamo_export(model_int8, X_features_padded, mask_quantized, export_options=export_options)\n",
    "# onnx_program.save(\"mlpf_int8_dynamo.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfcff62-763d-48b0-99de-4485c160382d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.onnx.export(model_int8,                                       # model\n",
    "                  (X_features_padded, mask_quantized),              # model input\n",
    "                  \"mlpf_int8.onnx\",                                 # path\n",
    "                  export_params=True,                               # store the trained parameter weights inside the model file\n",
    "                  opset_version=17,                                 # the ONNX version to export the model to\n",
    "                  do_constant_folding=True,                         # constant folding for optimization\n",
    "                  input_names = ['input'],                          # input names\n",
    "                  output_names = ['output'],                        # output names\n",
    "                  dynamic_axes={'input' : {0 : 'batch_size', 1: 'num_elems'},\n",
    "                                'output' : {0 : 'batch_size', 1: 'num_elems'}},\n",
    "                  verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a36aea-6c1c-4070-a9c1-fa418fe70587",
   "metadata": {},
   "outputs": [],
   "source": [
    "!du -csh *.onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36df9966-0a7a-471a-ab2f-f050581164da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime as ort\n",
    "\n",
    "ort_fp32 = ort.InferenceSession('mlpf_fp32.onnx')\n",
    "outputs = ort_fp32.run(None, {'input': X_features_padded.numpy()})\n",
    "preds_unpacked_ort_fp32 = unpack_predictions((torch.tensor(outputs[0]), torch.tensor(outputs[1])))\n",
    "\n",
    "px = preds_unpacked_ort_fp32[\"pt\"] * preds_unpacked_ort_fp32[\"cos_phi\"] * msk_true_particles\n",
    "py = preds_unpacked_ort_fp32[\"pt\"] * preds_unpacked_ort_fp32[\"sin_phi\"] * msk_true_particles\n",
    "pred_met_ort_fp32 = torch.sqrt(torch.sum(px, axis=-2) ** 2 + torch.sum(py, axis=-2) ** 2)\n",
    "\n",
    "ort_int8 = ort.InferenceSession('mlpf_int8.onnx')\n",
    "outputs = ort_int8.run(None, {'input': X_features_padded.numpy()})\n",
    "preds_unpacked_ort_int8 = unpack_predictions((torch.tensor(outputs[0]), torch.tensor(outputs[1])))\n",
    "\n",
    "px = preds_unpacked_ort_int8[\"pt\"] * preds_unpacked_ort_int8[\"cos_phi\"] * msk_true_particles\n",
    "py = preds_unpacked_ort_int8[\"pt\"] * preds_unpacked_ort_int8[\"sin_phi\"] * msk_true_particles\n",
    "pred_met_ort_int8 = torch.sqrt(torch.sum(px, axis=-2) ** 2 + torch.sum(py, axis=-2) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a8dcba-ade3-4135-a23b-9d9eed6830c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(\n",
    "    preds_unpacked[\"pt\"][targets_unpacked[\"cls_id\"]!=0],\n",
    "    preds_unpacked_ort_fp32[\"pt\"][targets_unpacked[\"cls_id\"]!=0],\n",
    "    marker=\".\", label=\"fp32\"\n",
    ")\n",
    "\n",
    "plt.scatter(\n",
    "    preds_unpacked_int8[\"pt\"][targets_unpacked[\"cls_id\"]!=0],\n",
    "    preds_unpacked_ort_int8[\"pt\"][targets_unpacked[\"cls_id\"]!=0],\n",
    "    marker=\".\", label=\"int8\"\n",
    ")\n",
    "plt.xlabel(\"pt, pytorch\")\n",
    "plt.ylabel(\"pt, ONNX\")\n",
    "plt.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6919306-9c6e-43ad-9f3a-fa32af4ee102",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(\n",
    "    pred_met,\n",
    "    pred_met_ort_fp32,\n",
    "    marker=\".\", label=\"fp32\"\n",
    ")\n",
    "\n",
    "plt.scatter(\n",
    "    pred_met_int8,\n",
    "    pred_met_ort_int8,\n",
    "    marker=\".\", label=\"int8\"\n",
    ")\n",
    "plt.xlabel(\"MET, pytorch\")\n",
    "plt.ylabel(\"MET, ONNX\")\n",
    "plt.legend(loc=\"best\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
