{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd3d41e4",
   "metadata": {},
   "source": [
    "# Task:\n",
    "\n",
    "1. Working on the CPU with a reseaonable number of statistics try to plot the figure 9.\n",
    "2. Increase the number of statistics for the validation $\\leftarrow$\n",
    "3. Try with one event and try to debug.\n",
    "4. Try to plot IQR/median vs P-gen for the MET\n",
    "5. Produce the plots for the MET\n",
    "6. For the statistics, plot for on event. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c0de9525",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import tqdm\n",
    "\n",
    "import ROOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "267b31e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, Tensor\n",
    "import tensorflow_datasets as tfds\n",
    "import torch_geometric\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa6d4992",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36d3d83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets\n",
    "data_dir = \"../../mlpf/tensorflow_datasets/\"\n",
    "dataset = \"clic_edm_ttbar_pf\"\n",
    "\n",
    "# Load dataset\n",
    "builder = tfds.builder(dataset, data_dir=data_dir)\n",
    "ds_train = builder.as_data_source(split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd5ecbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_FEATURES_TRK = [\n",
    "    \"elemtype\",\n",
    "    \"pt\",\n",
    "    \"eta\",\n",
    "    \"sin_phi\",\n",
    "    \"cos_phi\",\n",
    "    \"p\",\n",
    "    \"chi2\",\n",
    "    \"ndf\",\n",
    "    \"dEdx\",\n",
    "    \"dEdxError\",\n",
    "    \"radiusOfInnermostHit\",\n",
    "    \"tanLambda\",\n",
    "    \"D0\",\n",
    "    \"omega\",\n",
    "    \"Z0\",\n",
    "    \"time\",\n",
    "]\n",
    "X_FEATURES_CL = [\n",
    "    \"elemtype\",\n",
    "    \"et\",\n",
    "    \"eta\",\n",
    "    \"sin_phi\",\n",
    "    \"cos_phi\",\n",
    "    \"energy\",\n",
    "    \"position.x\",\n",
    "    \"position.y\",\n",
    "    \"position.z\",\n",
    "    \"iTheta\",\n",
    "    \"energy_ecal\",\n",
    "    \"energy_hcal\",\n",
    "    \"energy_other\",\n",
    "    \"num_hits\",\n",
    "    \"sigma_x\",\n",
    "    \"sigma_y\",\n",
    "    \"sigma_z\",\n",
    "]\n",
    "Y_FEATURES = [\"cls_id\", \"charge\", \"pt\", \"eta\", \"sin_phi\", \"cos_phi\", \"energy\"]\n",
    "Y_CLASSES = [0, 211, 130, 22, 11, 13]\n",
    "\n",
    "INPUT_DIM = max(len(X_FEATURES_TRK), len(X_FEATURES_CL))\n",
    "NUM_CLASSES = len(Y_CLASSES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512117c7",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5346ebb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# JP 2024-02-29: currently torch int8 onnx export does not work with MultiheadAttention because of the following:\n",
    "# - it uses q_scaling_product.mul_scalar which is not supported in ONNX opset 17: the fix is to just remove the q_scaling_product\n",
    "# - somehow, the \"need_weights\" option confuses the ONNX exporter because the multiheaded attention layer then returns a tuple: the fix is to make the MHA always return just the attended values only\n",
    "# I lifted these two modules directly from the pytorch code and made the modifications here.\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as nnF\n",
    "\n",
    "from torch import Tensor\n",
    "from typing import Optional, Tuple\n",
    "\n",
    "class QuantizeableMultiheadAttention(nn.MultiheadAttention):\n",
    "    _FLOAT_MODULE = nn.MultiheadAttention\n",
    "\n",
    "    r\"\"\"Quantizable implementation of the MultiheadAttention.\n",
    "\n",
    "    Note::\n",
    "        Please, refer to :class:`~torch.nn.MultiheadAttention` for more\n",
    "        information\n",
    "\n",
    "    Allows the model to jointly attend to information from different\n",
    "    representation subspaces.\n",
    "    See reference: Attention Is All You Need\n",
    "\n",
    "    The original MHA module is not quantizable.\n",
    "    This reimplements it by explicitly instantiating the linear layers.\n",
    "\n",
    "    .. math::\n",
    "        \\text{MultiHead}(Q, K, V) = \\text{Concat}(head_1,\\dots,head_h)W^O\n",
    "        \\text{where} head_i = \\text{Attention}(QW_i^Q, KW_i^K, VW_i^V)\n",
    "\n",
    "    Args:\n",
    "        embed_dim: total dimension of the model.\n",
    "        num_heads: parallel attention heads.\n",
    "        dropout: a Dropout layer on attn_output_weights. Default: 0.0.\n",
    "        bias: add bias as module parameter. Default: True.\n",
    "        add_bias_kv: add bias to the key and value sequences at dim=0.\n",
    "        add_zero_attn: add a new batch of zeros to the key and\n",
    "                       value sequences at dim=1.\n",
    "        kdim: total number of features in key. Default: None.\n",
    "        vdim: total number of features in value. Default: None.\n",
    "        batch_first: If ``True``, then the input and output tensors are provided\n",
    "            as (batch, seq, feature). Default: ``False`` (seq, batch, feature).\n",
    "\n",
    "    Note that if :attr:`kdim` and :attr:`vdim` are None, they will be set\n",
    "    to :attr:`embed_dim` such that query, key, and value have the same\n",
    "    number of features.\n",
    "\n",
    "    Examples::\n",
    "\n",
    "        >>> import torch.ao.nn.quantizable as nnqa\n",
    "        >>> multihead_attn = nnqa.MultiheadAttention(embed_dim, num_heads)\n",
    "        >>> attn_output, attn_output_weights = multihead_attn(query, key, value)\n",
    "\n",
    "    Note::\n",
    "        Please, follow the quantization flow to convert the quantizable MHA.\n",
    "    \"\"\"\n",
    "    __constants__ = ['batch_first']\n",
    "\n",
    "    def __init__(self, embed_dim: int, num_heads: int,\n",
    "                 dropout: float = 0., bias: bool = True,\n",
    "                 add_bias_kv: bool = False, add_zero_attn: bool = False,\n",
    "                 kdim: Optional[int] = None, vdim: Optional[int] = None, batch_first: bool = False,\n",
    "                 device=None, dtype=None) -> None:\n",
    "        factory_kwargs = {'device': device, 'dtype': dtype}\n",
    "        super().__init__(embed_dim, num_heads, dropout,\n",
    "                         bias, add_bias_kv,\n",
    "                         add_zero_attn, kdim, vdim, batch_first,\n",
    "                         **factory_kwargs)\n",
    "        self.linear_Q = nn.Linear(self.embed_dim, self.embed_dim, bias=bias, **factory_kwargs)\n",
    "        self.linear_K = nn.Linear(self.kdim, self.embed_dim, bias=bias, **factory_kwargs)\n",
    "        self.linear_V = nn.Linear(self.vdim, self.embed_dim, bias=bias, **factory_kwargs)\n",
    "        # for the type: ignore, see https://github.com/pytorch/pytorch/issues/58969\n",
    "        self.out_proj = nn.Linear(self.embed_dim, self.embed_dim, bias=bias, **factory_kwargs)  # type: ignore[assignment]\n",
    "\n",
    "        # Functionals\n",
    "        # self.q_scaling_product = torch.ao.nn.quantized.FloatFunctional()\n",
    "        # note: importing torch.ao.nn.quantized at top creates a circular import\n",
    "\n",
    "        # Quant/Dequant\n",
    "        self.quant_attn_output = torch.ao.quantization.QuantStub()\n",
    "        self.quant_attn_output_weights = torch.ao.quantization.QuantStub()\n",
    "        self.dequant_q = torch.ao.quantization.DeQuantStub()\n",
    "        self.dequant_k = torch.ao.quantization.DeQuantStub()\n",
    "        self.dequant_v = torch.ao.quantization.DeQuantStub()\n",
    "\n",
    "    def _get_name(self):\n",
    "        return 'QuantizableMultiheadAttention'\n",
    "\n",
    "    @classmethod\n",
    "    def from_float(cls, other):\n",
    "        assert type(other) == cls._FLOAT_MODULE\n",
    "        assert hasattr(other, 'qconfig'), \"The float module must have 'qconfig'\"\n",
    "        # Setting the dropout to 0.0!\n",
    "        observed = cls(other.embed_dim, other.num_heads, other.dropout,\n",
    "                       (other.in_proj_bias is not None),\n",
    "                       (other.bias_k is not None),\n",
    "                       other.add_zero_attn, other.kdim, other.vdim,\n",
    "                       other.batch_first)\n",
    "        observed.bias_k = other.bias_k\n",
    "        observed.bias_v = other.bias_v\n",
    "        observed.qconfig = other.qconfig\n",
    "\n",
    "        # Set the linear weights\n",
    "        # for the type: ignores, see https://github.com/pytorch/pytorch/issues/58969\n",
    "        observed.out_proj.weight = other.out_proj.weight  # type: ignore[has-type]\n",
    "        observed.out_proj.bias = other.out_proj.bias  # type: ignore[has-type]\n",
    "        if other._qkv_same_embed_dim:\n",
    "            # Use separate params\n",
    "            bias = other.in_proj_bias\n",
    "            _start = 0\n",
    "            _end = _start + other.embed_dim\n",
    "            weight = other.in_proj_weight[_start:_end, :]\n",
    "            if bias is not None:\n",
    "                bias = torch.nn.Parameter(bias[_start:_end], bias.requires_grad)\n",
    "            observed.linear_Q.weight = torch.nn.Parameter(weight,\n",
    "                                                          weight.requires_grad)\n",
    "            observed.linear_Q.bias = bias\n",
    "\n",
    "            bias = other.in_proj_bias\n",
    "            _start = _end\n",
    "            _end = _start + other.embed_dim\n",
    "            weight = other.in_proj_weight[_start:_end, :]\n",
    "            if bias is not None:\n",
    "                bias = torch.nn.Parameter(bias[_start:_end], bias.requires_grad)\n",
    "            observed.linear_K.weight = torch.nn.Parameter(weight,\n",
    "                                                          weight.requires_grad)\n",
    "            observed.linear_K.bias = bias\n",
    "\n",
    "            bias = other.in_proj_bias\n",
    "            _start = _end\n",
    "            weight = other.in_proj_weight[_start:, :]\n",
    "            if bias is not None:\n",
    "                bias = torch.nn.Parameter(bias[_start:], bias.requires_grad)\n",
    "            observed.linear_V.weight = torch.nn.Parameter(weight,\n",
    "                                                          weight.requires_grad)\n",
    "            observed.linear_V.bias = bias\n",
    "        else:\n",
    "            observed.linear_Q.weight = nn.Parameter(other.q_proj_weight)\n",
    "            observed.linear_K.weight = nn.Parameter(other.k_proj_weight)\n",
    "            observed.linear_V.weight = nn.Parameter(other.v_proj_weight)\n",
    "            if other.in_proj_bias is None:\n",
    "                observed.linear_Q.bias = None  # type: ignore[assignment]\n",
    "                observed.linear_K.bias = None  # type: ignore[assignment]\n",
    "                observed.linear_V.bias = None  # type: ignore[assignment]\n",
    "            else:\n",
    "                observed.linear_Q.bias = nn.Parameter(other.in_proj_bias[0:other.embed_dim])\n",
    "                observed.linear_K.bias = nn.Parameter(other.in_proj_bias[other.embed_dim:(other.embed_dim * 2)])\n",
    "                observed.linear_V.bias = nn.Parameter(other.in_proj_bias[(other.embed_dim * 2):])\n",
    "        observed.eval()\n",
    "        # Explicit prepare\n",
    "        observed = torch.ao.quantization.prepare(observed, inplace=True)\n",
    "        return observed\n",
    "\n",
    "    @torch.jit.unused\n",
    "    def dequantize(self):\n",
    "        r\"\"\"Utility to convert the quantized MHA back to float.\n",
    "\n",
    "        The motivation for this is that it is not trivial to conver the weights\n",
    "        from the format that is used in the quantized version back to the\n",
    "        float.\n",
    "        \"\"\"\n",
    "        fp = self._FLOAT_MODULE(self.embed_dim, self.num_heads, self.dropout,\n",
    "                                (self.linear_Q._weight_bias()[1] is not None),\n",
    "                                (self.bias_k is not None),\n",
    "                                self.add_zero_attn, self.kdim, self.vdim, self.batch_first)\n",
    "        assert fp._qkv_same_embed_dim == self._qkv_same_embed_dim\n",
    "        if self.bias_k is not None:\n",
    "            fp.bias_k = nn.Parameter(self.bias_k.dequantize())\n",
    "        if self.bias_v is not None:\n",
    "            fp.bias_v = nn.Parameter(self.bias_v.dequantize())\n",
    "\n",
    "        # Set the linear weights\n",
    "        # Note: Because the linear layers are quantized, mypy does not nkow how\n",
    "        # to deal with them -- might need to ignore the typing checks.\n",
    "        # for the type: ignore[has-type], see https://github.com/pytorch/pytorch/issues/58969\n",
    "        w, b = self.out_proj._weight_bias()  # type: ignore[operator, has-type]\n",
    "        fp.out_proj.weight = nn.Parameter(w.dequantize())\n",
    "        if b is not None:\n",
    "            fp.out_proj.bias = nn.Parameter(b)\n",
    "\n",
    "        wQ, bQ = self.linear_Q._weight_bias()  # type: ignore[operator]\n",
    "        wQ = wQ.dequantize()\n",
    "        wK, bK = self.linear_K._weight_bias()  # type: ignore[operator]\n",
    "        wK = wK.dequantize()\n",
    "        wV, bV = self.linear_V._weight_bias()  # type: ignore[operator]\n",
    "        wV = wV.dequantize()\n",
    "        if fp._qkv_same_embed_dim:\n",
    "            # Use separate params\n",
    "            _start = 0\n",
    "            _end = _start + fp.embed_dim\n",
    "            fp.in_proj_weight[_start:_end, :] = wQ\n",
    "            if fp.in_proj_bias is not None:\n",
    "                assert all(bQ == 0)\n",
    "                fp.in_proj_bias[_start:_end] = bQ\n",
    "\n",
    "            _start = _end\n",
    "            _end = _start + fp.embed_dim\n",
    "            fp.in_proj_weight[_start:_end, :] = wK\n",
    "            if fp.in_proj_bias is not None:\n",
    "                assert all(bK == 0)\n",
    "                fp.in_proj_bias[_start:_end] = bK\n",
    "\n",
    "            _start = _end\n",
    "            fp.in_proj_weight[_start:, :] = wV\n",
    "            if fp.in_proj_bias is not None:\n",
    "                assert all(bV == 0)\n",
    "                fp.in_proj_bias[_start:] = bV\n",
    "        else:\n",
    "            fp.q_proj_weight = nn.Parameter(wQ)\n",
    "            fp.k_proj_weight = nn.Parameter(wK)\n",
    "            fp.v_proj_weight = nn.Parameter(wV)\n",
    "            if fp.in_proj_bias is None:\n",
    "                self.linear_Q.bias = None\n",
    "                self.linear_K.bias = None\n",
    "                self.linear_V.bias = None\n",
    "            else:\n",
    "                fp.in_proj_bias[0:fp.embed_dim] = bQ\n",
    "                fp.in_proj_bias[fp.embed_dim:(fp.embed_dim * 2)] = bK\n",
    "                fp.in_proj_bias[(fp.embed_dim * 2):] = bV\n",
    "\n",
    "        return fp\n",
    "\n",
    "\n",
    "    @classmethod\n",
    "    def from_observed(cls, other):\n",
    "        # The whole flow is float -> observed -> quantized\n",
    "        # This class does float -> observed only\n",
    "        # See nn.quantized.MultiheadAttention\n",
    "        raise NotImplementedError(\"It looks like you are trying to prepare an \"\n",
    "                                  \"MHA module. Please, see \"\n",
    "                                  \"the examples on quantizable MHAs.\")\n",
    "\n",
    "    def forward(self,\n",
    "                query: Tensor,\n",
    "                key: Tensor,\n",
    "                value: Tensor,\n",
    "                key_padding_mask: Optional[Tensor] = None,\n",
    "                need_weights: bool = True,\n",
    "                attn_mask: Optional[Tensor] = None,\n",
    "                average_attn_weights: bool = True,\n",
    "                is_causal: bool = False) -> Tuple[Tensor, Optional[Tensor]]:\n",
    "        r\"\"\"\n",
    "    Note::\n",
    "        Please, refer to :func:`~torch.nn.MultiheadAttention.forward` for more\n",
    "        information\n",
    "\n",
    "    Args:\n",
    "        query, key, value: map a query and a set of key-value pairs to an output.\n",
    "            See \"Attention Is All You Need\" for more details.\n",
    "        key_padding_mask: if provided, specified padding elements in the key will\n",
    "            be ignored by the attention. When given a binary mask and a value is True,\n",
    "            the corresponding value on the attention layer will be ignored.\n",
    "        need_weights: output attn_output_weights.\n",
    "        attn_mask: 2D or 3D mask that prevents attention to certain positions. A 2D mask will be broadcasted for all\n",
    "            the batches while a 3D mask allows to specify a different mask for the entries of each batch.\n",
    "\n",
    "    Shape:\n",
    "        - Inputs:\n",
    "        - query: :math:`(L, N, E)` where L is the target sequence length, N is the batch size, E is\n",
    "          the embedding dimension. :math:`(N, L, E)` if ``batch_first`` is ``True``.\n",
    "        - key: :math:`(S, N, E)`, where S is the source sequence length, N is the batch size, E is\n",
    "          the embedding dimension. :math:`(N, S, E)` if ``batch_first`` is ``True``.\n",
    "        - value: :math:`(S, N, E)` where S is the source sequence length, N is the batch size, E is\n",
    "          the embedding dimension. :math:`(N, S, E)` if ``batch_first`` is ``True``.\n",
    "        - key_padding_mask: :math:`(N, S)` where N is the batch size, S is the source sequence length.\n",
    "          If a BoolTensor is provided, the positions with the\n",
    "          value of ``True`` will be ignored while the position with the value of ``False`` will be unchanged.\n",
    "        - attn_mask: 2D mask :math:`(L, S)` where L is the target sequence length, S is the source sequence length.\n",
    "          3D mask :math:`(N*num_heads, L, S)` where N is the batch size, L is the target sequence length,\n",
    "          S is the source sequence length. attn_mask ensure that position i is allowed to attend the unmasked\n",
    "          positions. If a BoolTensor is provided, positions with ``True``\n",
    "          is not allowed to attend while ``False`` values will be unchanged. If a FloatTensor\n",
    "          is provided, it will be added to the attention weight.\n",
    "        - is_causal: If specified, applies a causal mask as attention mask. Mutually exclusive with providing attn_mask.\n",
    "          Default: ``False``.\n",
    "        - average_attn_weights: If true, indicates that the returned ``attn_weights`` should be averaged across\n",
    "          heads. Otherwise, ``attn_weights`` are provided separately per head. Note that this flag only has an\n",
    "          effect when ``need_weights=True.``. Default: True (i.e. average weights across heads)\n",
    "\n",
    "        - Outputs:\n",
    "        - attn_output: :math:`(L, N, E)` where L is the target sequence length, N is the batch size,\n",
    "          E is the embedding dimension. :math:`(N, L, E)` if ``batch_first`` is ``True``.\n",
    "        - attn_output_weights: If ``average_attn_weights=True``, returns attention weights averaged\n",
    "          across heads of shape :math:`(N, L, S)`, where N is the batch size, L is the target sequence length,\n",
    "          S is the source sequence length. If ``average_attn_weights=False``, returns attention weights per\n",
    "          head of shape :math:`(N, num_heads, L, S)`.\n",
    "        \"\"\"\n",
    "        return self._forward_impl(query, key, value, key_padding_mask,\n",
    "                                  need_weights, attn_mask, average_attn_weights,\n",
    "                                  is_causal)\n",
    "\n",
    "    def _forward_impl(self,\n",
    "                      query: Tensor,\n",
    "                      key: Tensor,\n",
    "                      value: Tensor,\n",
    "                      key_padding_mask: Optional[Tensor] = None,\n",
    "                      need_weights: bool = True,\n",
    "                      attn_mask: Optional[Tensor] = None,\n",
    "                      average_attn_weights: bool = True,\n",
    "                      is_causal: bool = False) -> Tuple[Tensor, Optional[Tensor]]:\n",
    "        # This version will not deal with the static key/value pairs.\n",
    "        # Keeping it here for future changes.\n",
    "        #\n",
    "        # TODO: This method has some duplicate lines with the\n",
    "        # `torch.nn.functional.multi_head_attention`. Will need to refactor.\n",
    "        static_k = None\n",
    "        static_v = None\n",
    "\n",
    "        if attn_mask is not None and is_causal:\n",
    "            raise AssertionError(\"Only allow causal mask or attn_mask\")\n",
    "\n",
    "        if is_causal:\n",
    "            raise AssertionError(\"causal mask not supported by AO MHA module\")\n",
    "\n",
    "        if self.batch_first:\n",
    "            query, key, value = (x.transpose(0, 1) for x in (query, key, value))\n",
    "\n",
    "        tgt_len, bsz, embed_dim_to_check = query.size()\n",
    "        assert self.embed_dim == embed_dim_to_check\n",
    "        # allow MHA to have different sizes for the feature dimension\n",
    "        assert key.size(0) == value.size(0) and key.size(1) == value.size(1)\n",
    "\n",
    "        head_dim = self.embed_dim // self.num_heads\n",
    "        assert head_dim * self.num_heads == self.embed_dim, \"embed_dim must be divisible by num_heads\"\n",
    "        scaling = float(head_dim) ** -0.5\n",
    "\n",
    "        q = self.linear_Q(query)\n",
    "        k = self.linear_K(key)\n",
    "        v = self.linear_V(value)\n",
    "\n",
    "        #JP fix here: disabled this\n",
    "        # q = self.q_scaling_product.mul_scalar(q, scaling)\n",
    "\n",
    "        if attn_mask is not None:\n",
    "            if attn_mask.dtype == torch.uint8:\n",
    "                warnings.warn(\"Byte tensor for attn_mask in nn.MultiheadAttention is deprecated. Use bool tensor instead.\")\n",
    "                attn_mask = attn_mask.to(torch.bool)\n",
    "            assert attn_mask.is_floating_point() or attn_mask.dtype == torch.bool, \\\n",
    "                f'Only float and bool types are supported for attn_mask, not {attn_mask.dtype}'\n",
    "\n",
    "            if attn_mask.dim() == 2:\n",
    "                attn_mask = attn_mask.unsqueeze(0)\n",
    "                if list(attn_mask.size()) != [1, query.size(0), key.size(0)]:\n",
    "                    raise RuntimeError('The size of the 2D attn_mask is not correct.')\n",
    "            elif attn_mask.dim() == 3:\n",
    "                if list(attn_mask.size()) != [bsz * self.num_heads, query.size(0), key.size(0)]:\n",
    "                    raise RuntimeError('The size of the 3D attn_mask is not correct.')\n",
    "            else:\n",
    "                raise RuntimeError(f\"attn_mask's dimension {attn_mask.dim()} is not supported\")\n",
    "            # attn_mask's dim is 3 now.\n",
    "\n",
    "        # convert ByteTensor key_padding_mask to bool\n",
    "        if key_padding_mask is not None and key_padding_mask.dtype == torch.uint8:\n",
    "            warnings.warn(\"Byte tensor for key_padding_mask in nn.MultiheadAttention is deprecated. Use bool tensor instead.\")\n",
    "            key_padding_mask = key_padding_mask.to(torch.bool)\n",
    "        if self.bias_k is not None and self.bias_v is not None:\n",
    "            if static_k is None and static_v is None:\n",
    "\n",
    "                # Explicitly assert that bias_k and bias_v are not None\n",
    "                # in a way that TorchScript can understand.\n",
    "                bias_k = self.bias_k\n",
    "                assert bias_k is not None\n",
    "                bias_v = self.bias_v\n",
    "                assert bias_v is not None\n",
    "\n",
    "                k = torch.cat([k, bias_k.repeat(1, bsz, 1)])\n",
    "                v = torch.cat([v, bias_v.repeat(1, bsz, 1)])\n",
    "                if attn_mask is not None:\n",
    "                    attn_mask = nnF.pad(attn_mask, (0, 1))\n",
    "                if key_padding_mask is not None:\n",
    "                    key_padding_mask = nnF.pad(key_padding_mask, (0, 1))\n",
    "            else:\n",
    "                assert static_k is None, \"bias cannot be added to static key.\"\n",
    "                assert static_v is None, \"bias cannot be added to static value.\"\n",
    "        else:\n",
    "            assert self.bias_k is None\n",
    "            assert self.bias_v is None\n",
    "\n",
    "        q = q.contiguous().view(tgt_len, bsz * self.num_heads, head_dim).transpose(0, 1)\n",
    "        if k is not None:\n",
    "            k = k.contiguous().view(-1, bsz * self.num_heads, head_dim).transpose(0, 1)\n",
    "        if v is not None:\n",
    "            v = v.contiguous().view(-1, bsz * self.num_heads, head_dim).transpose(0, 1)\n",
    "\n",
    "        if static_k is not None:\n",
    "            assert static_k.size(0) == bsz * self.num_heads\n",
    "            assert static_k.size(2) == head_dim\n",
    "            k = static_k\n",
    "\n",
    "        if static_v is not None:\n",
    "            assert static_v.size(0) == bsz * self.num_heads\n",
    "            assert static_v.size(2) == head_dim\n",
    "            v = static_v\n",
    "\n",
    "        src_len = k.size(1)\n",
    "\n",
    "        if key_padding_mask is not None:\n",
    "            assert key_padding_mask.size(0) == bsz\n",
    "            assert key_padding_mask.size(1) == src_len\n",
    "\n",
    "        if self.add_zero_attn:\n",
    "            src_len += 1\n",
    "            k_zeros = torch.zeros((k.size(0), 1) + k.size()[2:])\n",
    "            if k.is_quantized:\n",
    "                k_zeros = torch.quantize_per_tensor(k_zeros, k.q_scale(), k.q_zero_point(), k.dtype)\n",
    "            k = torch.cat([k, k_zeros], dim=1)\n",
    "            v_zeros = torch.zeros((v.size(0), 1) + k.size()[2:])\n",
    "            if v.is_quantized:\n",
    "                v_zeros = torch.quantize_per_tensor(v_zeros, v.q_scale(), v.q_zero_point(), v.dtype)\n",
    "            v = torch.cat([v, v_zeros], dim=1)\n",
    "\n",
    "            if attn_mask is not None:\n",
    "                attn_mask = nnF.pad(attn_mask, (0, 1))\n",
    "            if key_padding_mask is not None:\n",
    "                key_padding_mask = nnF.pad(key_padding_mask, (0, 1))\n",
    "\n",
    "        # Leaving the quantized zone here\n",
    "        q = self.dequant_q(q)\n",
    "        k = self.dequant_k(k)\n",
    "        v = self.dequant_v(v)\n",
    "        attn_output_weights = torch.bmm(q, k.transpose(1, 2))\n",
    "        assert list(attn_output_weights.size()) == [bsz * self.num_heads, tgt_len, src_len]\n",
    "\n",
    "        if attn_mask is not None:\n",
    "            if attn_mask.dtype == torch.bool:\n",
    "                attn_output_weights.masked_fill_(attn_mask, float('-inf'))\n",
    "            else:\n",
    "                attn_output_weights += attn_mask\n",
    "\n",
    "        if key_padding_mask is not None:\n",
    "            attn_output_weights = attn_output_weights.view(bsz, self.num_heads, tgt_len, src_len)\n",
    "            attn_output_weights = attn_output_weights.masked_fill(\n",
    "                key_padding_mask.unsqueeze(1).unsqueeze(2),\n",
    "                float('-inf'),\n",
    "            )\n",
    "            attn_output_weights = attn_output_weights.view(bsz * self.num_heads, tgt_len, src_len)\n",
    "\n",
    "        attn_output_weights = nnF.softmax(\n",
    "            attn_output_weights, dim=-1)\n",
    "        attn_output_weights = nnF.dropout(attn_output_weights, p=self.dropout, training=self.training)\n",
    "\n",
    "        attn_output = torch.bmm(attn_output_weights, v)\n",
    "        assert list(attn_output.size()) == [bsz * self.num_heads, tgt_len, head_dim]\n",
    "        if self.batch_first:\n",
    "            attn_output = attn_output.view(bsz, tgt_len, self.embed_dim)\n",
    "        else:\n",
    "            attn_output = attn_output.transpose(0, 1).contiguous().view(tgt_len, bsz, self.embed_dim)\n",
    "\n",
    "        # Reentering the quantized zone\n",
    "        attn_output = self.quant_attn_output(attn_output)\n",
    "        # for the type: ignore[has-type], see https://github.com/pytorch/pytorch/issues/58969\n",
    "        attn_output = self.out_proj(attn_output)  # type: ignore[has-type]\n",
    "\n",
    "        #JP fix: removed need_weights part from here, return attn_output instead of tuple\n",
    "        return attn_output\n",
    "\n",
    "class QuantizedMultiheadAttention(QuantizeableMultiheadAttention):\n",
    "    _FLOAT_MODULE = torch.ao.nn.quantizable.MultiheadAttention\n",
    "\n",
    "    def _get_name(self):\n",
    "        return \"QuantizedMultiheadAttention\"\n",
    "\n",
    "    @classmethod\n",
    "    def from_float(cls, other):\n",
    "        # The whole flow is float -> observed -> quantized\n",
    "        # This class does observed -> quantized only\n",
    "        raise NotImplementedError(\"It looks like you are trying to convert a \"\n",
    "                                  \"non-observed MHA module. Please, see \"\n",
    "                                  \"the examples on quantizable MHAs.\")\n",
    "\n",
    "    @classmethod\n",
    "    def from_observed(cls, other):\n",
    "        converted = torch.ao.quantization.convert(other, mapping=None,\n",
    "                                                  inplace=False,\n",
    "                                                  remove_qconfig=True,\n",
    "                                                  convert_custom_config_dict=None)\n",
    "        converted.__class__ = cls\n",
    "        # Remove the parameters for the bias_k and bias_v to quantize them\n",
    "        # TODO: This is a potential source of accuracy drop.\n",
    "        #       quantized cat takes the scale and zp of the first\n",
    "        #       element, which might lose the precision in the bias_k\n",
    "        #       and the bias_v (which are cat'ed with k/v being first).\n",
    "        if converted.bias_k is not None:\n",
    "            bias_k = converted._parameters.pop('bias_k')\n",
    "            sc, zp = torch._choose_qparams_per_tensor(bias_k,\n",
    "                                                      reduce_range=False)\n",
    "            bias_k = torch.quantize_per_tensor(bias_k, sc, zp, torch.quint8)\n",
    "            setattr(converted, 'bias_k', bias_k)  # noqa: B010\n",
    "\n",
    "        if converted.bias_v is not None:\n",
    "            bias_v = converted._parameters.pop('bias_v')\n",
    "            sc, zp = torch._choose_qparams_per_tensor(bias_k,  # type: ignore[possibly-undefined]\n",
    "                                                      reduce_range=False)\n",
    "            bias_v = torch.quantize_per_tensor(bias_v, sc, zp, torch.quint8)\n",
    "            setattr(converted, 'bias_v', bias_v)  # noqa: B010\n",
    "\n",
    "        del converted.in_proj_weight\n",
    "        del converted.in_proj_bias\n",
    "\n",
    "        return converted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aa692873",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    \"\"\"Focal Loss, as described in https://arxiv.org/abs/1708.02002.\n",
    "    It is essentially an enhancement to cross entropy loss and is\n",
    "    useful for classification tasks when there is a large class imbalance.\n",
    "    x is expected to contain raw, unnormalized scores for each class.\n",
    "    y is expected to contain class labels.\n",
    "    Shape:\n",
    "        - x: (batch_size, C) or (batch_size, C, d1, d2, ..., dK), K > 0.\n",
    "        - y: (batch_size,) or (batch_size, d1, d2, ..., dK), K > 0.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, alpha = None, gamma = 0.0, reduction = \"mean\", ignore_index = -100\n",
    "    ):\n",
    "        \"\"\"Constructor.\n",
    "        Args:\n",
    "            alpha (Tensor, optional): Weights for each class. Defaults to None.\n",
    "            gamma (float, optional): A constant, as described in the paper.\n",
    "                Defaults to 0.\n",
    "            reduction (str, optional): 'mean', 'sum' or 'none'.\n",
    "                Defaults to 'mean'.\n",
    "            ignore_index (int, optional): class label to ignore.\n",
    "                Defaults to -100.\n",
    "        \"\"\"\n",
    "        if reduction not in (\"mean\", \"sum\", \"none\"):\n",
    "            raise ValueError('Reduction must be one of: \"mean\", \"sum\", \"none\".')\n",
    "\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "        self.nll_loss = nn.NLLLoss(weight=alpha, reduction=\"none\")\n",
    "\n",
    "    def __repr__(self):\n",
    "        arg_keys = [\"alpha\", \"gamma\", \"reduction\"]\n",
    "        arg_vals = [self.__dict__[k] for k in arg_keys]\n",
    "        arg_strs = [f\"{k}={v!r}\" for k, v in zip(arg_keys, arg_vals)]\n",
    "        arg_str = \", \".join(arg_strs)\n",
    "        return f\"{type(self).__name__}({arg_str})\"\n",
    "\n",
    "    def forward(self, x: Tensor, y: Tensor) -> Tensor:\n",
    "        if x.ndim > 2:\n",
    "            # (N, C, d1, d2, ..., dK) --> (N * d1 * ... * dK, C)\n",
    "            c = x.shape[1]\n",
    "            x = x.permute(0, *range(2, x.ndim), 1).reshape(-1, c)\n",
    "            # (N, d1, d2, ..., dK) --> (N * d1 * ... * dK,)\n",
    "            y = y.view(-1)\n",
    "\n",
    "        # compute weighted cross entropy term: -alpha * log(pt)\n",
    "        # (alpha is already part of self.nll_loss)\n",
    "        log_p = F.log_softmax(x, dim=-1)\n",
    "        ce = self.nll_loss(log_p, y)\n",
    "\n",
    "        # get true class column from each row\n",
    "        # this is slow due to indexing\n",
    "        # all_rows = torch.arange(len(x))\n",
    "        # log_pt = log_p[all_rows, y]\n",
    "        log_pt = torch.gather(log_p, 1, y.unsqueeze(axis=-1)).squeeze(axis=-1)\n",
    "\n",
    "        # compute focal term: (1 - pt)^gamma\n",
    "        pt = log_pt.exp()\n",
    "        focal_term = (1 - pt) ** self.gamma\n",
    "\n",
    "        # the full loss: -alpha * ((1 - pt)^gamma) * log(pt)\n",
    "        loss = focal_term * ce\n",
    "\n",
    "        if self.reduction == \"mean\":\n",
    "            loss = loss.mean()\n",
    "        elif self.reduction == \"sum\":\n",
    "            loss = loss.sum()\n",
    "\n",
    "        return loss\n",
    "        \n",
    "def mlpf_loss(y, ypred, mask):\n",
    "    loss = {}\n",
    "    loss_obj_id = FocalLoss(gamma=2.0, reduction=\"none\")\n",
    "\n",
    "    msk_true_particle = torch.unsqueeze((y[\"cls_id\"] != 0).to(dtype=torch.float32), axis=-1)\n",
    "    nelem = torch.sum(mask)\n",
    "    npart = torch.sum(y[\"cls_id\"] != 0)\n",
    "    \n",
    "    ypred[\"momentum\"] = ypred[\"momentum\"] * msk_true_particle\n",
    "    y[\"momentum\"] = y[\"momentum\"] * msk_true_particle\n",
    "\n",
    "    ypred[\"cls_id_onehot\"] = ypred[\"cls_id_onehot\"].permute((0, 2, 1))\n",
    "\n",
    "    loss_classification = loss_obj_id(ypred[\"cls_id_onehot\"], y[\"cls_id\"]).reshape(y[\"cls_id\"].shape)\n",
    "    loss_regression = torch.nn.functional.huber_loss(ypred[\"momentum\"], y[\"momentum\"], reduction=\"none\")\n",
    "    \n",
    "    # average over all elements that were not padded\n",
    "    loss[\"Classification\"] = loss_classification.sum() / npart\n",
    "    \n",
    "    mom_normalizer = y[\"momentum\"][y[\"cls_id\"] != 0].std(axis=0)\n",
    "    reg_losses = loss_regression[y[\"cls_id\"] != 0]\n",
    "    # average over all true particles\n",
    "    loss[\"Regression\"] = (reg_losses / mom_normalizer).sum() / npart\n",
    "\n",
    "    px = ypred[\"momentum\"][..., 0:1] * ypred[\"momentum\"][..., 3:4] * msk_true_particle\n",
    "    py = ypred[\"momentum\"][..., 0:1] * ypred[\"momentum\"][..., 2:3] * msk_true_particle\n",
    "    pred_met = torch.sqrt(torch.sum(px, axis=-2) ** 2 + torch.sum(py, axis=-2) ** 2)\n",
    "\n",
    "    px = y[\"momentum\"][..., 0:1] * y[\"momentum\"][..., 3:4] * msk_true_particle\n",
    "    py = y[\"momentum\"][..., 0:1] * y[\"momentum\"][..., 2:3] * msk_true_particle\n",
    "    true_met = torch.sqrt(torch.sum(px, axis=-2) ** 2 + torch.sum(py, axis=-2) ** 2)\n",
    "    loss[\"MET\"] = torch.nn.functional.huber_loss(pred_met, true_met).mean()\n",
    "\n",
    "    loss[\"Total\"] = loss[\"Classification\"] + loss[\"Regression\"]\n",
    "    # loss[\"Total\"] += 0.1*loss[\"MET\"]\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916bf3fb",
   "metadata": {},
   "source": [
    "### Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3398392d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantizeFeaturesStub(torch.ao.quantization.QuantStub):\n",
    "    def __init__(self, num_feats):\n",
    "        super().__init__()\n",
    "        self.num_feats = num_feats\n",
    "        self.quants = torch.nn.ModuleList()\n",
    "        for ifeat in range(self.num_feats):\n",
    "            self.quants.append(torch.ao.quantization.QuantStub())\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.cat([self.quants[ifeat](x[..., ifeat:ifeat+1]) for ifeat in range(self.num_feats)], axis=-1)\n",
    "        \n",
    "class SelfAttentionLayer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        embedding_dim=128,\n",
    "        num_heads=2,\n",
    "        width=128,\n",
    "        dropout_mha=0.1,\n",
    "        dropout_ff=0.1,\n",
    "        attention_type=\"efficient\",\n",
    "    ):\n",
    "        super(SelfAttentionLayer, self).__init__()\n",
    "\n",
    "        self.attention_type = attention_type\n",
    "        self.act = nn.ReLU\n",
    "        self.mha = torch.nn.MultiheadAttention(embedding_dim, num_heads, dropout=dropout_mha, batch_first=True)\n",
    "        self.norm0 = torch.nn.LayerNorm(embedding_dim)\n",
    "        self.norm1 = torch.nn.LayerNorm(embedding_dim)\n",
    "        self.seq = torch.nn.Sequential(\n",
    "            nn.Linear(embedding_dim, width), self.act(), nn.Linear(width, embedding_dim), self.act()\n",
    "        )\n",
    "        self.dropout = torch.nn.Dropout(dropout_ff)\n",
    "\n",
    "        self.add0 = torch.ao.nn.quantized.FloatFunctional()\n",
    "        self.add1 = torch.ao.nn.quantized.FloatFunctional()\n",
    "        self.mul = torch.ao.nn.quantized.FloatFunctional()\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        mha_out = self.mha(x, x, x, need_weights=False)[0]\n",
    "        x = self.add0.add(x, mha_out)\n",
    "        x = self.norm0(x)\n",
    "        x = self.add1.add(x, self.seq(x))\n",
    "        x = self.norm1(x)\n",
    "        x = self.dropout(x)\n",
    "        # x = self.mul.mul(x, mask.unsqueeze(-1))\n",
    "        return x\n",
    "\n",
    "class RegressionOutput(nn.Module):\n",
    "    def __init__(self, embed_dim, width, act, dropout):\n",
    "        super(RegressionOutput, self).__init__()\n",
    "        self.dequant = torch.ao.quantization.DeQuantStub()\n",
    "        self.nn = ffn(embed_dim, 1, width, act, dropout)\n",
    "\n",
    "    def forward(self, elems, x, orig_value):\n",
    "        nn_out = self.nn(x)\n",
    "        nn_out = self.dequant(nn_out)\n",
    "        return orig_value + nn_out\n",
    "\n",
    "def ffn(input_dim, output_dim, width, act, dropout):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(input_dim, width),\n",
    "        act(),\n",
    "        torch.nn.LayerNorm(width),\n",
    "        nn.Dropout(dropout),\n",
    "        nn.Linear(width, output_dim),\n",
    "    )\n",
    "\n",
    "def transform_batch(Xbatch):\n",
    "    Xbatch = Xbatch.clone()\n",
    "    Xbatch[..., 1] = torch.log(Xbatch[..., 1])\n",
    "    Xbatch[..., 5] = torch.log(Xbatch[..., 5])\n",
    "    Xbatch[torch.isnan(Xbatch)] = 0.0\n",
    "    Xbatch[torch.isinf(Xbatch)] = 0.0\n",
    "    return Xbatch\n",
    "    \n",
    "def unpack_target(y):\n",
    "    ret = {}\n",
    "    ret[\"cls_id\"] = y[..., 0].long()\n",
    "\n",
    "    for i, feat in enumerate(Y_FEATURES):\n",
    "        if i >= 2:  # skip the cls and charge as they are defined above\n",
    "            ret[feat] = y[..., i].to(dtype=torch.float32)\n",
    "    ret[\"phi\"] = torch.atan2(ret[\"sin_phi\"], ret[\"cos_phi\"])\n",
    "    \n",
    "    # note ~ momentum = [\"pt\", \"eta\", \"sin_phi\", \"cos_phi\", \"energy\"]\n",
    "    ret[\"momentum\"] = y[..., 2:7].to(dtype=torch.float32)\n",
    "    ret[\"p4\"] = torch.cat(\n",
    "        [ret[\"pt\"].unsqueeze(1), ret[\"eta\"].unsqueeze(1), ret[\"phi\"].unsqueeze(1), ret[\"energy\"].unsqueeze(1)], axis=1\n",
    "    )\n",
    "\n",
    "    return ret\n",
    "\n",
    "\n",
    "def unpack_predictions(preds):\n",
    "    ret = {}\n",
    "    ret[\"cls_id_onehot\"], ret[\"momentum\"] = preds\n",
    "\n",
    "    ret[\"pt\"] = ret[\"momentum\"][..., 0]\n",
    "    ret[\"eta\"] = ret[\"momentum\"][..., 1]\n",
    "    ret[\"sin_phi\"] = ret[\"momentum\"][..., 2]\n",
    "    ret[\"cos_phi\"] = ret[\"momentum\"][..., 3]\n",
    "    ret[\"energy\"] = ret[\"momentum\"][..., 4]\n",
    "\n",
    "    ret[\"cls_id\"] = torch.argmax(ret[\"cls_id_onehot\"], axis=-1)\n",
    "    ret[\"phi\"] = torch.atan2(ret[\"sin_phi\"], ret[\"cos_phi\"])\n",
    "    ret[\"p4\"] = torch.cat(\n",
    "        [\n",
    "            ret[\"pt\"].unsqueeze(axis=-1),\n",
    "            ret[\"eta\"].unsqueeze(axis=-1),\n",
    "            ret[\"phi\"].unsqueeze(axis=-1),\n",
    "            ret[\"energy\"].unsqueeze(axis=-1),\n",
    "        ],\n",
    "        axis=-1,\n",
    "    )\n",
    "\n",
    "    return ret\n",
    "\n",
    "class MLPF(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim=16,\n",
    "        num_classes=6,\n",
    "        num_convs=2,\n",
    "        dropout_ff=0.0,\n",
    "        dropout_conv_reg_mha=0.0,\n",
    "        dropout_conv_reg_ff=0.0,\n",
    "        dropout_conv_id_mha=0.0,\n",
    "        dropout_conv_id_ff=0.0,\n",
    "        num_heads=16,\n",
    "        head_dim=16,\n",
    "        elemtypes=[0,1,2],\n",
    "    ):\n",
    "        super(MLPF, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.act = nn.ReLU\n",
    "        self.elemtypes = elemtypes\n",
    "        self.num_elemtypes = len(self.elemtypes)\n",
    "\n",
    "        embedding_dim = num_heads * head_dim\n",
    "        width = num_heads * head_dim\n",
    "        \n",
    "        self.nn0_id = ffn(self.input_dim, embedding_dim, width, self.act, dropout_ff)\n",
    "        self.nn0_reg = ffn(self.input_dim, embedding_dim, width, self.act, dropout_ff)\n",
    "        \n",
    "        self.conv_id = nn.ModuleList()\n",
    "        self.conv_reg = nn.ModuleList()\n",
    "\n",
    "        for i in range(num_convs):\n",
    "            self.conv_id.append(\n",
    "                SelfAttentionLayer(\n",
    "                    embedding_dim=embedding_dim,\n",
    "                    num_heads=num_heads,\n",
    "                    width=width,\n",
    "                    dropout_mha=dropout_conv_id_mha,\n",
    "                    dropout_ff=dropout_conv_id_ff,\n",
    "                )\n",
    "            )\n",
    "            self.conv_reg.append(\n",
    "                SelfAttentionLayer(\n",
    "                    embedding_dim=embedding_dim,\n",
    "                    num_heads=num_heads,\n",
    "                    width=width,\n",
    "                    dropout_mha=dropout_conv_reg_mha,\n",
    "                    dropout_ff=dropout_conv_reg_ff,\n",
    "                )\n",
    "            )\n",
    "\n",
    "        decoding_dim = self.input_dim + embedding_dim\n",
    "\n",
    "        # DNN that acts on the node level to predict the PID\n",
    "        self.nn_id = ffn(decoding_dim, num_classes, width, self.act, dropout_ff)\n",
    "\n",
    "        # elementwise DNN for node momentum regression\n",
    "        embed_dim = decoding_dim + num_classes\n",
    "        self.nn_pt = RegressionOutput(embed_dim, width, self.act, dropout_ff)\n",
    "        self.nn_eta = RegressionOutput(embed_dim, width, self.act, dropout_ff)\n",
    "        self.nn_sin_phi = RegressionOutput(embed_dim, width, self.act, dropout_ff)\n",
    "        self.nn_cos_phi = RegressionOutput(embed_dim, width, self.act, dropout_ff)\n",
    "        self.nn_energy = RegressionOutput(embed_dim, width, self.act, dropout_ff)\n",
    "        \n",
    "        self.quant = QuantizeFeaturesStub(self.input_dim + len(self.elemtypes))\n",
    "        self.dequant_id = torch.ao.quantization.DeQuantStub()\n",
    "\n",
    "    def forward(self, X_features, mask):\n",
    "        Xfeat_transformed = transform_batch(X_features)\n",
    "        Xfeat_normed = self.quant(Xfeat_transformed)\n",
    "\n",
    "        embeddings_id, embeddings_reg = [], []\n",
    "        embedding_id = self.nn0_id(Xfeat_normed)\n",
    "        embedding_reg = self.nn0_reg(Xfeat_normed)\n",
    "        for num, conv in enumerate(self.conv_id):\n",
    "            conv_input = embedding_id if num == 0 else embeddings_id[-1]\n",
    "            out_padded = conv(conv_input, mask)\n",
    "            embeddings_id.append(out_padded)\n",
    "        for num, conv in enumerate(self.conv_reg):\n",
    "            conv_input = embedding_reg if num == 0 else embeddings_reg[-1]\n",
    "            out_padded = conv(conv_input, mask)\n",
    "            embeddings_reg.append(out_padded)\n",
    "\n",
    "        final_embedding_id = torch.cat([Xfeat_normed] + [embeddings_id[-1]], axis=-1)\n",
    "        preds_id = self.nn_id(final_embedding_id)\n",
    "\n",
    "        final_embedding_reg = torch.cat([Xfeat_normed] + [embeddings_reg[-1]] + [preds_id], axis=-1)\n",
    "        preds_pt = self.nn_pt(X_features, final_embedding_reg, X_features[..., 1:2])\n",
    "        preds_eta = self.nn_eta(X_features, final_embedding_reg, X_features[..., 2:3])\n",
    "        preds_sin_phi = self.nn_sin_phi(X_features, final_embedding_reg, X_features[..., 3:4])\n",
    "        preds_cos_phi = self.nn_cos_phi(X_features, final_embedding_reg, X_features[..., 4:5])\n",
    "        preds_energy = self.nn_energy(X_features, final_embedding_reg, X_features[..., 5:6])\n",
    "        preds_momentum = torch.cat([preds_pt, preds_eta, preds_sin_phi, preds_cos_phi, preds_energy], axis=-1)\n",
    "        \n",
    "        preds_id = self.dequant_id(preds_id)\n",
    "        return preds_id, preds_momentum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13b02bb",
   "metadata": {},
   "source": [
    "# Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7eedb51a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 200/200 [00:40<00:00,  4.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, loss=1.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 200/200 [00:33<00:00,  6.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, loss=0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 200/200 [00:33<00:00,  5.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, loss=0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 200/200 [00:33<00:00,  5.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, loss=0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 200/200 [00:33<00:00,  5.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, loss=0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 200/200 [00:33<00:00,  5.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, loss=0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 200/200 [00:33<00:00,  6.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, loss=0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 200/200 [00:33<00:00,  6.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, loss=0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 200/200 [00:33<00:00,  6.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, loss=0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 200/200 [00:33<00:00,  6.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, loss=0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "max_events_train = 10000\n",
    "max_events_eval = 5000\n",
    "events_per_batch = 50\n",
    "nepochs = 10\n",
    "\n",
    "model = MLPF(input_dim=INPUT_DIM, num_classes=NUM_CLASSES).to(device=device)\n",
    "optimizer = torch.optim.Adam(lr=1e-4, params=model.parameters())\n",
    "\n",
    "#Training loop\n",
    "loss_vals_epochs = []\n",
    "for epoch in range(nepochs):\n",
    "    loss_vals_steps = []\n",
    "    inds_train = range(0,max_events_train,events_per_batch)\n",
    "    for ind in tqdm.tqdm(inds_train):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        #load the data for one batch\n",
    "        ds_elems = [ds_train[i] for i in range(ind,ind+events_per_batch)]\n",
    "        X_features = [torch.tensor(elem[\"X\"]).to(torch.float32) for elem in ds_elems]\n",
    "        y_targets = [torch.tensor(elem[\"ygen\"]).to(torch.float32) for elem in ds_elems]\n",
    "\n",
    "        #batch the data into [batch_size, num_elems, num_features]\n",
    "        X_features_padded = pad_sequence(X_features, batch_first=True).to(device=device)\n",
    "        y_targets_padded = pad_sequence(y_targets, batch_first=True).to(device=device)\n",
    "        mask = X_features_padded[:, :, 0]!=0\n",
    "\n",
    "        #run the model\n",
    "        preds = model(X_features_padded, mask)\n",
    "        preds_unpacked = unpack_predictions(preds)\n",
    "        targets_unpacked = unpack_target(y_targets_padded)\n",
    "\n",
    "        #compute loss, update model weights\n",
    "        loss = mlpf_loss(targets_unpacked, preds_unpacked, mask)\n",
    "        loss[\"Total\"].backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        loss_vals_steps.append(loss[\"Total\"].detach().cpu().item())\n",
    "\n",
    "    loss_vals_epochs.append(np.mean(loss_vals_steps))\n",
    "    print(\"Epoch {}, loss={:.2f}\".format(epoch, loss_vals_epochs[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "40ca3dfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fb0344c0670>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_vals_epochs, label=\"training loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099839cc",
   "metadata": {},
   "source": [
    "# Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a2b93784",
   "metadata": {},
   "outputs": [],
   "source": [
    "#put the model back on CPU\n",
    "model = model.to(device=\"cpu\")\n",
    "\n",
    "#get the validation data\n",
    "ds_elems = [ds_train[i] for i in range(max_events_train,max_events_train+max_events_eval)]\n",
    "X_features = [torch.tensor(elem[\"X\"]).to(torch.float32) for elem in ds_elems]\n",
    "X_features_padded = pad_sequence(X_features, batch_first=True)\n",
    "y_targets = [torch.tensor(elem[\"ygen\"]).to(torch.float32) for elem in ds_elems]\n",
    "y_targets_padded = pad_sequence(y_targets, batch_first=True)\n",
    "mask = X_features_padded[:, :, 0]!=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9479f82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model(X_features_padded, mask)\n",
    "preds = preds[0].detach(), preds[1].detach()\n",
    "mask = X_features_padded[:, :, 0:1] != 0\n",
    "preds_unpacked = unpack_predictions(preds)\n",
    "targets_unpacked = unpack_target(y_targets_padded)\n",
    "\n",
    "loss = mlpf_loss(targets_unpacked, preds_unpacked, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b5cff804",
   "metadata": {},
   "outputs": [],
   "source": [
    "msk_true_particles = targets_unpacked[\"cls_id\"]!=0\n",
    "msk_pred_particles = preds_unpacked[\"cls_id\"]!=0\n",
    "\n",
    "\n",
    "pt_target = targets_unpacked[\"pt\"][msk_true_particles].numpy()\n",
    "pt_pred = preds_unpacked[\"pt\"][msk_true_particles].numpy()\n",
    "\n",
    "eta_target = targets_unpacked[\"eta\"][msk_true_particles].numpy()\n",
    "eta_pred = preds_unpacked[\"eta\"][msk_true_particles].numpy()\n",
    "\n",
    "sphi_target = targets_unpacked[\"sin_phi\"][msk_true_particles].numpy()\n",
    "sphi_pred = preds_unpacked[\"sin_phi\"][msk_true_particles].numpy()\n",
    "\n",
    "cphi_target = targets_unpacked[\"cos_phi\"][msk_true_particles].numpy()\n",
    "cphi_pred = preds_unpacked[\"cos_phi\"][msk_true_particles].numpy()\n",
    "\n",
    "energy_target = targets_unpacked[\"energy\"][msk_true_particles].numpy()\n",
    "energy_pred = preds_unpacked[\"energy\"][msk_true_particles].numpy()\n",
    "\n",
    "px = preds_unpacked[\"pt\"] * preds_unpacked[\"cos_phi\"] * msk_true_particles\n",
    "py = preds_unpacked[\"pt\"] * preds_unpacked[\"sin_phi\"] * msk_true_particles\n",
    "pred_met = torch.sqrt(torch.sum(px, axis=-2) ** 2 + torch.sum(py, axis=-2) ** 2)\n",
    "\n",
    "px = targets_unpacked[\"pt\"] * targets_unpacked[\"cos_phi\"] * msk_true_particles\n",
    "py = targets_unpacked[\"pt\"] * targets_unpacked[\"sin_phi\"] * msk_true_particles\n",
    "true_met = torch.sqrt(torch.sum(px, axis=-2) ** 2 + torch.sum(py, axis=-2) ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51bc323",
   "metadata": {},
   "source": [
    "Is this right?\n",
    "\n",
    "true_met is PF while the pred_met is the MLPF\n",
    "\n",
    "targets_unpacked is the yvlas for the gen particle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4f96d466",
   "metadata": {},
   "outputs": [],
   "source": [
    "px = targets_unpacked[\"pt\"] * targets_unpacked[\"cos_phi\"] * msk_true_particles\n",
    "py = targets_unpacked[\"pt\"] * targets_unpacked[\"sin_phi\"] * msk_true_particles\n",
    "pz = targets_unpacked[\"pt\"] * np.sinh(targets_unpacked[\"eta\"]) * msk_true_particles\n",
    "phi = np.arctan2(targets_unpacked[\"sin_phi\"], targets_unpacked[\"cos_phi\"]) * msk_true_particles\n",
    "\n",
    "px_np = px.detach().cpu().numpy()\n",
    "py_np = py.detach().cpu().numpy()\n",
    "pz_np = pz.detach().cpu().numpy()\n",
    "phi_np = phi.detach().cpu().numpy()\n",
    "\n",
    "# print(\"px_np\", px_np)\n",
    "# print(\"py_np\", py_np)\n",
    "# print(\"pz_np\", pz_np)\n",
    "# print(\"phi_np\", phi_np)\n",
    "\n",
    "true_mom = np.sqrt(np.sum(px_np, axis=1)**2 + np.sum(py_np, axis=1)**2 + np.sum(pz_np, axis=1)**2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1c937eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "px = preds_unpacked[\"pt\"] * preds_unpacked[\"cos_phi\"] * msk_pred_particles\n",
    "py = preds_unpacked[\"pt\"] * preds_unpacked[\"sin_phi\"] * msk_pred_particles\n",
    "pz = preds_unpacked[\"pt\"] * np.sinh(preds_unpacked[\"eta\"]) * msk_pred_particles\n",
    "phi = np.arctan2(preds_unpacked[\"sin_phi\"], preds_unpacked[\"cos_phi\"]) * msk_pred_particles\n",
    "\n",
    "px_np = px.detach().cpu().numpy()\n",
    "py_np = py.detach().cpu().numpy()\n",
    "pz_np = pz.detach().cpu().numpy()\n",
    "phi_np = phi.detach().cpu().numpy()\n",
    "\n",
    "# print(\"px_np\", px_np)\n",
    "# print(\"py_np\", py_np)\n",
    "# print(\"pz_np\", pz_np)\n",
    "# print(\"phi_np\", phi_np)\n",
    "\n",
    "pred_mom = np.sqrt(np.sum(px_np, axis=1)**2 + np.sum(py_np, axis=1)**2 + np.sum(pz_np, axis=1)**2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "10dd95e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5000, 280])\n",
      "torch.Size([5000, 280])\n"
     ]
    }
   ],
   "source": [
    "print(msk_true_particles.shape)\n",
    "print(msk_pred_particles.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fb4a5ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def med_iqr(arr):\n",
    "    if len(arr) > 0:\n",
    "        p25 = np.percentile(arr, 25)\n",
    "        p50 = np.percentile(arr, 50)\n",
    "        p75 = np.percentile(arr, 75)\n",
    "    else:\n",
    "        p25 = 0.0\n",
    "        p50 = 0.0\n",
    "        p75 = 0.0\n",
    "    return p50, p75 - p25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1a62b700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true_momentum: [ 2.8392746 11.047623  33.464092  ... 39.577892  89.680504  10.5933895]\n"
     ]
    }
   ],
   "source": [
    "print(\"true_momentum:\",true_mom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "37d18b15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred_momentum: [ 42.46911   49.149784  48.077187 ...  90.43628  111.28069   20.719532]\n"
     ]
    }
   ],
   "source": [
    "print(\"pred_momentum:\",pred_mom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4d21068c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000,)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_mom.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1db757eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000,)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_mom.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d53d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_bins = [ 10, 20, 30, 40, 60, 80, 100, 200]\n",
    "\n",
    "x_vals = []\n",
    "for ibin in range(len(gen_bins)-1):\n",
    "    lim_low = gen_bins[ibin]\n",
    "    lim_hi = gen_bins[ibin + 1]\n",
    "    x_vals.append(np.mean([lim_low, lim_hi]))\n",
    "    \n",
    "    msk_genmet = (true_mom > lim_low) & (true_mom <= lim_hi)\n",
    "    \n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572a1cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "msk_genmet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1fb960b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bins\n",
    "bins = [10, 20, 30, 40, 60, 80, 100, 200]\n",
    "\n",
    "x_vals = []\n",
    "true_iqr_median_ratios = []\n",
    "pred_iqr_median_ratios = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50522479",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ibin in range(len(bins) - 1):\n",
    "    lim_low = bins[ibin]\n",
    "    lim_hi = bins[ibin + 1]\n",
    "    x_vals.append(np.mean([lim_low, lim_hi]))\n",
    "\n",
    "    # values within the bin\n",
    "    true_values_in_bin = true_mom[(true_mom > lim_low) & (true_mom <= lim_hi)]\n",
    "    pred_values_in_bin = pred_mom[(pred_mom > lim_low) & (pred_mom <= lim_hi)]\n",
    "\n",
    "    if len(true_values_in_bin) > 0:\n",
    "        true_iqr = np.percentile(true_values_in_bin, 75) - np.percentile(true_values_in_bin, 25)\n",
    "        true_median = np.median(true_values_in_bin)\n",
    "        true_iqr_median_ratio = true_iqr / true_median\n",
    "        true_iqr_median_ratios.append(true_iqr_median_ratio)\n",
    "    else:\n",
    "        true_iqr_median_ratios.append(np.nan)\n",
    "\n",
    "    if len(pred_values_in_bin) > 0:\n",
    "        pred_iqr = np.percentile(pred_values_in_bin, 75) - np.percentile(pred_values_in_bin, 25)\n",
    "        pred_median = np.median(pred_values_in_bin)\n",
    "        pred_iqr_median_ratio = pred_iqr / pred_median\n",
    "        pred_iqr_median_ratios.append(pred_iqr_median_ratio)\n",
    "    else:\n",
    "        pred_iqr_median_ratios.append(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0317597",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Length of x_vals:\", len(x_vals))\n",
    "print(\"Length of true_iqr_median_ratios:\", len(true_iqr_median_ratios))\n",
    "print(\"Length of pred_iqr_median_ratios:\", len(pred_iqr_median_ratios))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dea0f00",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(x_vals, true_iqr_median_ratios, label='True Momentum', color='blue', alpha=1)\n",
    "plt.scatter(x_vals, pred_iqr_median_ratios, label='Predicted Momentum', color='red', alpha=1)\n",
    "plt.xlabel('Momentum')\n",
    "plt.ylabel('IQR/Median Ratio')\n",
    "plt.legend()\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf45bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ROOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3c76ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot IQR/median ratio versus momentum\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(x_vals, true_iqr_median_ratios, label='True Momentum', color='blue', alpha=0.5)\n",
    "plt.scatter(x_vals, pred_iqr_median_ratios, label='Predicted Momentum', color='red', alpha=0.5)\n",
    "plt.plot(x_vals, true_iqr_median_ratios, linestyle='-', color='blue', alpha=0.7)\n",
    "plt.plot(x_vals, pred_iqr_median_ratios, linestyle='-', color='red', alpha=0.7)\n",
    "plt.xlabel('Momentum')\n",
    "plt.ylabel('$IQR/Median Ratio$')\n",
    "# plt.title('IQR/Median Ratio vs Momentum (Binned)')\n",
    "plt.legend()\n",
    "plt.grid(False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfdb6d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a TGraph\n",
    "gr_true = ROOT.TGraph(len(x_vals), np.array(x_vals), np.array(true_iqr_median_ratios))\n",
    "gr_pred = ROOT.TGraph(len(x_vals), np.array(x_vals), np.array(pred_iqr_median_ratios))\n",
    "\n",
    "# Set the titles to empty strings\n",
    "gr_true.SetTitle(\"\")\n",
    "gr_pred.SetTitle(\"\")\n",
    "\n",
    "# Create a canvas\n",
    "canvas = ROOT.TCanvas(\"canvas\", \"\", 800, 600)\n",
    "\n",
    "# Draw the graphs\n",
    "gr_true.SetMarkerStyle(20)\n",
    "gr_true.SetMarkerColor(ROOT.kBlue)\n",
    "gr_true.SetLineColor(ROOT.kBlue)\n",
    "gr_true.GetXaxis().SetTitle(\"P_{gen}(GeV)\")\n",
    "gr_true.GetYaxis().SetTitle(\"IQR/Median\")\n",
    "# Set number of divisions for the x and y axes\n",
    "gr_true.GetXaxis().SetNdivisions(510)\n",
    "gr_true.GetYaxis().SetNdivisions(510)\n",
    "gr_true.Draw(\"AP\")\n",
    "\n",
    "gr_pred.SetMarkerStyle(20)\n",
    "gr_pred.SetMarkerColor(ROOT.kRed)\n",
    "gr_pred.SetLineColor(ROOT.kRed)\n",
    "gr_pred.Draw(\"P\")\n",
    "\n",
    "# Create a TGraph for the line representing the true momentum\n",
    "line_true = ROOT.TGraph(len(x_vals), np.array(x_vals), np.array(true_iqr_median_ratios))\n",
    "line_true.SetLineColor(ROOT.kBlue)\n",
    "line_true.SetLineWidth(2)\n",
    "line_true.Draw(\"L\")\n",
    "\n",
    "# Create a TGraph for the line representing the predicted momentum\n",
    "line_pred = ROOT.TGraph(len(x_vals), np.array(x_vals), np.array(pred_iqr_median_ratios))\n",
    "line_pred.SetLineColor(ROOT.kRed)\n",
    "line_pred.SetLineWidth(2)\n",
    "line_pred.Draw(\"L\")\n",
    "\n",
    "# Add legend\n",
    "legend = ROOT.TLegend(0.7, 0.7, 0.9, 0.9)\n",
    "legend.AddEntry(gr_true, \"True Momentum\", \"p\")\n",
    "legend.AddEntry(gr_pred, \"Predicted Momentum\", \"p\")\n",
    "legend.Draw()\n",
    "\n",
    "# Show the canvas\n",
    "canvas.Draw()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8601c4b0",
   "metadata": {},
   "source": [
    "# Corrected one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f3d20f52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning in <TCanvas::Constructor>: Deleting canvas with same name: canvas\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxwAAAI8CAIAAAD0vjrdAAAABmJLR0QAAAAAAAD5Q7t/AAAgAElEQVR4nO3dQXLbRr4/8Mar2bpk751UbgJw9+YdJIntA7wkG4CrzDtA4pQv8l8SuEhqakZ7SxcI/oseIwhIgpQEkgD686lUSiJBCk3K7K+6G7/O2rYNAAC8zH/d+gQAANZAqAIAmIBQBQAwAaEKAGACQhUAwASEKgCACQhVAAATEKoAACYgVAEATECoAgCYgFAFADABoQoAYAJCFQDABIQqAIAJCFUAABMQqgAAJiBUAQBMQKgCAJiAUAUAMAGhCgBgAkIVAMAEhCoAgAkIVQAAExCqAAAmIFQBAExAqAIAmIBQBQAwAaEKAGACQhUAwASEKgCACQhVAAATEKoAACYgVAEATECoAgCYgFAFADABoQoAYAJCFQDABIQqAIAJCFUAABMQqgAAJiBUAQBMQKgCAJiAUAUAMAGhCgBgAkIVAMAEhCoAgAkIVQAAExCqAAAmIFQBAExAqAIAmIBQBQAwAaEKAGACQhUAwASEKgCACQhVAAATEKoAACbwt1ufwFVlWXbrUwCAhLRte+tTuJ60QlVI7N0F4Jgsy/QIl5baWIbpPwCACdwyVFVVVRRFURRVVZ3/qP3jsz1PekIAgJe72fRfURRN08Svm6ap67qu6zMfVRTFRc8NAOCpbjNSVdd10zRlWbZt27ZtWZYxV53zqP0bQwi73a7tMVIFAFzZbULVZrMJIXTRJ35xMgltNps8zwc3xlBl7AoAuK2brakaxKM8z/dHofpibNofzepuOXMCEQDgEm65pur8g6uqappm5NrX/kWbeZ5LVwDAld1gpOpg4hnJWHVdb7fb3W538N44vjVYnjXybPuXCp7pia0EANJyIlRVVTV5yHjq+qe4lOrYo+IS9f7yrPGZxPa5nnTOAEBqxqb/4hBR2Fv/dAnHJuxiWhrUpqrruqtxtR+2YtmFuq6tXgcArmYsVMUcc6FBmicte4rZrtM0zclqVRIVAHBNJ6b/LjRGtT9DF8tW7R9ZVdX+NFxcQVUURV3X+/XTrVIHAK5vLFTFa+4u8VO7Sb34bfyiy0YHo9JBRVHkeb7dbrsgFc/5YD4DALicsem/GFnigNC0P7UoirIst9ttt+B9/+K+M39oTGCxmmhUlqWK6gDAlWUjS6bquu6HlYFJ1lpNVQ89Vv48uG69L8vG2gtAOvQIV5Dai3yi+Oelr/ubajn5yTgFAHBRaUXI1CIzAMfoEa4gtRf5mRXVq6pykR0AQOf03n/7i77ruj5ZJgoAICknQtWx7WhG9o2ZufENdpIapQQAJnSiTlX4srle6G1aHJZcr9wGfwDAJYyFqn69g7Isu0VUu91usG8MAEDizt2mJu5S3H0d7AYDANAzFqoEKQCAM50oIBGXde92u6Io4tdxHrBpmiWuQEqtYAYAx+gRriC1F/nE9N9ut+tmAOP2fNvt1o7FAAADT46QcYu9y5zMxaUWmQE4Ro9wBam9yIm1NrF3F4Bj9AhXkNqLfGD6L8uybll6dty1zxQAYMYOVFTvV0vvFlQBADAirXG51MYhAThGj3AFqb3IJ67+45qaJqHfPABYmcNrqs5x/XOdxAwbdX/f/vRT++ZNWxThzZv2xx/b+3vpCgAW5sCaqn4Nqljns7tx8O0SzW0c8v6+/e678PXX4eEhCyE8PITHx/bbb8OnT+3bt0tNrgCQoLHJzrquN5tNWZZVVfVvj9vXzC2dnGOGk7s//dR+/hx+++0v+endu/buLvz8s1AFcCkz7BHOVFXVdrs98+Rjl53n+ZkbzVVVFY8simLQ+5+8d99yX+TnGWvtyNuWZVncu+aCp3YBM3x337xp4xjVwN3d4dsBmMQMe4QznR+qjg2OjBwcvlz4Hyem+j+lWyST53m892QSWO6L/DxjC9Vtn3xpj4/tw8Oxu8LDQ0K/iACztfSriM5JVN1hbdvWdV3XddybrstM8d7dbhcPiFEphjA6Y6GqKwE6uD2+sosbppqhu7vs9etjd4XXr41UAdzMs68i6ubIqqranybr39u/K+4Cd2xa7eBTjavrOh7f/4kjJxZnCbtvB738drsd3Ngttj7/lNavHRWPKcty90V8xfM8H3/gPJ1s7/X98MMf7979EULb/+/9+z/+93//uPWpAazZeI/w73//8T//88f33//5+fzu3R9///sf//736Q/ncKh0dhzjifd2F3t1nen+8d2zxRGjvnjwydPoX1IWf9D4icVefr8h3RmWZbn//IOH7L8UJ89zTU60tktRfYOXdUFm+O7++99//P3vf8lV79//8d///ce//iVUAVzQeI/w449/SVRdrvrhh7NCVb+v7FJR/97+2MQgncTjuwMG0aeLSue0MT7V4MT6P/rgU/XHUEYy05lDM+ec52qc29pupOqSJ3Nx83x3//3vP3744Y+7uz9C+COEP/73fyUqgIsb7xFevx4mqvjf3d25oap/Sz827d8b9uZ/4vHtl1Q0GMt4Yag6dmKDw0bGULqYeDIVzLPbvZynVVS3juoS3r7Nfv45e3jIdrsQQvaPf2RffWU1FcDNvPwqosEkz2CN8sF9dauewUKlQef7km15B4+Ny6oGP65t291uV5bldrvd7/eLoojr05dYBODSDhT/HIglLuLXbdtmWXZ+uQuepChkKYDbu7vLXr8+nKuedxXRSPiI/WnTNF1X27+rKwo1eLb9g6cVl8x3Fb+784lx6swaDQk6MVKVZVnTNGVZdtm2LMumaYRTAFbs++/Du3fDEan379vvv3/Osx3MRlG88eBEW0w2YW8k6SXjGoM01j1VvPZwZIQsJqo4TSlRHTMWqrqiFPHay+7GmKsMVgGwVh8+hH/+8y+56v379vffw4cPZz18kF1OliLaTzOx0mZ8yH7tg7NO4gxd2oujXyPpLY5R6frHnS7+uf9LsOiIOsMNlfvaNszgLABS9/Zt9ulTuLsLd3dxfXr76lX49Cmcv+a1G/ipqmpQAmogDlV0fWs8vl92oX/vy2eKsizrTmy73eZ5Hp8zz/PtdtvFpoOnXe154cmszcgi9n4ljO5KhCicseZ/hsbbOxNLOEeAxTu/R9jtnnZFdgghz/N+HBlUMdiv9divKbV/wCDZDHrk0TMfXv03OLGwdx3iwdPYr5XVUaeq7/SGynF5f3+nIRsqX1SWhdmfI8DiXa5HyLIsLuXuRn3OHF4aWXr11Kc6dmLxUrORZ5vkB/V/4vy73QmNXf1XFEWe53FhWrwlRqvQqwYLABz01Fwycvy014dd7Qel5kRJhbhzUAxS4cvWP0pTAMBtdVv7HdO/yIzrOF2nyko0AJibk/srS1TXl9Zk51Imdy2rAri0pfQIi5bai3xgpOpJ6+kAAAgHR6rOLNe0xOy5lMhspArg0pbSIyxaai/yWPHPPM9H6k9c7RQBAObvQKiKmSkWeN1sNlmW7e8HBABA39GRqqqqpCsAgDM9YbKzX7AqlmS91EldzIImdy2rArioBfUIy5Xai/zk1nbRaokv08k1+PNplFAFcFGp9fc3kdqLfLr4ZxQrtzZNE79d7jY1Sb27AMDVnLVNTT9Lqa4OALDvcKiSpQAAnuRAqOoWHpVlWRSFzYNuom0tqwKAJVFRfb6EKoDLWVaPsFCpvcgHRqryPL/+eQAALNqsI2RVVbEaVlEU5y/qilOWB49fVmQ2UgVwOcvqERYqtRf5QEX1mVROL4piu902TdM0zXa7PXNpV1EU3fp6AICrObz3X1VVVVXFdHWT6/7qum6apizL/lY5J3NefNRVThAA4C8O7/0XR6piuqrrOsuyLMuuma42m00IofuJ8YuTJ7DZbNa0ICxeAAgALMLRDZWjLl3tdrsQQpeurjA5OIhHeZ6Pj0LF+cGbz1oCAGk6Eao6cR4wTsaFEDabzaXjy5PqY8VSpUmthgMAZuXcUNUX09XlioIejGsjP66u6+12G8fSTsqe67mtAQCScHSbmqi/UD3eEr/ebreXGxZ6alyLS6nOfJTRLADgEg6Eqrqu4zrxEEIsZ9C27c2Hao7NNsbMN7hKMe5daI8dAOBqDoSqmKh2u11cpb7ZbGKiilsBhqePJD3Pk9Zsbbfb/rexutUKEpUdAAFgKQ7v/VeWZX/Wb7PZ9G+5gljDs39ug7MaMXLkEku7ClUAl7DEHmFxUnuRTy9Uv+boVKeb1OufQz/nXbluFgDAuKPFP697GgdOIFZRj1feNU2zf3GfklQAwHwcnv6LC6pGbrmabkPlSZ5tieOQpv8ALmGJPcLipPYiHy6pMB83HzO7OWvVAWARjtapGny9P9cm7gAAdA5P/53zyCUO6C10HNJIFcDkFtojLEtqL/KBkaoz93sBAKCTVoRcaGQ2UgUwuYX2CMuS2ot8eqF6twngOhZRjU9uJvXeAyTu5juwsTJHI2R/B8C+WFthv+L5Iiw3MhusAmBxltvtPs/hkaqqquJuenmexwgVx6uapumSlqVXAACdAxEyJqo8zw+WLI9jVMfunbnlRmYjVQAsznK73ec5WlLh2KvQzUAv8WVa7rsrVAGwOMvtdp9nuPdfHH8qy/Lg0fHeOPG3xJEqAIALObym6tiFfkVRJBU5AQDONBypOocxquuLOwACALM1DFVxjGo8NglVAAADT16ofs4Bs7XoFXPWqgOwLIvudp/hwPRfXIeeZdn+iFRd1zFRKVIFANB3OEL2i3+GEGLxzxBC0zQhhLIsq6q65llOZdGR2UgVAMuy6G73GcZaG+t89m9ZaM3PzqLfXaEKgGVZdLf7DGe1Nm6ofPmTubiTe2fO/L2XqwBYEKFqzZb+7gpVACzI0rvdpzpQ/PPM9VILXVYFAHAJR0sqnLTE7Ln0yGykCoAFWXq3+1QHRqqSaj8AwCSes00Nt2KzGgCYLaEKAGACQhUAwASEKgCACQhVAAATEKoAACZwbqiq63rRu/6thgsAAWCeDtSpGuhvq9y2bZZli95Weby0qRpdAMDznBipyrKsaZqyLPM8j7fked40zXL3V25H3frsAIClGgtVcXe/3W5XVVWXouq6LsuyG7sCACCMh6o4x7c/KBXD1nJnAAEAJufqPwCACZye/tsfkYpjV8tdVrV0LgAEgBkau/qvKIo8zzebTbdKvaqq7XYbQijL8hpnBwCwENnJS966INXZ7XYLHabKstPtXYQsC6toBwBrtppu90yJtXYt765QBcD8rabbPdPTFqqrqw4AcNCJUFVVVZZlMUhVVbXZbDabTZZlcQ07t2KtOgDMzdi4XF3Xm80mfNm8JW7wEmuBNk2zxAG9NY1DmgEEYObW1O2e43RJhfhyxMGquERd8U8AgIET039dMYV+dfX4/4WGqmzUrc8OAFiqsVBVFEW3x992uz0YsBbHhsoAwCWcCFXx/4MBqrjQaqGhCgDgEk6sIOsqf+Z5HgeouuXqSwxVK1sxZ606AHO2sm73pMRau653V6gCYM5W1u2e9LTinwAAHHQiVNV1XRSFC+UAAMb9beS+bk16d93ftKqq6i4kPFmifeTg/YRXlqWa7wDANY2Fqn7xz8n16zU0TTOyq+Ag22232+12m9QcLQAwf+cW/5xWXddN05RlGatDlWUZc9XBg7utcmLw2u124UvgC71S7/1yU4kMU9kBEADm49zin9OKOamLPvGLkSRUlmX/rEKvnvuiK5ECAKtxYu+/PM8vlFcGY2B5nh8LcAdrYnW39NPVQnfOAQBW4MRC9RBC0zQHr/V74aqm87PaID/FAa3Bw/tn2NUpBQC4mrFQFU2+rOpg4jlnqjFOGoYQyrLsQlV8VHe5XywBXxTFsVz17GIQlsYDACPGQtVINHmJZ88ndmvV4845MUUNJgdj5YWRfCYbAQCXcG5F9UuvWDrzyWORqjzPY64KhyLaYCX7urkAEABm4nSoihXVN5vNZrOJtdQnKVhwZuiJJd0HB58z1uV6QADgmk6EqizLmqbJ87wsy91uV5ZlHCV6Ya7av9Yvlq3aPzKutRqEqv4Vf/shL5ExKgBgXtrjYsoZ1NXsbh954EmxgGee5/HbuBZ+cG9XGjSeZ3ca8ad398bHHrt34IWnPU9rbBMAa7DKbndE1h5fuB1HiQ4ekGXZwfJR54uX6XXf9p8t7kvTr4wwuGRvUDRhcO/Ixn9ZNtbehcqysLo2AbAGq+x2R9wsVEXn10PvUtTBg+M6+qIoxp9qre+uXAXADK212z1mrLVxMGk/PI2ErZlb67srVAEwQ2vtdo850do4s9bfrCbO2Y1Msc3ZWt9doQqAGVprt3vM6dYOFj+FxSaqsN53V6gCYIbW2u0e84TWxkVLlzyZi1vruytUATBDa+12jzm991/YK6e+9GgFADC5ExEyVjcY3DioaLAgJ3dTXm6gNlgFwNykNlJ1oqJ6TFSxnHrbtrvdLhZDX+5g1XjZrlufHQCwVGOhKq5G3+12VVXFFBW34SvLcn/rGACAlI2FqmOVORd66R8AwOWMhapjc3zGqAAABk4X/9yvSpVl2ULXqq94xZyF6gDMzYq73YPGWlvXdVVVTdOEEPI8jzcOvg0hFEWxlAnBdb+7chUAs7Lubnff6b3/znmWpbxk6353hSoAZmXd3e6+xFq76ndXqAJgVtbd7e47Uadq3xKXUgEAXNqJUFVVVZZlMUjFrzebTXcLAADRiYXqsaJ6PCbu8RJrgTZNs8QBvdWPQ5oBBGA+Vt/tDpyuqB5fjjg0tdvtumv9DFYBAHROTP91pRP61dXj/xcaqrJRtz47AGCp/jZ+d6xKFULo11Y4tn3NIiQ1DgkAXM3p6b+iKGJ+Kssy9BZaLTRUAQBcwokVZF39z25fmjhHtr93zSKsfsWcheoAzMfqu92BJ7e2ruvljlGl8O7KVQDMRArdbt8Tin8ueikVAMBFnQ5VRVHEK+PiUqosy5Y48QcAcFEnQlWWZU3TlGXZ1VbI83y73RqvAgDoO331Xyyh3qWouq7LsuxKLQAAEMZD1bFFVCqqAwAMPGGhOovQtkFleAC4vrFQdWw7mq4o6GVOCQBgeca2qamqKtZP71apx1vi0vWrnB4AwDKcrsrVFVXvLLScevhSDn7EOmqUqf8JwBykVvzzCa1ddC31KJF3V6gCYA4S6XY7ibU2jXdXqAJgDhLpdjtHF6rH2lSDab66ruu6rqrq5DwaN+QCQAC4vgMRMi5O79/Stm1RFIOCn0vMnulEZoNVANxcOt1udKC1cRSqLMu4gqoLWN0tYbH1FNJ5d4UqAG4unW43OlxSoX99326322w2y73iDwDgCk5XVI+DUgsdmgIAuI7DoUqEWjpr1QHgyuz9BwAwAaEKAGAChxeq72+ivH+LKUIAgM7RkgonLfEiyUT2/otUVQDgtpRUCGVZXv88riapdxcAuJq0ImRqkdlgFQA3lFq3a6E6AMAEhCoAgAkIVQAAExCqAAAmMOtQVVVVURRFUZyzl/OTDgYAmNZ8l+UXRdE0Tfdtnuf7BUijuq43m008JoQQH3WwXaldhhBcAAjA7aTW7c50pKqu66ZpyrJs27Zt27Ism6Y5Fqpiomrbtq7ruq53u10IwXgVAHBNM42QsfR5/9yyLDs2WJVlWVmW/RR17ODUInMwUgXA7aTW7R7e+28O4lxe/9v+bGBfHJoasDUhAHBN8w1V56ei7sg4NBWHrIQqAOCa5hiqDs7xDdatHxQXV4UQyrI8FqrO3C5630IHMNvWDCAAXMMcQ9WzB5m6terb7TYcWau+0GwEAMzcTK/+23fs0r+BWKcqz/OYqwAArmO+oerMFFXXdVEUg4MtqAIArmymoWr/Wr9Ytmr/yLjWahCqzgxkAABTmWmoGlzBF7/o1kjVdZ1lWX/J1Ha77YJUVVXHEhgAwIXMcaF6CKEoirIst9ttd7HefjGqLkW1bZtlWXfpXwghz3MV1TsuAASAK5h7qdOYnM5ZI9VlrJGDUyvt2hGqALi+1LrdxFqb2LvbEaoAuL7Uut2ZrqkCAFgWoQoAYAJCFQDABISqJMQLAAGAy5lpSYXLGd9QOan1dADAhJILVWITAHAJpv8AACYgVAEATECoAgCYgFCVChcAAsBFCVUAABMQqgAAJiBUAQBMQKgCAJiAUJUQa9UB4HKEKgCACQhVAAATSG7vPxsqAwCXkFyoEpsAgEsw/QcAMAGhKi0uAASACxGqAAAmIFQBAExAqAIAmIBQBQAwAaEKAGACQlVyXAAIAJcgVAEATECoAgCYgFAFADCB5Pb+s6EyAHAJyYUqsSl8WavulQCACZn+AwCYgFAFADABoQoAYAJCFQDABIQqAIAJCFWJslkNAExLqAIAmIBQBQAwAaEKAGACQhUAwASEKgCACSS3958NlTt2AASACSUXqpKKTQDA1Zj+AwCYgFCVuqYxdAcAExCqEnV/3/70UxtCWxThzZv2xx/b+3vpCgCeT6hK0f19+9134fPnEEIWQvbwkD0+hm+/DXIVADybUJWiX38NX38dfvvtzwshP37Mvvkm/PLLDU8KAJYtu+HVcFVV1XUdQiiKoqqqZx+8XyWhLMuDT5hlt2zvfLx50z48HCgtcXd3+HYAeIbUut2btbYoiqZpum/zPI+Z6aAYm/I8DyHER+12u6Io+vf2CVUjHh/b169DCAfDU/v5c3j9Wq4CYAKpdbu3mf6r67ppmrIs27Zt27Ysy6ZpjoWqGJ52u11d13Vdx7dns9l0TxXvbXtOjnul7O4ue/362F0SFQA8020iZBxb6v/oLMuODVbt31VV1Xa7jQ/vf33Oz00qMh/z44/t42P4+PEv+en9+/bVq/CPfwhVAEwjtW73ZgvV41xe/9v+bODgrm6mb18XtuI41lSnt24fPoR//jO8e/fnL/r79+3vv4cPH254UgCwbDfbpmYkJw3sR6Xtdju4pb+sanx5FiGEt2+zT5/aX34Jd3ft42MIIbx6FT59Cl99ZZgKAJ7pBiNVBxPPmRmrruuYn3a7Xbwljm8NlmeNPFv2XE9u57y9fZv9/HP28JDtdqFts//7v0yiAoCXuMFI1fljVPsP3L/0r/91+FJ54dhMYrCh8p6ikKUAYAJzKf45PmEXB6i6Cwb7KWo/osVbzAA+SduG1Q3GAcBV3WxN1fmhp67rzWbz1JVSzx4PAwB4htuMVO1f6xdHoQ4eHEtSHUxUcQRrUJXKGBUAcH23Gamqqmqz2RRF0e08E2+M98ahqVgVvUtI+/U8q6oqiiLP8+12WxRF9yQj+YwRcQbQkjMAeJ6bVeWKRTu7b/vrzfvzffHrg8/Qnfng0rxje9SE9KqQPZVQBcCEUut2b9za/kjVC5+nrutuvOqY1N7dpxKqAJhQat1uYq1N7N19BrkKgKmk1u3OpaQCAMCiCVUAABMQqvgLVUAB4HluVvzzVsZ38Utq6hcAmFByoUpsAgAuwfQfQ2YAAeAZhCoAgAkIVRxgsAoAnkqoAgCYgFAFADABoYrDzAACwJMIVQAAExCq4CxNo8IZAGOEKo4yAxhCuL9vf/qpffOmLYrw5k3744/t/b10BcABQhUcdX/ffvdd+Pw5PDxkIWQPD9njY/j22yBXAbBPqIKjfv01fP11+O23P8frPn7Mvvkm/PLLDU8KgJnKktoLb3w35WBnwEOyLCT7qrx50z48HPidubs7fDsAfVmWWMxIq7WJvbuTSDZUPT62r1+HEA6Gp/bz5/D6tVwFMCa1btf0Hycku1z97i57/frYXRIVAEN/u/UJwHx9/314fGw/fvxLfnr/vn316lZnBMB8CVVw1IcP4dtvQwhtNwn4/n3766/hX/+66WkBMEum/zgt2RnAt2+z//f/wg8/hLu7NoT27u4/Y1RffZXkywHAqLRWkKW2Ym5CaS5X77e6rtuiyPZvB+CY1LrdxFqb2Ls7oTRjxEir03xBAJ4ktW7X9B9nSXAGcDw2JfiCADBOqIIDzhmIkqsA6BOqYOj8qT25CoCOUMW5BAgAGCFUwV88dQW6rAlAlFzxz/E9lZO6SIF9z7umL+YqvzsAiUsuVIlNL7Hu9PCSpq37lQHgHKb/YBrmAQESJ1TxNGuNDpOMM631xQHgHEIVmLkDYAJCFambNlEZrAJIllDFk8kN47w+AGkSqkjahSb+5CqABAlVpOuiS6nkKoDUCFU8h8RwDq8SQFKEKhLlij8ApiVUkaKrJSqDVQDpEKp4puXGhSuPUS33hQLgSZLb+8+GylyfnQEBUpBcqBKbJrTErHCrE17iawXAk5j+IyG3jTXmAQHWTagiFQaKALgooYoXMfryJF4ugBUTqkjCfIap5CqAtRKqWL/5JKpIrgJYpVmHqqqqiqIoiqKqqmkPZkIzjwhzS1TRzF80AJ4hm22JgaIomqbpvs3zvK7rYwfH6lN5nocQ4qN2u11RFPuHzba9izbP4BI5N4BbSa3bnelIVV3XTdOUZdm2bdu2ZVk2TXMsVMXwtNvt6rqu6zq+f5vN5orny0zNPLUYrwJYk5lGyDjy1D+3LMuODVbt31VV1Xa73W9aapH5mmYYX2Z4SvsWcZIAz5NatzvTkarwZS6v/21/NnBw1/5MH4lbSlgxWAW8RNMs4ZMuGfPdpub8nLQ/fLXdbqc9GU6yDcuzeemAp7q/b3/9NXz8GB4ewuvX7fffhw8fwtu3/kS7sTmOVB2c4zszY9V1HacOd7vdwQOy53p+e7i6xWUU41XA+e7v2+++C58/h4eHLITs4SF7fAzffhvu7xf1wbdGcwxVz57LK4oirk8/eOlf1D7Xc1vDtS0uUUVyFXCmX38NX38dfvvtz4+Mjx+zb74Jv/xyw5MihHmGqoNG6imELwNU3QWDlljdxBxiwUITVTSHFxCYv48f/5KovtyYffx4k9PhT/NdUzWeogZHbjab8UJWALACj4/tw8Oxu8LDQ/v6tT/Obmam1zrGyp+DkgplWR6slr5ff+GY1K7tvL7bDhQtepiqs45WAJeTZW0IB5LT3V378DCvRJVatzvTkdOrykUAABDxSURBVKqqqjabTVEUcfApTud1iSoOTcWM1Y1O7ect+9Vc3w0vZFtNFnExIHBMXCHwww/h8bH9+PEv+en9+/bVq9ucFZ2ZhqqiKMqy3G633WV3+1fzDSb79ssoCFUslFwF9HWrLePHwv19+Pbb8O7dn7nq/fv299/Dp083Oj++mPu4XH+k6uVSG4e8iZukgVVGkFU2CjjfIEv13d+3v/wSPn4Mj4/h7i7EOlVffTWvub+QXrebWGsTe3dv5cppYMXhY8VNA44ZyVL76rotitllqU5q3W5irU3s3b2Va0aBdceOdbcOGIhxak3/6lPrdme6pgoIFldBGp40NMWcCVVM72pRIIXAIVfBWslS6yNUsVTpRA25CtZEllqx5ELV+NbISU39XtSlc0BqIUOughVY35IpBpILVWITCyVXwUIZmkpHcqGKFZAtgPmTpRIkVHEpFxpZSTlRGayC+ZOlUiZUsSQihVwFs2XJFEIVLIxcBbNiaIqOUMUFTdv9SxIduQpuTpZin1DFMsgQA3IV3IQsxQihigWQHoCbs2SKk4QqLsuAyuV4beEKDE1xPqGKuZMbRshVcCGyFM8gVHFxL+n4JYaT5CqYkCzFSwhVsHhyFbycJVO8XHKhyobKCyIonE+ugucxNMWEkgtVYtNNPKPLFxGeSq6C88lSXEJyoYpFEA6ACzHNx+UIVbAeBqvgGENTXIFQxZWc39+LBS8hV0GfLMU1CVXMi0DwcnIVyFLchFDFjIgCU5GrSJYlU9yQUMX16OmvyatNUgxNMQdCFXMhAQBPJUsxK0IVsyBRXYLBKtZKlmKehCqu6mA3r+O/HLmKlbFkijn7r1ufAIlqGh+KVxJzFSxalv3nv7aVqJiv5EJVNurWZ7d+9/ftjz+2WdYWRXjz5j9f+4i8NLmKhRpkKZ8VzFxyoaoddeuzW7n7+/a778LnzyGELITs4SH7xz/C3/8e7u+98hcnV7EgshQLlVyo4oZ+/TV8/XX47bd+355980345ZdbnREwL7IUi5bW1Etmqumm3rxpHx4OjJbc3R2+nclZtM48uZpvrVLrdo1UcSWPj+3Dw7G7wsNDQv/qbsgkILNimo+VEaq4kru77PXrY3eF16919VciV3FzshRrpU4V1/P99+Hxsf348S9d+vv37atXtzqjRClexa2oMsW6Ganiej58CP/8Z3j37s8P1Pfv299/Dx8+3PCkEmW8imtSZYpECFVcz9u32adP4e4u3N21IbR3d+2rV+HTp/DVV7p3WCHTfKQmrWX5qV2GMGd13RaFLHVjJgG5BJfy0Umt202stYm9u3CSXMWELJliILVu10J1SJpF67ycoSmIrKmC1A0WrdvrmjNZMgUDyYUqGyrDvrYNWdb+9FP75s2fe13bk5GDZCk4JrlQZUNl2Bfz0+fP4eHhP3tdPz6Gb7+11zV/IUvBuLRWkKW2Yg7O9NNP7efPg72uw7t37d1d+PlnI7ips2SKZ0ut202stYm9u3Ame12zT5bi5VLrdpOb/gMG7HVNnyVT8GxCFaTOXtdEshS8kFAFhO+//8uejNH79+3joy0C18/GfDCVW4aqqqqKoiiKoqqqMx9SFEVd14Mb9ysjnP+EQDi+1/W//vWfKlbxP9bENB9M7mYV1YuiaJomft00TV3X+2lpoK7r7iHAhN6+zT59an/5JdzdtY+P4e4u9Pe67rpbm5CsgOXncDm3GamK8agsy1gdqizLmKtGjq+qarPZHLwrhLDb7frlpoxUwVO9fZv9/HP28JDtduHhIfvHP7KYqPrieIZRq4UyLgWXdptrHWPt8v6PzrIsz/Njuapf63y32xVF0X1bVdV2uz2zFald2wmXY8BjKbxT3FBq3e7N1lTleT74dmRqL44/7Xa7/bu6HHbOBCIwlW7Aw8DVPFkyBdd3yzVVEz5bfyhrZMQLmFzsrS23mgnjUnBDNxipOph4np2x4vjWYHnWyLONb6hsr2V4nv6olX8uN2FcCm7uBiNV045R7S+xGr9IMKnJXbgy1wlen6EpmI+5FP989oTdfkSLt5gBhBuy3OrSLJmCGbrZmqpLh55px8OAZ+gvtwqGUqbgxYQ5u81I1f61frFs1VOfp67r/frpxqhgVlwnOAnjUjB/twlVMQZ1g0nxiy4bHYxKBxVFkef5drvtglRVVc/LZ8CliVbPYGM+WJDbTP8VRVGW5Xa77a6q269BdeaAU0xg/WLrZVmqqA6zZU7wHF4fWKIblzqNyenl659i5c+4PfPIYamVdoX5c53ggBeENUmt202stYm9u7AUkoShKVYptW73Zlf/AXSSLcsuS8GaCFXAXKSz3CqFNkKChCpgXtZdln2VjQIioQqYqTXNCRqaghQkF6rGt0ZOaj0dLMKi5wQXetrA8yQXqsQmWKJlzQnKUpCm5EIVsGgznxOc7YkBVyBUAcsztznB+ZwJcENCFbBUN58TlKWAPqEKWLwrzwnKUsBBQhWwEleYE7RkChjxX7c+AYApte1//suyMFpBJYQQmuasfBSfKsv+88wABwlVwDqNRKv7+/ann9o3b9qiCG/etD/+2N7fH8hKgywlTgHjhCpgzfrRKqar+/v2u+/C58/h4SELIXt4yB4fw7ffhi5XyVLA8whVwPr15wS/+ip8/XX47bc/x68+fsy++Sb88ossBbxIllSF8SxLq73Avjdv2oeHg4ut2rY9tQgLeIrUul0jVUBCHh/bh4ej9z48JPTpD0wurQg5vptysDMgJODYSNXd3bERLOCZUhupSq5OVVLvLrDv++/D42P78eNf8tP79+2rV7c6I2AlTP8BafnwIfzzn+Hduz//vnr/vv399/Dhww1PClgDoQpIy9u32adP4e4u3N21IbR3d+2rV+HTp/DVV+b+gBdJa7IztcldYFxdt0UhS8GlpNbtJtbaxN5dALih1Lpd038AABMQqgAAJiBUAQBMQKgCAJiAUAUAMAGhCgBgAkIVAMAEktv7b3xP5aTKaQAAE0ouVIlNAMAlmP4DAJiAUAUAMAGhCgBgAkIVAMAEhCoAgAkIVQAAExCqAAAmIFQBAExAqAIAmIBQtRLj2++sSTotDRq7Uum0NGjsSqXT0qdKbpsae/8BAJeQXKgSmwCASzD9BwAwAaEKAGACQhUAwASEqsNecmnDsx97k+spbtLSFz72Jj90WW/rS36ut/UKj73JD/U7fOnH3uSHLu5tXTehCgBgAkIVAMAEhCoAgAkIVQAAExCqAAAmIFQBAEwgS2rbFleQAsA1pRUzkmotAMCFmP4DAJiAUAUAMAGhCgBgAkIVAMAEhKqFqaqqKIqiKKqqeuq9C1UURV3XgxtX1tK6rtN5W1f/O3zwNzastOEaOzhgv0VLbOyxlib1SfVMLcsR37I8z/M8j1/vdrvu3u7G7rCbneh0YqPKsty/cTUtLcuya8j+v8qVNXb/d7h/7woau9vtBv8wo/GmLbThxxq7yk+qY43trObD6lhLk/qkejahajHir2z/F73/ax3/GXT/nuNv/8i//0WIjRp8Tq2spYPmxG+7z6OVNXbwO3yw7ctt7G6363qdwWmPN22JDR9p7Po+qUYa2z9mBR9W5/8Or/uT6iWEqsXYz/7xF7e7d/B3wwr+Vuj+JOp/Tq2spbGB/VvKsuzau7LGjjdn6Y3t/5k+6E7Gm7b/OzD/ho83duSTamWN7R+z/2G1uMaOtHT8k2pxLb0coWox8jwf+S3f/w3e/y1flq5F+6FqTS0d/+hZWWMPfvL2E+QKGntw6mS8actt+MHG5nk+mAIb/Pm3psZGXRPW8WF15u/w+L2LaOklWKi+GHGFYP+Wpmn63w7uXbS4zvHYmtA1tTR8WdxaFEWWZfvrQ9fU2Ni0LMuqqqqqKm4b1V/TuqbGDow3bXDvol+Huq4H65S3223/2zU1NoRQVVXTNO2RvUnW1NgnfVItuqUvIVQtUl3XsUPqJvL3Lfd3uq7r7XY70rSBRbc0hLDdbmOvU5Zl0zSbzWbkCqPlNjaKf7/2mzxy8NIbO2LFTes755Nq0Z76YbVQz/ikStbfbn0CPFlRFHGMarfbrfKjebPZ5Hm+yqYd0/2ZG8dvNpvNsT98Fy3+6pZlGUcyqqqKn9FJX4C9Xqv/pArpfVgl8kn1EkaqliT+2Re7pbZtx/8lL/RviNi/xnHmKHyZUDjWooW2NHwZrhhcijw+eLPcxtZ13U9UIYSqqvI8H8wNDR5ynXO7vvGmLb3hKXxShZQ+rJL6pHohI1WLUdd1/KtoZf9cDxp0tE3TNE3TfTSvqaXh1EzQuhsbBzO69YIra2zfulNUX1KfVCGxD6t9KfzjfZqbLZHnicbfr/HrqhYtnHGV8nJbut+c/i0ra+z+ya+vsccuiBtp2nIvRz92mdhTP6mW29iBcz6s5t/YM3+HT/7jnX9LL0GoWoZ+ZbmB/gEjlW+WKxyqp7ealg6aE0fU1/q2Dgr5xMYO6gcuvbEHO6Txph28dxGFE/cb+7xPqoU2dt85H1bzb+w5v8PnfFLNv6WXsLzPrDSNXF1y7JjV/ELvD1esrKWDpQmDP+9W1tjBsoz1NfZY1zvetIU2fCRUre+T6hmhql1mY4+1NKlPqmfLWkv31yVObKdwNcrKWjreHI1dh2Qbvk9jF8rv8DihCgBgAkoqAABMQKgCgCTUda32wUUJVQBwDbEQ+b5pNxXodgca3BJroG82m6f+0Pjwg8fHFnXber7wzFfAmioAuIa4NVNZlv2CmbF86ISb+WRZNti6oNuzr/u53S1nRqsYmPYDQ//2WEo+8ZEwoQoAriHmm/38dCyyPEOsaN9/qmNPHvczOPOHxoMPnnm/en6WZSve6vEcpv8AYCXilpr9b0MIB+uHdfua92+M287EDQ33Dx6MQu0/Q57nie+PbqQKAK7hCiNVg7GiJz1zHI7q3zI+4rU/1hUbmHKuMFIFALfRbUg8qFf+7GcLe7U3B9sYHFNVVZzgi5XB4+BW/6niGfYHq5qmGTz5wQGtpAhVAHA93fV38XK8GE0mmTU7mGYGGasoiv6Fh9292+02z/Pu26IoyrLsD1wNJvsOzh6OnEYi/nbrEwCAhAwGpeIapkme+WCaGdzY/3Hb7XYw39cPSQefrTvejjQHCVUAcD0TpqhzjMSmWFghfElITdMMDg69CcoQQlmW2+023tI0zbEpy5RHqkz/AcA6xTVPJ1NOt66r3dPPf92UX/ziWDRMefhKqAKANdhPMzFObTab8w/uH7BfJD3P86ZpzP0dI1QBwIx0dcn7Kaeu6/0FT4MbD6acOEnX32cmbjszmOmLy9L769APTvDFA47N/cWzSrpU1f5YHwAwuRhEurIFB4UQ8jzvIkv/xjiXNzisf2O8fX8Wb7/4Z57n3fkMTm9wzMEzPNaKwRMmSPFPAJiFOPLUjffEQpr9jQK7/fX6G/z1C372D95/8q5g+vg5hOdO7Q22HUyQUAUAszAo/pRlWdu2cX+97phYxLwfpParqN+qZ7/hj54JJRUAYHa60aZYk7NflnP8gbGU6PWHi2K90Cv/0LmxUB0AZqEoikHtqHhjN203WJl+ULfO/fpSnviLjFQBwCwURZHn+WC+r6qquKVM/Pac+bWbhKqUa352Up/+BID56NaJ13W92Wy6PlppqEUQqgBgLuKq8xDCZrNJ/Eq6JRKqAGAuuhVRV94ikEkIVQAAE3D1HwDABIQqAIAJCFUAABMQqgAAJiBUAQBMQKgCAJiAUAUAMAGhCgBgAkIVAMAEhCoAgAkIVQAAExCqAAAmIFQBAEzg/wOj9KvVgAzJIAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ROOT\n",
    "import numpy as np\n",
    "\n",
    "# Define bins\n",
    "bins = [10, 20, 30, 40, 60, 80, 100, 200]\n",
    "\n",
    "# Initialize lists to store values\n",
    "x_vals = []\n",
    "ratio_iqr_median = []\n",
    "\n",
    "# Iterate over bins\n",
    "for i in range(len(bins) - 1):\n",
    "    lim_low = bins[i]\n",
    "    lim_hi = bins[i + 1]\n",
    "    x_vals.append(np.mean([lim_low, lim_hi]))\n",
    "\n",
    "    # Filter true and predicted momentum values within the bin\n",
    "    true_values_in_bin = true_mom[(true_mom > lim_low) & (true_mom <= lim_hi)]\n",
    "    pred_values_in_bin = pred_mom[(pred_mom > lim_low) & (pred_mom <= lim_hi)]\n",
    "\n",
    "    # Resize arrays to ensure they have the same shape\n",
    "    min_length = min(len(pred_values_in_bin), len(true_values_in_bin))\n",
    "    pred_values_in_bin_resized = np.resize(pred_values_in_bin, min_length)\n",
    "    true_values_in_bin_resized = np.resize(true_values_in_bin, min_length)\n",
    "\n",
    "    # Calculate ratio of pred/true\n",
    "    ratio_values_in_bin = pred_values_in_bin_resized / true_values_in_bin_resized\n",
    "\n",
    "    # Calculate IQR and median for the ratio\n",
    "    if len(ratio_values_in_bin) > 0:\n",
    "        ratio_iqr = np.percentile(ratio_values_in_bin, 75) - np.percentile(ratio_values_in_bin, 25)\n",
    "        ratio_median = np.median(ratio_values_in_bin)\n",
    "        ratio_iqr_median_ratio = ratio_iqr / ratio_median\n",
    "        ratio_iqr_median.append(ratio_iqr_median_ratio)\n",
    "    else:\n",
    "        ratio_iqr_median.append(np.nan)\n",
    "\n",
    "# Create a TGraph\n",
    "gr_ratio = ROOT.TGraph(len(x_vals), np.array(x_vals), np.array(ratio_iqr_median))\n",
    "\n",
    "# Set the titles to empty strings\n",
    "gr_ratio.SetTitle(\"\")\n",
    "\n",
    "# Create a canvas\n",
    "canvas = ROOT.TCanvas(\"canvas\", \"Ratio IQR/Median vs Momentum\", 800, 600)\n",
    "\n",
    "# Draw the graph with connecting lines\n",
    "gr_ratio.SetMarkerStyle(20)\n",
    "gr_ratio.SetMarkerColor(ROOT.kBlue)\n",
    "gr_ratio.SetLineColor(ROOT.kBlue)\n",
    "gr_ratio.GetXaxis().SetTitle(\"P_{gen}(GeV)\")\n",
    "gr_ratio.GetYaxis().SetTitle(\"Response IQR/Median\")\n",
    "gr_ratio.Draw(\"APL\")\n",
    "\n",
    "\n",
    "# Add legend\n",
    "legend = ROOT.TLegend(0.75, 0.75, 0.9, 0.9)\n",
    "legend.AddEntry(gr_ratio, \"pred_fp32\", \"p\")\n",
    "legend.Draw()\n",
    "\n",
    "# Show the canvas\n",
    "canvas.Draw()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e900a5",
   "metadata": {},
   "source": [
    "# quantization to INT8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "178e8fea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cvmfs/sft.cern.ch/lcg/views/LCG_105_cuda/x86_64-el9-gcc11-opt/lib/python3.9/site-packages/torch/ao/quantization/observer.py:1207: UserWarning: must run observer before calling calculate_qparams.                                    Returning default scale and zero point \n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "model.qconfig = torch.ao.quantization.get_default_qconfig('onednn')\n",
    "custom_module_config = {\n",
    "        \"float_to_observed_custom_module_class\": {torch.nn.MultiheadAttention: QuantizeableMultiheadAttention},\n",
    "        \"observed_to_quantized_custom_module_class\": {QuantizeableMultiheadAttention: QuantizedMultiheadAttention},\n",
    "}\n",
    "\n",
    "model_prepared = torch.ao.quantization.prepare(model, prepare_custom_config_dict=custom_module_config)\n",
    "\n",
    "#calibrate on data\n",
    "num_events_to_calibrate = 100\n",
    "for ind in range(max_events_train,max_events_train+num_events_to_calibrate):\n",
    "    _X = torch.unsqueeze(torch.tensor(ds_train[ind][\"X\"]).to(torch.float32), 0)\n",
    "    _mask = _X[:, :, 0]!=0\n",
    "    model_prepared(_X, _mask)\n",
    "\n",
    "model_int8 = torch.ao.quantization.convert(model_prepared,convert_custom_config_dict=custom_module_config,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2bf39de2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QuantizeFeaturesStub(\n",
       "  (quants): ModuleList(\n",
       "    (0): Quantize(scale=tensor([0.0078]), zero_point=tensor([0]), dtype=torch.quint8)\n",
       "    (1): Quantize(scale=tensor([0.0396]), zero_point=tensor([138]), dtype=torch.quint8)\n",
       "    (2): Quantize(scale=tensor([0.0342]), zero_point=tensor([129]), dtype=torch.quint8)\n",
       "    (3): Quantize(scale=tensor([0.0078]), zero_point=tensor([127]), dtype=torch.quint8)\n",
       "    (4): Quantize(scale=tensor([0.0078]), zero_point=tensor([128]), dtype=torch.quint8)\n",
       "    (5): Quantize(scale=tensor([0.0339]), zero_point=tensor([117]), dtype=torch.quint8)\n",
       "    (6): Quantize(scale=tensor([49.7997]), zero_point=tensor([62]), dtype=torch.quint8)\n",
       "    (7): Quantize(scale=tensor([22.5108]), zero_point=tensor([128]), dtype=torch.quint8)\n",
       "    (8): Quantize(scale=tensor([30.9407]), zero_point=tensor([130]), dtype=torch.quint8)\n",
       "    (9): Quantize(scale=tensor([0.0122]), zero_point=tensor([0]), dtype=torch.quint8)\n",
       "    (10): Quantize(scale=tensor([3.2249]), zero_point=tensor([0]), dtype=torch.quint8)\n",
       "    (11): Quantize(scale=tensor([0.3067]), zero_point=tensor([25]), dtype=torch.quint8)\n",
       "    (12): Quantize(scale=tensor([0.4297]), zero_point=tensor([130]), dtype=torch.quint8)\n",
       "    (13): Quantize(scale=tensor([8.0287]), zero_point=tensor([0]), dtype=torch.quint8)\n",
       "    (14): Quantize(scale=tensor([9.5126]), zero_point=tensor([151]), dtype=torch.quint8)\n",
       "    (15): Quantize(scale=tensor([4.2339]), zero_point=tensor([0]), dtype=torch.quint8)\n",
       "    (16): Quantize(scale=tensor([3.6354]), zero_point=tensor([0]), dtype=torch.quint8)\n",
       "    (17-19): 3 x Quantize(scale=tensor([1.]), zero_point=tensor([0]), dtype=torch.quint8)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_int8.quant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "308471ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_quantized = torch.quantize_per_tensor((X_features_padded[:, :, 0]!=0).to(torch.float32), 1, 0, torch.quint8)\n",
    "preds = model_int8(X_features_padded, mask_quantized)\n",
    "preds = preds[0].detach(), preds[1].detach()\n",
    "preds_unpacked_int8 = unpack_predictions(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44065c9",
   "metadata": {},
   "source": [
    "## Physics performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d39a5273",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_int8 = mlpf_loss(targets_unpacked, preds_unpacked_int8, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "133a4f23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Final total loss')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAD4CAYAAADmWv3KAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAAsTAAALEwEAmpwYAAAOGklEQVR4nO3da6xlZX3H8e9PQEFkinFOtCOXEWtMpkbAHG2E1gitCtJqU9tU2tJ661TbiqSNLfqi3l4IrbYVI+JUbdF6iRGJFhE1FaSkVDyDXAaQ1NIxUjQMaSsQzcjl3xd7TzkzzOxZM/s8Z5/zzPeTTPa6nfX8k7PnN88861lrpaqQJPXnMbMuQJLUhgEvSZ0y4CWpUwa8JHXKgJekTh086wIWW7t2ba1fv37WZUjSqrF58+Z7qmpud/tWVMCvX7+ehYWFWZchSatGku/uaZ9DNJLUKQNekjplwEtSpwx4SeqUAS9JnTLgJalTBrwkdcqAl6ROGfCS1KkVdSer1LP1535x1iVohdp63hlNzmsPXpI6ZcBLUqeaDtEk2QrcBzwEPFhV8y3bkyQ9YjnG4E+pqnuWoR1J0iIO0UhSp1oHfAFfSbI5ycbdHZBkY5KFJAvbtm1rXI4kHThaB/zJVfUc4HTgj5K8YNcDqmpTVc1X1fzc3G5fSiJJ2g9NA76q7hp/3g1cCjyvZXuSpEc0C/gkhyc5Yscy8GJgS6v2JEk7azmL5snApUl2tPPJqrqiYXuSpEWaBXxV3QEc3+r8kqTJnCYpSZ0y4CWpUwa8JHXKgJekThnwktQpA16SOmXAS1KnDHhJ6pQBL0mdMuAlqVMGvCR1yoCXpE4Z8JLUKQNekjplwEtSpwx4SeqUAS9JnTLgJalTBrwkdcqAl6ROGfCS1CkDXpI6ZcBLUqcMeEnqlAEvSZ0y4CWpUwa8JHXKgJekThnwktQpA16SOmXAS1Knmgd8koOSfCvJZa3bkiQ9Yjl68G8CbluGdiRJizQN+CRHAWcAH27ZjiTp0Vr34P8W+DPg4T0dkGRjkoUkC9u2bWtcjiQdOJoFfJJfBu6uqs2TjquqTVU1X1Xzc3NzrcqRpANOyx78ycDLkmwFPg2cmuQfG7YnSVqkWcBX1Vuq6qiqWg+8EvhaVf1Oq/YkSTtzHrwkderg5Wikqq4CrlqOtiRJI/bgJalTBrwkdcqAl6ROGfCS1CkDXpI6ZcBLUqcMeEnqlAEvSZ0y4CWpUwa8JHXKgJekThnwktSpfQr4JI9JsqZVMZKkpbPXgE/yySRrkhwO3ArcnuTN7UuTJE1jSA9+Q1XdC/wqcDlwDHBWy6IkSdMbEvCHJDmEUcB/vqoeAKppVZKkqQ0J+A8BW4HDgauTHAvc27IoSdL09vpGp6q6ALhg0abvJjmlXUmSpKUw5CLrm8YXWZPkI0muB05dhtokSVMYMkTzmvFF1hcDc8CrgfOaViVJmtqQgM/486XA31fVjYu2SZJWqCEBvznJVxgF/JeTHAE83LYsSdK09nqRFXgtcAJwR1X9KMmTGA3TSJJWsCGzaB5OchTwW0kAvl5V/9S8MknSVIbMojkPeBOjxxTcCpyd5N2tC5MkTWfIEM1LgROq6mGAJBcD3wLe0rIwSdJ0hj5N8shFyz/VoA5J0hIb0oN/N/CtJFcymh75Auy9S9KKN+Qi66eSXAU8l1HA/3lV/aB1YZKk6ewx4JM8Z5dNd44/1yVZV1XXtytLkjStST34907YV/g8Gkla0fYY8FU11RMjkxwKXA08btzOZ6vqbdOcU5I03JCLrPtrO3BqVd0/fmHINUm+VFX/1rBNSdJYs4CvqgLuH68eMv7jm6AkaZkMnQe/X5IclOQG4G7gq1X1jd0cszHJQpKFbdu2tSxHkg4o+zKLZidDZtFU1UPACUmOBC5N8qyq2rLLMZuATQDz8/P28CVpiSzLLJqq+t/xXPrTgC17OVyStARazqKZAx4Yh/thwC8B509zTknScIMusiZ5FrABOHTHtqr62F5+7KeBi5McxGis/zNVddn+FipJ2jd7DfgkbwNeyCjgLwdOB64BJgZ8Vd0EnDh9iZKk/TFkFs2vA78I/KCqXg0cz+jmJUnSCjYk4H88fhb8g0nWMJryeFzbsiRJ0xoyBr8wnub4d8BmRjcvXdeyKEnS9IY8LvgPx4sXJbkCWDMeX5ckrWBD3sn6zzuWq2prVd20eJskaWWadCfrocDjgbVJnsjoZR8Aa4B1y1CbJGkKk4Zo/gA4h1GYL34swb3ABxrWJElaApPuZH0f8L4kb6yq9y9jTZKkJTBkFs2HkpzN6GXbAFcBH6qqB5pVJUma2pCAv5DRs9wvHK+fBXwQeF2roiRJ0xsS8M+tquMXrX8tyY2tCpIkLY0hd7I+lOTpO1aSHAc81K4kSdJSGNKDfzNwZZI7GE2VPBZ4TdOqJElTGxLw1wDPAJ7JKOC/3bQiSdKSGDJEc21Vba+qm6rqxqraDlzbujBJ0nQm3cn6FOCpwGFJTmTnO1kfvwy1SZKmMGmI5iXAq4CjGL2fdUfA3wu8tW1ZkqRpTbqT9WJGr9x7RVVdsow1SZKWwF7H4A13SVqdhlxklSStQga8JHVq0iyaX5v0g1X1uaUvR5K0VCbNovmVCfsKMOAlaQWbNIvm1ctZiCRpaQ15VAFJzgB+Fjh0x7aqemeroiRJ0xvy0u2LgN8E3sjoZqffYPTAMUnSCjZkFs1JVfW7wP9U1TuA5wNHty1LkjStIQH/4/Hnj5KsAx4AntauJEnSUhgyBn9ZkiOBvwKuZzSD5sMti5IkTW+vAV9V7xovXpLkMuDQqvph27IkSdMaOovmJGD9juOTUFUfa1iXJGlKew34JB8Hng7cwCPvYi1gYsAnOXp8zFOAh4FNVfW+aYqVJA03pAc/D2yoqtrHcz8I/GlVXZ/kCGBzkq9W1a37XKUkaZ8NmUWzhVEvfJ9U1fer6vrx8n3AbYzeECVJWgZDevBrgVuTXAds37Gxql42tJEk64ETgW/sa4GSpP0zJODfPk0DSZ4AXAKcU1X37mb/RmAjwDHHHDNNU5KkRYZMk/z6/p48ySGMwv0Te3q8cFVtAjYBzM/P7+s4vyRpDyY9D/6aqvr5JPcxmjXz/7uAqqo1k06cJMBHgNuq6q+XpFpJ0mCTevC/DVBVR+znuU8GzgJuTnLDeNtbq+ry/TyfJGkfTAr4S4HnACS5pKpesS8nrqprGPX2JUkzMGma5OJwPq51IZKkpTUp4GsPy5KkVWDSEM3xSe5l1JM/bLwMAy+ySpJma9I7WQ9azkIkSUtryKMKJEmrkAEvSZ0y4CWpUwa8JHXKgJekThnwktQpA16SOmXAS1KnDHhJ6pQBL0mdMuAlqVMGvCR1yoCXpE4Z8JLUKQNekjplwEtSpwx4SeqUAS9JnTLgJalTBrwkdcqAl6ROGfCS1CkDXpI6ZcBLUqcMeEnqlAEvSZ0y4CWpUwa8JHWqWcAn+WiSu5NsadWGJGnPWvbg/wE4reH5JUkTNAv4qroa+O9W55ckTTbzMfgkG5MsJFnYtm3brMuRpG7MPOCralNVzVfV/Nzc3KzLkaRuzDzgJUltGPCS1KmW0yQ/BVwLPDPJnUle26otSdKjHdzqxFV1ZqtzS5L2ziEaSeqUAS9JnTLgJalTBrwkdcqAl6ROGfCS1CkDXpI6ZcBLUqcMeEnqlAEvSZ1q9qiC5bb+3C/OugStUFvPO2PWJUgzYQ9ekjplwEtSpwx4SeqUAS9JnTLgJalTBrwkdcqAl6ROGfCS1CkDXpI6ZcBLUqcMeEnqlAEvSZ0y4CWpUwa8JHXKgJekThnwktQpA16SOmXAS1KnDHhJ6pQBL0mdahrwSU5LcnuS7yQ5t2VbkqSdNQv4JAcBHwBOBzYAZybZ0Ko9SdLOWvbgnwd8p6ruqKqfAJ8GXt6wPUnSIgc3PPdTge8tWr8T+LldD0qyEdg4Xr0/ye0NazpQrAXumXURK0XOn3UF2gO/p2NTfkeP3dOOlgGf3WyrR22o2gRsaljHASfJQlXNz7oOaRK/p+21HKK5Ezh60fpRwF0N25MkLdIy4L8JPCPJ05I8Fngl8IWG7UmSFmk2RFNVDyb5Y+DLwEHAR6vqllbtaScOeWk18HvaWKoeNSwuSeqAd7JKUqcMeEnqlAG/iiQ5O8ltST6xh/3HJtmc5IYktyR5/aJ9nxg/NmJLko8mOWT5KteBJsm/DjjmnCSPX7R+ZpKbk9yU5Ioka9tW2T/H4FeRJN8GTq+q/9zD/scy+p1uT/IEYAtwUlXdleSlwJfGh34SuLqqPrgshUu7kWQrMF9V9yQ5mNE06g3j9b8EflRVb59ljaudPfhVIslFwHHAF5L8MMnHk3wtyb8n+X2AqvpJVW0f/8jjWPT7rarLawy4jtF9CVITSe4ff74wyVVJPpvk2+P/SSbJ2cA64MokVzK6MTLA4UkCrMH7ZqZmwK8SVfV6Rl/4U4C/AZ4NnAE8H/iLJOsAkhyd5CZGj4k4v6p2+ksyHpo5C7hiGcvXge1E4BxGDx08Dji5qi5g/H2uqlOq6gHgDcDN4+0bgI/Mptx+GPCr1+er6sdVdQ9wJaOHu1FV36uqZwM/A/xekifv8nMXMhqe+ZflLVcHsOuq6s6qehi4AVi/6wHjjscbGP1jsA64CXjLMtbYJQN+9dr14slO6+Oe+y3AL+zYluRtwBzwJ82rkx6xfdHyQ+z+BssTAKrqP8bDiJ8BTmpfWt8M+NXr5UkOTfIk4IXAN5McleQwgCRPBE4Gbh+vvw54CXDmuCclzdp9wBHj5f8CNiSZG6+/CLhtJlV1pOXTJNXWdcAXgWOAd41nyrwIeG+SYnTB6j1VdfP4+IuA7wLXjq5h8bmqeucM6pZ22AR8Kcn3q+qUJO8Ark7yAKPv6qtmWl0HnCa5CiV5O3B/Vb1n1rVIWrkcopGkTtmDl6RO2YOXpE4Z8JLUKQNekjplwEtSpwx4SerU/wEmKk03yIrbrwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(range(2), [loss[\"Total\"].detach().numpy(), loss_int8[\"Total\"].detach().numpy()])\n",
    "plt.xticks(range(2), [\"fp32\", \"int8\"])\n",
    "plt.ylabel(\"Final total loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9542dbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_pred_int8 = preds_unpacked_int8[\"pt\"][msk_true_particles].numpy()\n",
    "eta_pred_int8 = preds_unpacked_int8[\"eta\"][msk_true_particles].numpy()\n",
    "sphi_pred_int8 = preds_unpacked_int8[\"sin_phi\"][msk_true_particles].numpy()\n",
    "cphi_pred_int8 = preds_unpacked_int8[\"cos_phi\"][msk_true_particles].numpy()\n",
    "energy_pred_int8 = preds_unpacked_int8[\"energy\"][msk_true_particles].numpy()\n",
    "\n",
    "px = preds_unpacked_int8[\"pt\"] * preds_unpacked_int8[\"cos_phi\"] * msk_true_particles\n",
    "py = preds_unpacked_int8[\"pt\"] * preds_unpacked_int8[\"sin_phi\"] * msk_true_particles\n",
    "pred_met_int8 = torch.sqrt(torch.sum(px, axis=-2) ** 2 + torch.sum(py, axis=-2) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d64b0554",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fae94131af0>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(pred_met/true_met, bins=np.linspace(0,5,61), histtype=\"step\", lw=2, label=\"fp32\");\n",
    "plt.hist(pred_met_int8/true_met, bins=np.linspace(0,5,61), histtype=\"step\", lw=2, label=\"int8\");\n",
    "plt.xlabel(\"reco_met / gen_met\")\n",
    "plt.ylabel(\"number of events / bin\")\n",
    "plt.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9ddf71d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the 3-momentum for the quantized particles.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "805b2ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "px = preds_unpacked_int8[\"pt\"] * preds_unpacked_int8[\"cos_phi\"] * msk_true_particles\n",
    "py = preds_unpacked_int8[\"pt\"] * preds_unpacked_int8[\"sin_phi\"] * msk_true_particles\n",
    "pz = preds_unpacked_int8[\"pt\"] * np.sinh(preds_unpacked_int8[\"eta\"]) * msk_true_particles\n",
    "phi = np.arctan2(preds_unpacked_int8[\"sin_phi\"], preds_unpacked_int8[\"cos_phi\"]) * msk_true_particles\n",
    "\n",
    "px_np = px.detach().cpu().numpy()\n",
    "py_np = py.detach().cpu().numpy()\n",
    "pz_np = pz.detach().cpu().numpy()\n",
    "phi_np = phi.detach().cpu().numpy()\n",
    "\n",
    "# print(\"px_np\", px_np)\n",
    "# print(\"py_np\", py_np)\n",
    "# print(\"pz_np\", pz_np)\n",
    "# print(\"phi_np\", phi_np)\n",
    "\n",
    "quantized_mom = np.sqrt(np.sum(px_np, axis=1)**2 + np.sum(py_np, axis=1)**2 + np.sum(pz_np, axis=1)**2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b9e6b6b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([145.70184, 347.48117,  89.0497 , ...,  93.8607 , 180.75926,\n",
       "        91.3306 ], dtype=float32)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quantized_mom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "722aefba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning in <TCanvas::Constructor>: Deleting canvas with same name: canvas\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ROOT\n",
    "import numpy as np\n",
    "\n",
    "# Define bins\n",
    "bins = [10, 20, 30, 40, 60, 80, 100, 200]\n",
    "\n",
    "# Initialize lists to store values\n",
    "x_vals = []\n",
    "ratio_iqr_median = []\n",
    "quantized_ratio_iqr_median = []\n",
    "\n",
    "# Iterate over bins\n",
    "for i in range(len(bins) - 1):\n",
    "    lim_low = bins[i]\n",
    "    lim_hi = bins[i + 1]\n",
    "    x_vals.append(np.mean([lim_low, lim_hi]))\n",
    "\n",
    "    # Filter true and predicted momentum values within the bin\n",
    "    true_values_in_bin = true_mom[(true_mom > lim_low) & (true_mom <= lim_hi)]\n",
    "    pred_values_in_bin = pred_mom[(pred_mom > lim_low) & (pred_mom <= lim_hi)]\n",
    "    quantized_values_in_bin = quantized_mom[(quantized_mom > lim_low) & (quantized_mom <= lim_hi)]\n",
    "\n",
    "    # Resize arrays to ensure they have the same shape\n",
    "    min_length = min(len(pred_values_in_bin), len(true_values_in_bin), len(quantized_values_in_bin))\n",
    "    pred_values_in_bin_resized = np.resize(pred_values_in_bin, min_length)\n",
    "    true_values_in_bin_resized = np.resize(true_values_in_bin, min_length)\n",
    "    quantized_values_in_bin_resized = np.resize(quantized_values_in_bin, min_length)\n",
    "\n",
    "    # Calculate ratios\n",
    "    ratio_values_in_bin = pred_values_in_bin_resized / true_values_in_bin_resized\n",
    "    quantized_ratio_values_in_bin = quantized_values_in_bin_resized / true_values_in_bin_resized\n",
    "\n",
    "    # Calculate IQR and median for the ratios\n",
    "    if len(ratio_values_in_bin) > 0:\n",
    "        ratio_iqr = np.percentile(ratio_values_in_bin, 75) - np.percentile(ratio_values_in_bin, 25)\n",
    "        ratio_median = np.median(ratio_values_in_bin)\n",
    "        ratio_iqr_median_ratio = ratio_iqr / ratio_median\n",
    "        ratio_iqr_median.append(ratio_iqr_median_ratio)\n",
    "    else:\n",
    "        ratio_iqr_median.append(np.nan)\n",
    "\n",
    "    if len(quantized_ratio_values_in_bin) > 0:\n",
    "        quantized_ratio_iqr = np.percentile(quantized_ratio_values_in_bin, 75) - np.percentile(quantized_ratio_values_in_bin, 25)\n",
    "        quantized_ratio_median = np.median(quantized_ratio_values_in_bin)\n",
    "        quantized_ratio_iqr_median_ratio = quantized_ratio_iqr / quantized_ratio_median\n",
    "        quantized_ratio_iqr_median.append(quantized_ratio_iqr_median_ratio)\n",
    "    else:\n",
    "        quantized_ratio_iqr_median.append(np.nan)\n",
    "\n",
    "# Create TGraphs\n",
    "gr_ratio = ROOT.TGraph(len(x_vals), np.array(x_vals), np.array(ratio_iqr_median))\n",
    "gr_quantized_ratio = ROOT.TGraph(len(x_vals), np.array(x_vals), np.array(quantized_ratio_iqr_median))\n",
    "\n",
    "# Create a canvas\n",
    "canvas = ROOT.TCanvas(\"canvas\", \"Ratio IQR/Median vs Momentum\", 800, 600)\n",
    "\n",
    "# Draw the graphs with connecting lines\n",
    "gr_ratio.SetMarkerStyle(20)\n",
    "gr_ratio.SetMarkerColor(ROOT.kBlue)\n",
    "gr_ratio.SetLineColor(ROOT.kBlue)\n",
    "gr_ratio.GetXaxis().SetTitle(\"P_{gen}(GeV)\")\n",
    "gr_ratio.GetYaxis().SetTitle(\"Response IQR/Median\")\n",
    "gr_ratio.Draw(\"APL\")\n",
    "\n",
    "gr_quantized_ratio.SetMarkerStyle(20)\n",
    "gr_quantized_ratio.SetMarkerColor(ROOT.kRed)\n",
    "gr_quantized_ratio.SetLineColor(ROOT.kRed)\n",
    "gr_quantized_ratio.Draw(\"PL\")\n",
    "\n",
    "# Add legend\n",
    "legend = ROOT.TLegend(0.7, 0.7, 0.9, 0.9)\n",
    "legend.AddEntry(gr_ratio, \"pred_fp32\", \"lp\")\n",
    "legend.AddEntry(gr_quantized_ratio, \"pred_INT8\", \"lp\")\n",
    "legend.Draw()\n",
    "\n",
    "# Show the canvas\n",
    "canvas.Draw()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ab4ff8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165e8b23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3170bf59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4adb23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268778ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea962f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052a45b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e3ba0591",
   "metadata": {},
   "source": [
    "### Calculation of response IQR/Median\n",
    "1. Sort the array in ascending order\n",
    "2. First quartile q1, median of the first half of the sorted array.\n",
    "3. thrid quartile q3, median of the second half of the sorted array.\n",
    "4. $IQR=q3-q1$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2b07c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f79be8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16de5ae7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defba48f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c9f4ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f72a481c",
   "metadata": {},
   "source": [
    "# With larger number of statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2e344b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import awkward\n",
    "import fastjet\n",
    "import vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ea6d18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eeb2f76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0f6897a2",
   "metadata": {},
   "source": [
    "# Jets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41b7d52",
   "metadata": {},
   "outputs": [],
   "source": [
    " # For one batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143207db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
